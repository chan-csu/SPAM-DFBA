{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 14:26:20,013\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "WARNING:cobra.medium.boundary_types:Could not identify an external compartment by name and choosing one with the most boundary reactions. That might be complete nonsense or change suddenly. Consider renaming your compartments using `Model.compartments` to fix this.\n",
      "WARNING:cobra.medium.boundary_types:Could not identify an external compartment by name and choosing one with the most boundary reactions. That might be complete nonsense or change suddenly. Consider renaming your compartments using `Model.compartments` to fix this.\n",
      "WARNING:cobra.medium.boundary_types:Could not identify an external compartment by name and choosing one with the most boundary reactions. That might be complete nonsense or change suddenly. Consider renaming your compartments using `Model.compartments` to fix this.\n",
      "WARNING:cobra.medium.boundary_types:Could not identify an external compartment by name and choosing one with the most boundary reactions. That might be complete nonsense or change suddenly. Consider renaming your compartments using `Model.compartments` to fix this.\n",
      "WARNING:cobra.medium.boundary_types:Could not identify an external compartment by name and choosing one with the most boundary reactions. That might be complete nonsense or change suddenly. Consider renaming your compartments using `Model.compartments` to fix this.\n"
     ]
    }
   ],
   "source": [
    "from spamdfba import toolkit as tk\n",
    "from spamdfba import toymodels as tm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "# import seaborn  as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import rich\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 8\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy-Exoenzyme-Single-Agent\n",
    "\n",
    "This toy community is designed to emulate a case that microbial cells are grown on a mixture of starch and glucose in a chemostat with a very low dilution rate of 0.0001, practically a batch system, Figure 3A-C, The strains are capable of secreting amylase to degrade the available starch. However, producing amylase is an energy-consuming step in the organism’s metabolism and it requires ATP that would otherwise be used in biomass production. \n",
    "\n",
    "First, we need to define the agents. The agents need a metabolic model (cobra model) which is defined in Toy_Model.py. The agents\n",
    "also need a name, a neural network class, not instance as a pytorch module, clip which shows the threshold for clipping the gradients, and a learning rate. you also need to define what environment states you want your agent to sense and also what is the actions that the agents can take. Look below for an example of defining an agent.\n",
    "additionally, you can look at toolkit.py for more information on defining agents.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1=tk.Agent(\"agent1\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1' ,'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agents=[agent1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the agents, we need to define the environment. The environment needs a list of agents, inictial conditions and a dictionary representing extracellular reactions as well as the duration of an episode and the time resoloution of the DFBA algorithm. More information on defining the environment can be found in toolkit.py. Look below for an example of defining the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following species are not in the community: ['Starch']\n"
     ]
    }
   ],
   "source": [
    "env=tk.Environment(name=\"Toy-Exoenzyme-Single-agents\",\n",
    "                    agents=agents,\n",
    "                    dilution_rate=0.0001,\n",
    "                    initial_condition={\"Glc\":100,\"agent1\":0.1,\"Starch\":10},\n",
    "                    inlet_conditions={\"Starch\":10},\n",
    "                    extracellular_reactions=[{\"reaction\":{\n",
    "                    \"Glc\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc\",\"Amylase\"))}],\n",
    "                     dt=0.1,\n",
    "                     number_of_batches=50,\n",
    "                     episodes_per_batch=int(NUM_CORES/2),)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the training loop. The training loop needs the environment, the number of episodes, the number of steps per episode, and the number of steps for each gradient update. The training loop will return the rewards for each episode and the average reward for each episode. Look below for an example of training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=tk.Simulation(name=\"Starch_amylase_single\",\n",
    "                  env=env,\n",
    "                  save_dir=\"./Results/\",\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold on, bringing the creitc network to range ...\n",
      "Done!\n",
      "Batch 0 finished:\n",
      "agent1 return was:  -691.9799259050887\n",
      "Batch 1 finished:\n",
      "agent1 return was:  -694.6596566901848\n",
      "Batch 2 finished:\n",
      "agent1 return was:  -691.0036996004408\n",
      "Batch 3 finished:\n",
      "agent1 return was:  -698.9103302819636\n",
      "Batch 4 finished:\n",
      "agent1 return was:  -693.7709285641647\n",
      "Batch 5 finished:\n",
      "agent1 return was:  -696.4761105785169\n",
      "Batch 6 finished:\n",
      "agent1 return was:  -702.5075773106412\n",
      "Batch 7 finished:\n",
      "agent1 return was:  -696.4718172243971\n",
      "Batch 8 finished:\n",
      "agent1 return was:  -694.4911753806011\n",
      "Batch 9 finished:\n",
      "agent1 return was:  -691.3398926101797\n",
      "Batch 10 finished:\n",
      "agent1 return was:  -684.5602857094934\n",
      "Batch 11 finished:\n",
      "agent1 return was:  -691.4580766812104\n",
      "Batch 12 finished:\n",
      "agent1 return was:  -691.2026672651191\n",
      "Batch 13 finished:\n",
      "agent1 return was:  -683.5813871723199\n",
      "Batch 14 finished:\n",
      "agent1 return was:  -682.359433543093\n",
      "Batch 15 finished:\n",
      "agent1 return was:  -685.525736763581\n",
      "Batch 16 finished:\n",
      "agent1 return was:  -686.4635746144754\n",
      "Batch 17 finished:\n",
      "agent1 return was:  -683.34398303215\n",
      "Batch 18 finished:\n",
      "agent1 return was:  -679.0686285608178\n",
      "Batch 19 finished:\n",
      "agent1 return was:  -683.1028553627901\n",
      "Batch 20 finished:\n",
      "agent1 return was:  -684.4966801048037\n",
      "Batch 21 finished:\n",
      "agent1 return was:  -676.1231943540174\n",
      "Batch 22 finished:\n",
      "agent1 return was:  -676.920460331321\n",
      "Batch 23 finished:\n",
      "agent1 return was:  -673.0851753295142\n",
      "Batch 24 finished:\n",
      "agent1 return was:  -685.8158217164367\n",
      "Batch 25 finished:\n",
      "agent1 return was:  -686.812947566093\n",
      "Batch 26 finished:\n",
      "agent1 return was:  -684.79102766847\n",
      "Batch 27 finished:\n",
      "agent1 return was:  -690.5331588674528\n",
      "Batch 28 finished:\n",
      "agent1 return was:  -687.2684624487747\n",
      "Batch 29 finished:\n",
      "agent1 return was:  -684.8206301621353\n",
      "Batch 30 finished:\n",
      "agent1 return was:  -694.903754556825\n",
      "Batch 31 finished:\n",
      "agent1 return was:  -684.6479606746266\n",
      "Batch 32 finished:\n",
      "agent1 return was:  -689.6826284127\n",
      "Batch 33 finished:\n",
      "agent1 return was:  -677.4530498658471\n",
      "Batch 34 finished:\n",
      "agent1 return was:  -685.5577184523736\n",
      "Batch 35 finished:\n",
      "agent1 return was:  -684.5614353453149\n",
      "Batch 36 finished:\n",
      "agent1 return was:  -677.837737565429\n",
      "Batch 37 finished:\n",
      "agent1 return was:  -674.1802463164054\n",
      "Batch 38 finished:\n",
      "agent1 return was:  -669.738614515877\n",
      "Batch 39 finished:\n",
      "agent1 return was:  -675.097690840287\n",
      "Batch 40 finished:\n",
      "agent1 return was:  -666.0955243352832\n",
      "Batch 41 finished:\n",
      "agent1 return was:  -666.8174199256379\n",
      "Batch 42 finished:\n",
      "agent1 return was:  -672.0693056878797\n",
      "Batch 43 finished:\n",
      "agent1 return was:  -665.8719659522166\n",
      "Batch 44 finished:\n",
      "agent1 return was:  -662.6314623013037\n",
      "Batch 45 finished:\n",
      "agent1 return was:  -670.6479998738208\n",
      "Batch 46 finished:\n",
      "agent1 return was:  -666.143954511304\n",
      "Batch 47 finished:\n",
      "agent1 return was:  -666.3123822526375\n",
      "Batch 48 finished:\n",
      "agent1 return was:  -668.3561901403648\n",
      "Batch 49 finished:\n",
      "agent1 return was:  -662.815931205793\n"
     ]
    }
   ],
   "source": [
    "sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "rgb(31, 119, 180)"
         },
         "mode": "lines",
         "name": "agent1",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          -691.9799259050887,
          -694.6596566901848,
          -691.0036996004408,
          -698.9103302819636,
          -693.7709285641647,
          -696.4761105785169,
          -702.5075773106412,
          -696.4718172243971,
          -694.4911753806011,
          -691.3398926101797,
          -684.5602857094934,
          -691.4580766812104,
          -691.2026672651191,
          -683.5813871723199,
          -682.359433543093,
          -685.525736763581,
          -686.4635746144754,
          -683.34398303215,
          -679.0686285608178,
          -683.1028553627901,
          -684.4966801048037,
          -676.1231943540174,
          -676.920460331321,
          -673.0851753295142,
          -685.8158217164367,
          -686.812947566093,
          -684.79102766847,
          -690.5331588674528,
          -687.2684624487747,
          -684.8206301621353,
          -694.903754556825,
          -684.6479606746266,
          -689.6826284127,
          -677.4530498658471,
          -685.5577184523736,
          -684.5614353453149,
          -677.837737565429,
          -674.1802463164054,
          -669.738614515877,
          -675.097690840287,
          -666.0955243352832,
          -666.8174199256379,
          -672.0693056878797,
          -665.8719659522166,
          -662.6314623013037,
          -670.6479998738208,
          -666.143954511304,
          -666.3123822526375,
          -668.3561901403648,
          -662.815931205793
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(31, 119, 180,0.2)",
         "hoverinfo": "skip",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          49,
          48,
          47,
          46,
          45,
          44,
          43,
          42,
          41,
          40,
          39,
          38,
          37,
          36,
          35,
          34,
          33,
          32,
          31,
          30,
          29,
          28,
          27,
          26,
          25,
          24,
          23,
          22,
          21,
          20,
          19,
          18,
          17,
          16,
          15,
          14,
          13,
          12,
          11,
          10,
          9,
          8,
          7,
          6,
          5,
          4,
          3,
          2,
          1,
          0
         ],
         "y": [
          -687.677673939763,
          -692.3588614502403,
          -686.6201755031557,
          -691.6383949638306,
          -684.6980901373477,
          -687.6580397747797,
          -698.3763908389369,
          -688.7071520456554,
          -687.6595273292196,
          -686.7024457409133,
          -676.6457170955732,
          -686.5522373551123,
          -689.5325013439748,
          -681.5072655221715,
          -673.7219536868213,
          -679.5675406749456,
          -682.4827731108917,
          -678.640579555627,
          -670.585124087163,
          -673.7960816509692,
          -680.4095907598469,
          -669.7061753516081,
          -667.8801475484762,
          -660.6990722483418,
          -681.6881892958353,
          -684.5627074585491,
          -680.5210224140775,
          -687.5248118442101,
          -678.7093173480628,
          -677.6599938024245,
          -687.5284045821124,
          -676.8049383596331,
          -682.5033728014399,
          -668.7284797718369,
          -677.6325046441964,
          -679.6373660971427,
          -670.6778668022484,
          -670.8455330644165,
          -658.9423060731127,
          -670.5918420431653,
          -650.8223087388743,
          -661.6083993788441,
          -667.6431872910513,
          -657.7388480128352,
          -647.8476191476198,
          -667.6478280064907,
          -659.6761931814401,
          -659.6136475977501,
          -664.7189055682762,
          -658.5224108587672,
          -666.4138285876417,
          -671.5184526203303,
          -672.538081021967,
          -670.6756495664437,
          -673.5635516515842,
          -670.3686678467429,
          -672.4181644880894,
          -676.4756269594525,
          -674.3254795722587,
          -678.4461545295292,
          -680.4568531978475,
          -678.660723367464,
          -678.5876649087871,
          -684.3922076210075,
          -690.4159782801681,
          -695.3970715937864,
          -685.5752407279581,
          -701.2291276131017,
          -691.4328548082163,
          -699.34173669659,
          -691.3983361073883,
          -693.2678091151869,
          -695.4679967112588,
          -689.4954043168807,
          -692.5105274940842,
          -691.393102264415,
          -682.483739840441,
          -686.3956266064072,
          -682.3974188820054,
          -690.4243169163295,
          -687.6087702300691,
          -684.6413357065583,
          -689.3645771319152,
          -691.2333434648765,
          -697.3402001203074,
          -690.5667787831964,
          -686.5876039123833,
          -694.4167180367685,
          -696.3316101354135,
          -695.4354247794246,
          -693.6082089002261,
          -697.4783507051702,
          -702.3480372637431,
          -705.1554839466667,
          -701.3510928768885,
          -698.6462385991624,
          -705.1204336346303,
          -695.513035702754,
          -698.2577289160687,
          -696.3833587159911
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "title": {
          "text": "Batch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Total Episode Return"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=sim.plot_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        Simulation times                         </span>\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Level        </span>┃<span style=\"font-weight: bold\"> Mean                   </span>┃<span style=\"font-weight: bold\"> STD                   </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Optimization </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 0.0002770591378211975  </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 4.193920807812129e-06 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Step         </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 0.00039991034865379335 </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 4.628349008811643e-06 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Batch        </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 1.1968899726867677     </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 0.793404399593946     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Simulation   </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> 9.045735836029053      </span>│<span style=\"color: #008080; text-decoration-color: #008080\"> NA                    </span>│\n",
       "└──────────────┴────────────────────────┴───────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        Simulation times                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLevel       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMean                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSTD                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mOptimization\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m0.0002770591378211975 \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m4.193920807812129e-06\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mStep        \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m0.00039991034865379335\u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m4.628349008811643e-06\u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mBatch       \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m1.1968899726867677    \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m0.793404399593946    \u001b[0m\u001b[36m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSimulation  \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36m9.045735836029053     \u001b[0m\u001b[36m \u001b[0m│\u001b[36m \u001b[0m\u001b[36mNA                   \u001b[0m\u001b[36m \u001b[0m│\n",
       "└──────────────┴────────────────────────┴───────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.print_training_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file /var/folders/jk/fr50qn391k794svhntbw333c0000gn/T/tmpalrbsvhd.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 7 rows, 18 columns, 44 nonzeros\n",
      "Read LP format model from file /var/folders/jk/fr50qn391k794svhntbw333c0000gn/T/tmp566lcqnu.lp\n",
      "Reading time = 0.00 seconds\n",
      ": 7 rows, 18 columns, 44 nonzeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following species are not in the community: ['Starch']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Toy-Exoenzyme-Two-agents created successfully!.\n"
     ]
    }
   ],
   "source": [
    "agent1=tk.Agent(\"agent1\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2' ,'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agent2=tk.Agent(\"agent2\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2', 'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agents=[agent1,agent2]\n",
    "\n",
    "env=tk.Environment(name=\"Toy-Exoenzyme-Two-agents\",\n",
    "                    agents=agents,\n",
    "                    dilution_rate=0.0001,\n",
    "                    initial_condition={\"Glc\":100,\"agent1\":0.1,\"agent2\":0.1,\"Starch\":10},\n",
    "                    inlet_conditions={\"Starch\":10},\n",
    "                    extracellular_reactions=[{\"reaction\":{\n",
    "                    \"Glc\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc\",\"Amylase\"))}],\n",
    "                    max_c={'Glc':100,\n",
    "                           'agent1':10,  \n",
    "                           'Starch':10,\n",
    "                           },\n",
    "                           dt=0.1,\n",
    "                           episode_time=100,\n",
    "                           number_of_batches=5000,\n",
    "                           episodes_per_batch=int(NUM_CORES/2),\n",
    "                           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Hold on, bringing the creitc network to range...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m Hold on, bringing the creitc network to range\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Done!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Done!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 finished:\n",
      "agent1 return is:  -834.9255180536776\n",
      "agent2 return is:  -815.9404837891703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Hold on, bringing the creitc network to range...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m Hold on, bringing the creitc network to range\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Done!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Done!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 finished:\n",
      "agent1 return is:  -834.9255180536776\n",
      "agent2 return is:  -815.9404837891703\n",
      "Batch 1 finished:\n",
      "agent1 return is:  -841.8440040666383\n",
      "agent2 return is:  -826.1826531004805\n",
      "Batch 1 finished:\n",
      "agent1 return is:  -841.8440040666383\n",
      "agent2 return is:  -826.1826531004805\n",
      "Batch 2 finished:\n",
      "agent1 return is:  -835.6765195038785\n",
      "agent2 return is:  -820.6359854544567\n",
      "Batch 2 finished:\n",
      "agent1 return is:  -835.6765195038785\n",
      "agent2 return is:  -820.6359854544567\n",
      "Batch 3 finished:\n",
      "agent1 return is:  -838.8587132565848\n",
      "agent2 return is:  -824.0484213947282\n",
      "Batch 3 finished:\n",
      "agent1 return is:  -838.8587132565848\n",
      "agent2 return is:  -824.0484213947282\n",
      "Batch 4 finished:\n",
      "agent1 return is:  -841.3364360564342\n",
      "agent2 return is:  -832.9258086808351\n",
      "Batch 4 finished:\n",
      "agent1 return is:  -841.3364360564342\n",
      "agent2 return is:  -832.9258086808351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \tagent\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msolver\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mglpk\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mnumber_of_batches):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \tbatch_obs,batch_acts, batch_log_probs, batch_rtgs\u001b[39m=\u001b[39mtk\u001b[39m.\u001b[39;49mrollout(env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39magents:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \t\tV, _\u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mevaluate(batch_obs[agent\u001b[39m.\u001b[39mname],batch_acts[agent\u001b[39m.\u001b[39mname])\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:386\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mepisodes_per_batch):\n\u001b[1;32m    384\u001b[0m     \u001b[39m# batch.append(run_episode_single(env))\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     batch\u001b[39m.\u001b[39mappend(run_episode\u001b[39m.\u001b[39mremote(env))\n\u001b[0;32m--> 386\u001b[0m batch\u001b[39m=\u001b[39mray\u001b[39m.\u001b[39;49mget(batch)\n\u001b[1;32m    387\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mepisodes_per_batch):\n\u001b[1;32m    388\u001b[0m     \u001b[39mfor\u001b[39;00m ag \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39magents:\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/ray/worker.py:1825\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an object ref \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a list of object refs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m     )\n\u001b[1;32m   1824\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 1825\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1826\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   1827\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/ray/worker.py:364\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    359\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    363\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 364\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    365\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m (data, metadata) \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1200\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:169\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.rewards={agent.name:[] for agent in env.agents}\n",
    "\n",
    "if not os.path.exists(f\"Results/{env.name}\"):\n",
    "\tos.makedirs(f\"Results/{env.name}\")\n",
    "\n",
    "for agent in env.agents:\n",
    "\tagent.model.solver=\"glpk\"\n",
    "\n",
    "for batch in range(env.number_of_batches):\n",
    "\n",
    "\tbatch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "\tfor agent in env.agents:\n",
    "\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\tA_k = batch_rtgs[agent.name] - V.detach()   \n",
    "\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "\t\tif batch==0:\n",
    "\t\t\trich.print(\"[bold yellow] Hold on, bringing the creitc network to range...[/bold yellow]\")\n",
    "\t\t\terr=21\n",
    "\t\t\twhile err>20:\n",
    "\t\t\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step() \n",
    "\t\t\t\terr=critic_loss.item()\n",
    "\t\t\trich.print(\"[bold green] Done![/bold green]\")\n",
    "\t\telse: \n",
    "\t\t\t\n",
    "\t\t\tfor _ in range(agent.grad_updates):                                                      \n",
    "\t\t\t\tV, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "\t\t\t\tsurr1 = ratios * A_k.detach()\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_policy_.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\t\t\tagent.optimizer_policy_.step()\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step()                                                            \n",
    "\t\n",
    "\t\tif batch%500==0:\n",
    "\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(env, f)\n",
    "\t\t\twith open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_obs,f)\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_acts,f)\t\t\n",
    "          \t\t\n",
    "\t\tprint(f\"Batch {batch} finished:\")\n",
    "\t\tfor agent in env.agents:\n",
    "\t\t\tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1=tk.Agent(\"agent1\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5','Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agent2=tk.Agent(\"agent2\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5', 'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agent3=tk.Agent(\"agent3\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5', 'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "agent4=tk.Agent(\"agent4\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5', 'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "agent5=tk.Agent(\"agent5\",\n",
    "                model=tm.ToyModel_SA.copy(),\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=10,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5', 'Glc', 'Starch'],\n",
    "                actions=[\"Amylase_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agents=[agent1,agent2,agent3,agent4,agent5]\n",
    "\n",
    "\n",
    "env=tk.Environment(name=\"Toy-Exoenzyme-Five-agents\",\n",
    "                  agents=agents,\n",
    "                  dilution_rate=0.0001,\n",
    "                  initial_condition={\"Glc\":100,\"agent1\":0.1,\"agent2\":0.1,\"agent3\":0.1,\"agent4\":0.1,\"agent5\":0.1,\"Starch\":10},\n",
    "                  inlet_conditions={\"Starch\":10},\n",
    "                  extracellular_reactions=[{\"reaction\":{\n",
    "                      \"Glc\":10,\n",
    "                  \"Starch\":-0.1,},\n",
    "                  \"kinetics\": (tk.general_kinetic,(\"Glc\",\"Amylase\"))}],\n",
    "                  max_c={'Glc':100,\n",
    "                         'agent1':10,  \n",
    "                         'Starch':10,\n",
    "                         },\n",
    "                         dt=0.1,\n",
    "                         episode_time=100,\n",
    "                         number_of_batches=5000,\n",
    "                         episodes_per_batch=int(NUM_CORES/2),\n",
    "                         )                 \n",
    "\n",
    "\n",
    "env.rewards={agent.name:[] for agent in env.agents}\n",
    "\n",
    "if not os.path.exists(f\"Results/{env.name}\"):\n",
    "\tos.makedirs(f\"Results/{env.name}\")\n",
    "\n",
    "for agent in env.agents:\n",
    "\tagent.model.solver=\"glpk\"\n",
    "\n",
    "for batch in range(env.number_of_batches):\n",
    "\n",
    "\tbatch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "\tfor agent in env.agents:\n",
    "\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\tA_k = batch_rtgs[agent.name] - V.detach()   \n",
    "\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "\t\tif batch==0:\n",
    "\t\t\trich.print(\"[bold yellow] Hold on, bringing the creitc network to range...[/bold yellow]\")\n",
    "\t\t\terr=21\n",
    "\t\t\twhile err>20:\n",
    "\t\t\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step() \n",
    "\t\t\t\terr=critic_loss.item()\n",
    "\t\t\trich.print(\"[bold green] Done![/bold green]\")\n",
    "\t\telse: \n",
    "\t\t\t\n",
    "\t\t\tfor _ in range(agent.grad_updates):                                                      \n",
    "\t\t\t\tV, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "\t\t\t\tsurr1 = ratios * A_k.detach()\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_policy_.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\t\t\tagent.optimizer_policy_.step()\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step()                                                            \n",
    "\t\n",
    "\t\tif batch%500==0:\n",
    "\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(env, f)\n",
    "\t\t\twith open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_obs,f)\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_acts,f)\t\t\n",
    "          \t\t\n",
    "\t\tprint(f\"Batch {batch} finished:\")\n",
    "\t\tfor agent in env.agents:\n",
    "\t\t\tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy-NECOM-Auxotrophs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Toy-NECOM-Auxotrophs created successfully!.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Hold on, bringing the creitc network to range...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m Hold on, bringing the creitc network to range\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Done!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Done!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Hold on, bringing the creitc network to range...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m Hold on, bringing the creitc network to range\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Done!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Done!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 finished:\n",
      "agent1 return is:  -693.263211649023\n",
      "agent2 return is:  -494.3485401777354\n",
      "Batch 1 finished:\n",
      "agent1 return is:  -689.7608206478573\n",
      "agent2 return is:  -489.10863895799946\n",
      "Batch 2 finished:\n",
      "agent1 return is:  -686.385095640583\n",
      "agent2 return is:  -500.47163949786096\n",
      "Batch 3 finished:\n",
      "agent1 return is:  -697.5145220951706\n",
      "agent2 return is:  -505.0906397532352\n",
      "Batch 4 finished:\n",
      "agent1 return is:  -701.8949813944643\n",
      "agent2 return is:  -510.2214796378634\n",
      "Batch 5 finished:\n",
      "agent1 return is:  -688.8917124463186\n",
      "agent2 return is:  -506.8473380565723\n",
      "Batch 6 finished:\n",
      "agent1 return is:  -696.5160124816357\n",
      "agent2 return is:  -501.72032076966195\n",
      "Batch 7 finished:\n",
      "agent1 return is:  -680.2570645901875\n",
      "agent2 return is:  -490.71814468345343\n",
      "Batch 8 finished:\n",
      "agent1 return is:  -684.3835380369874\n",
      "agent2 return is:  -464.32930403313355\n",
      "Batch 9 finished:\n",
      "agent1 return is:  -688.5053279676099\n",
      "agent2 return is:  -459.6008065688017\n",
      "Batch 10 finished:\n",
      "agent1 return is:  -691.6378828485514\n",
      "agent2 return is:  -446.0847850771975\n",
      "Batch 11 finished:\n",
      "agent1 return is:  -686.881097989732\n",
      "agent2 return is:  -430.97899842993854\n",
      "Batch 12 finished:\n",
      "agent1 return is:  -690.7589441958671\n",
      "agent2 return is:  -414.8455504828014\n",
      "Batch 13 finished:\n",
      "agent1 return is:  -669.6174956205884\n",
      "agent2 return is:  -401.9577526718225\n",
      "Batch 14 finished:\n",
      "agent1 return is:  -671.741754680142\n",
      "agent2 return is:  -376.7136690416738\n",
      "Batch 15 finished:\n",
      "agent1 return is:  -657.7378259507495\n",
      "agent2 return is:  -388.3462916834491\n",
      "Batch 16 finished:\n",
      "agent1 return is:  -661.3607368052844\n",
      "agent2 return is:  -377.2319777861824\n",
      "Batch 17 finished:\n",
      "agent1 return is:  -650.4881431529591\n",
      "agent2 return is:  -350.0923122493871\n",
      "Batch 18 finished:\n",
      "agent1 return is:  -644.985511086697\n",
      "agent2 return is:  -354.4603381366355\n",
      "Batch 19 finished:\n",
      "agent1 return is:  -640.8545700251259\n",
      "agent2 return is:  -347.83222683488236\n",
      "Batch 20 finished:\n",
      "agent1 return is:  -625.0984187056993\n",
      "agent2 return is:  -347.82101928847806\n",
      "Batch 21 finished:\n",
      "agent1 return is:  -603.5861440006539\n",
      "agent2 return is:  -320.6916625273924\n",
      "Batch 22 finished:\n",
      "agent1 return is:  -601.3365783605028\n",
      "agent2 return is:  -316.6930531335137\n",
      "Batch 23 finished:\n",
      "agent1 return is:  -595.3292178934753\n",
      "agent2 return is:  -306.563551742964\n",
      "Batch 24 finished:\n",
      "agent1 return is:  -593.4495577553375\n",
      "agent2 return is:  -299.56842654005584\n",
      "Batch 25 finished:\n",
      "agent1 return is:  -575.3192086234436\n",
      "agent2 return is:  -301.9487937235096\n",
      "Batch 26 finished:\n",
      "agent1 return is:  -555.8026670104626\n",
      "agent2 return is:  -302.442643344259\n",
      "Batch 27 finished:\n",
      "agent1 return is:  -534.171677303948\n",
      "agent2 return is:  -299.0740298943119\n",
      "Batch 28 finished:\n",
      "agent1 return is:  -523.6570100961029\n",
      "agent2 return is:  -287.0550538840896\n",
      "Batch 29 finished:\n",
      "agent1 return is:  -495.51978905870703\n",
      "agent2 return is:  -272.7817217288882\n",
      "Batch 30 finished:\n",
      "agent1 return is:  -495.142700208164\n",
      "agent2 return is:  -258.4377524207303\n",
      "Batch 31 finished:\n",
      "agent1 return is:  -494.13971718532554\n",
      "agent2 return is:  -258.5618880532554\n",
      "Batch 32 finished:\n",
      "agent1 return is:  -464.8695210320626\n",
      "agent2 return is:  -243.65778763403966\n",
      "Batch 33 finished:\n",
      "agent1 return is:  -465.00266286551164\n",
      "agent2 return is:  -251.29405134308968\n",
      "Batch 34 finished:\n",
      "agent1 return is:  -454.1242162515245\n",
      "agent2 return is:  -241.79667050722932\n",
      "Batch 35 finished:\n",
      "agent1 return is:  -446.87280809330065\n",
      "agent2 return is:  -241.66259966302817\n",
      "Batch 36 finished:\n",
      "agent1 return is:  -449.1278278645865\n",
      "agent2 return is:  -234.15603326060904\n",
      "Batch 37 finished:\n",
      "agent1 return is:  -403.0950084917182\n",
      "agent2 return is:  -221.73860077690034\n",
      "Batch 38 finished:\n",
      "agent1 return is:  -393.95370335991174\n",
      "agent2 return is:  -221.24126931596902\n",
      "Batch 39 finished:\n",
      "agent1 return is:  -383.82273287467115\n",
      "agent2 return is:  -209.2615675960348\n",
      "Batch 40 finished:\n",
      "agent1 return is:  -376.81378033127726\n",
      "agent2 return is:  -211.36720809463623\n",
      "Batch 41 finished:\n",
      "agent1 return is:  -373.30311839743683\n",
      "agent2 return is:  -198.98591153260472\n",
      "Batch 42 finished:\n",
      "agent1 return is:  -375.29893192247584\n",
      "agent2 return is:  -188.3759656568804\n",
      "Batch 43 finished:\n",
      "agent1 return is:  -360.28607656533484\n",
      "agent2 return is:  -186.8781831805395\n",
      "Batch 44 finished:\n",
      "agent1 return is:  -354.65718611671934\n",
      "agent2 return is:  -179.73562362134695\n",
      "Batch 45 finished:\n",
      "agent1 return is:  -341.6573945038118\n",
      "agent2 return is:  -181.12499306687084\n",
      "Batch 46 finished:\n",
      "agent1 return is:  -337.51606562626534\n",
      "agent2 return is:  -176.86289523890733\n",
      "Batch 47 finished:\n",
      "agent1 return is:  -329.63054325373696\n",
      "agent2 return is:  -162.20892378702723\n",
      "Batch 48 finished:\n",
      "agent1 return is:  -316.8846137797467\n",
      "agent2 return is:  -165.7956335808036\n",
      "Batch 49 finished:\n",
      "agent1 return is:  -309.1127073539511\n",
      "agent2 return is:  -139.31457938333475\n",
      "Batch 50 finished:\n",
      "agent1 return is:  -296.8621679152144\n",
      "agent2 return is:  -141.67002491799963\n",
      "Batch 51 finished:\n",
      "agent1 return is:  -279.86116395394333\n",
      "agent2 return is:  -146.79915641016953\n",
      "Batch 52 finished:\n",
      "agent1 return is:  -274.10877925500256\n",
      "agent2 return is:  -136.57718242627283\n",
      "Batch 53 finished:\n",
      "agent1 return is:  -278.3528869410153\n",
      "agent2 return is:  -129.57302726563944\n",
      "Batch 54 finished:\n",
      "agent1 return is:  -265.7158198452914\n",
      "agent2 return is:  -115.42744591858005\n",
      "Batch 55 finished:\n",
      "agent1 return is:  -253.0712749804071\n",
      "agent2 return is:  -114.19748824832395\n",
      "Batch 56 finished:\n",
      "agent1 return is:  -248.17301083757047\n",
      "agent2 return is:  -104.30139751391499\n",
      "Batch 57 finished:\n",
      "agent1 return is:  -246.54349923781086\n",
      "agent2 return is:  -115.41447238476476\n",
      "Batch 58 finished:\n",
      "agent1 return is:  -242.28503210444742\n",
      "agent2 return is:  -106.30220723149064\n",
      "Batch 59 finished:\n",
      "agent1 return is:  -253.28395401226385\n",
      "agent2 return is:  -102.82258888014053\n",
      "Batch 60 finished:\n",
      "agent1 return is:  -239.78305172367817\n",
      "agent2 return is:  -101.08012310711106\n",
      "Batch 61 finished:\n",
      "agent1 return is:  -233.6426650166842\n",
      "agent2 return is:  -97.21548931570919\n",
      "Batch 62 finished:\n",
      "agent1 return is:  -232.39803740023052\n",
      "agent2 return is:  -98.58648231723468\n",
      "Batch 63 finished:\n",
      "agent1 return is:  -235.88692320937537\n",
      "agent2 return is:  -92.85051898271618\n",
      "Batch 64 finished:\n",
      "agent1 return is:  -223.00970966582963\n",
      "agent2 return is:  -88.33814951584742\n",
      "Batch 65 finished:\n",
      "agent1 return is:  -205.8572175892465\n",
      "agent2 return is:  -83.79956684895735\n",
      "Batch 66 finished:\n",
      "agent1 return is:  -213.97690945002142\n",
      "agent2 return is:  -81.06092847365002\n",
      "Batch 67 finished:\n",
      "agent1 return is:  -193.33522110937417\n",
      "agent2 return is:  -81.07983550982354\n",
      "Batch 68 finished:\n",
      "agent1 return is:  -197.59738228963982\n",
      "agent2 return is:  -78.30709605080037\n",
      "Batch 69 finished:\n",
      "agent1 return is:  -189.73673128651487\n",
      "agent2 return is:  -75.79403379115132\n",
      "Batch 70 finished:\n",
      "agent1 return is:  -186.97727970756304\n",
      "agent2 return is:  -76.3050139041468\n",
      "Batch 71 finished:\n",
      "agent1 return is:  -178.9678817343319\n",
      "agent2 return is:  -74.55985355534821\n",
      "Batch 72 finished:\n",
      "agent1 return is:  -196.5946392697187\n",
      "agent2 return is:  -75.57710984906646\n",
      "Batch 73 finished:\n",
      "agent1 return is:  -179.46871500241866\n",
      "agent2 return is:  -73.92170304254077\n",
      "Batch 74 finished:\n",
      "agent1 return is:  -182.34183359245546\n",
      "agent2 return is:  -78.04696850184206\n",
      "Batch 75 finished:\n",
      "agent1 return is:  -184.71228057835418\n",
      "agent2 return is:  -77.80385905356937\n",
      "Batch 76 finished:\n",
      "agent1 return is:  -177.20169332827064\n",
      "agent2 return is:  -69.2718381121206\n",
      "Batch 77 finished:\n",
      "agent1 return is:  -175.07868964560606\n",
      "agent2 return is:  -68.24125262878823\n",
      "Batch 78 finished:\n",
      "agent1 return is:  -167.30644566519155\n",
      "agent2 return is:  -71.71648522239657\n",
      "Batch 79 finished:\n",
      "agent1 return is:  -161.31371545076303\n",
      "agent2 return is:  -71.25452645100013\n",
      "Batch 80 finished:\n",
      "agent1 return is:  -155.82715945506274\n",
      "agent2 return is:  -63.960801271245145\n",
      "Batch 81 finished:\n",
      "agent1 return is:  -157.81569504269464\n",
      "agent2 return is:  -65.35273220287883\n",
      "Batch 82 finished:\n",
      "agent1 return is:  -151.4457226821561\n",
      "agent2 return is:  -65.83622478575242\n",
      "Batch 83 finished:\n",
      "agent1 return is:  -146.44675800552054\n",
      "agent2 return is:  -67.59391939007375\n",
      "Batch 84 finished:\n",
      "agent1 return is:  -140.07323086662404\n",
      "agent2 return is:  -62.56521636460319\n",
      "Batch 85 finished:\n",
      "agent1 return is:  -142.19316590955728\n",
      "agent2 return is:  -60.66781104264683\n",
      "Batch 86 finished:\n",
      "agent1 return is:  -128.68197662240377\n",
      "agent2 return is:  -51.41660786170093\n",
      "Batch 87 finished:\n",
      "agent1 return is:  -124.79042854908033\n",
      "agent2 return is:  -54.29592212492004\n",
      "Batch 88 finished:\n",
      "agent1 return is:  -113.19401842966863\n",
      "agent2 return is:  -54.809516695101564\n",
      "Batch 89 finished:\n",
      "agent1 return is:  -114.33520885159534\n",
      "agent2 return is:  -49.59379018896384\n",
      "Batch 90 finished:\n",
      "agent1 return is:  -122.44882730451963\n",
      "agent2 return is:  -44.85529279164601\n",
      "Batch 91 finished:\n",
      "agent1 return is:  -114.56208170180875\n",
      "agent2 return is:  -38.75911645302453\n",
      "Batch 92 finished:\n",
      "agent1 return is:  -112.67564930722408\n",
      "agent2 return is:  -37.37741301838849\n",
      "Batch 93 finished:\n",
      "agent1 return is:  -116.66175646281356\n",
      "agent2 return is:  -39.387957366262654\n",
      "Batch 94 finished:\n",
      "agent1 return is:  -117.41625309649093\n",
      "agent2 return is:  -41.76868269617465\n",
      "Batch 95 finished:\n",
      "agent1 return is:  -103.78831320322897\n",
      "agent2 return is:  -35.546988229056566\n",
      "Batch 96 finished:\n",
      "agent1 return is:  -110.52837166392844\n",
      "agent2 return is:  -33.41711670204701\n",
      "Batch 97 finished:\n",
      "agent1 return is:  -107.53199244254654\n",
      "agent2 return is:  -32.90759505859317\n",
      "Batch 98 finished:\n",
      "agent1 return is:  -96.79012128380893\n",
      "agent2 return is:  -30.886533188606258\n",
      "Batch 99 finished:\n",
      "agent1 return is:  -85.53770168146247\n",
      "agent2 return is:  -26.254609273720078\n",
      "Batch 100 finished:\n",
      "agent1 return is:  -86.28034495504068\n",
      "agent2 return is:  -29.019576147381027\n",
      "Batch 101 finished:\n",
      "agent1 return is:  -83.63061377441042\n",
      "agent2 return is:  -24.031042562484682\n",
      "Batch 102 finished:\n",
      "agent1 return is:  -79.40129154123501\n",
      "agent2 return is:  -24.558803128883017\n",
      "Batch 103 finished:\n",
      "agent1 return is:  -75.6285565849684\n",
      "agent2 return is:  -23.896413450160985\n",
      "Batch 104 finished:\n",
      "agent1 return is:  -74.7471790142383\n",
      "agent2 return is:  -25.302869631129155\n",
      "Batch 105 finished:\n",
      "agent1 return is:  -73.35719487571579\n",
      "agent2 return is:  -21.41290606192161\n",
      "Batch 106 finished:\n",
      "agent1 return is:  -67.45309616080435\n",
      "agent2 return is:  -19.620502713300958\n",
      "Batch 107 finished:\n",
      "agent1 return is:  -67.8088198478501\n",
      "agent2 return is:  -17.872479486048693\n",
      "Batch 108 finished:\n",
      "agent1 return is:  -65.45457533938509\n",
      "agent2 return is:  -16.880971856535623\n",
      "Batch 109 finished:\n",
      "agent1 return is:  -60.0508702006787\n",
      "agent2 return is:  -16.234043375767364\n",
      "Batch 110 finished:\n",
      "agent1 return is:  -56.055111799223994\n",
      "agent2 return is:  -14.965174006577826\n",
      "Batch 111 finished:\n",
      "agent1 return is:  -56.362224281109626\n",
      "agent2 return is:  -15.43721984796008\n",
      "Batch 112 finished:\n",
      "agent1 return is:  -50.25248657961876\n",
      "agent2 return is:  -17.56191342557519\n",
      "Batch 113 finished:\n",
      "agent1 return is:  -52.83590018943029\n",
      "agent2 return is:  -13.557864337269312\n",
      "Batch 114 finished:\n",
      "agent1 return is:  -47.96476315292631\n",
      "agent2 return is:  -12.7959029372468\n",
      "Batch 115 finished:\n",
      "agent1 return is:  -42.85378975459045\n",
      "agent2 return is:  -13.207733468942212\n",
      "Batch 116 finished:\n",
      "agent1 return is:  -42.09100255692617\n",
      "agent2 return is:  -12.073742973610877\n",
      "Batch 117 finished:\n",
      "agent1 return is:  -39.586876277289555\n",
      "agent2 return is:  -12.839400133225979\n",
      "Batch 118 finished:\n",
      "agent1 return is:  -40.45964881626085\n",
      "agent2 return is:  -12.51350178143581\n",
      "Batch 119 finished:\n",
      "agent1 return is:  -36.10176606973468\n",
      "agent2 return is:  -11.621072853979465\n",
      "Batch 120 finished:\n",
      "agent1 return is:  -36.83856291855081\n",
      "agent2 return is:  -10.750538605383294\n",
      "Batch 121 finished:\n",
      "agent1 return is:  -32.457591824313305\n",
      "agent2 return is:  -12.738218480552685\n",
      "Batch 122 finished:\n",
      "agent1 return is:  -29.848242617160366\n",
      "agent2 return is:  -12.24627710335799\n",
      "Batch 123 finished:\n",
      "agent1 return is:  -29.458200790291116\n",
      "agent2 return is:  -10.87965724865597\n",
      "Batch 124 finished:\n",
      "agent1 return is:  -28.082740574212878\n",
      "agent2 return is:  -9.51188730695941\n",
      "Batch 125 finished:\n",
      "agent1 return is:  -24.44718442503015\n",
      "agent2 return is:  -8.385329679083153\n",
      "Batch 126 finished:\n",
      "agent1 return is:  -25.82857449639929\n",
      "agent2 return is:  -8.473358529600322\n",
      "Batch 127 finished:\n",
      "agent1 return is:  -25.18680274973557\n",
      "agent2 return is:  -6.4708078517099725\n",
      "Batch 128 finished:\n",
      "agent1 return is:  -23.0778488426684\n",
      "agent2 return is:  -7.638198545947253\n",
      "Batch 129 finished:\n",
      "agent1 return is:  -19.953417113973593\n",
      "agent2 return is:  -6.501099458947922\n",
      "Batch 130 finished:\n",
      "agent1 return is:  -19.578558705357395\n",
      "agent2 return is:  -5.480138579590822\n",
      "Batch 131 finished:\n",
      "agent1 return is:  -17.4896032866299\n",
      "agent2 return is:  -5.619276167417915\n",
      "Batch 132 finished:\n",
      "agent1 return is:  -15.626842171628802\n",
      "agent2 return is:  -5.359753972958971\n",
      "Batch 133 finished:\n",
      "agent1 return is:  -16.380883832816252\n",
      "agent2 return is:  -5.611161266329472\n",
      "Batch 134 finished:\n",
      "agent1 return is:  -16.899180088064654\n",
      "agent2 return is:  -3.605264106822647\n",
      "Batch 135 finished:\n",
      "agent1 return is:  -13.12688592880992\n",
      "agent2 return is:  -4.751644180652997\n",
      "Batch 136 finished:\n",
      "agent1 return is:  -13.983010816482409\n",
      "agent2 return is:  -4.992242582494162\n",
      "Batch 137 finished:\n",
      "agent1 return is:  -11.839309172088727\n",
      "agent2 return is:  -4.843755990525195\n",
      "Batch 138 finished:\n",
      "agent1 return is:  -11.072204970830938\n",
      "agent2 return is:  -4.442088355214702\n",
      "Batch 139 finished:\n",
      "agent1 return is:  -12.094854731267665\n",
      "agent2 return is:  -2.7992722179925713\n",
      "Batch 140 finished:\n",
      "agent1 return is:  -12.459043158682064\n",
      "agent2 return is:  -3.421535282708441\n",
      "Batch 141 finished:\n",
      "agent1 return is:  -10.94202673140136\n",
      "agent2 return is:  -3.665682841911061\n",
      "Batch 142 finished:\n",
      "agent1 return is:  -11.80196123516483\n",
      "agent2 return is:  -4.257592448815338\n",
      "Batch 143 finished:\n",
      "agent1 return is:  -10.793570890173797\n",
      "agent2 return is:  -2.9030146864271877\n",
      "Batch 144 finished:\n",
      "agent1 return is:  -10.04931934267903\n",
      "agent2 return is:  -3.3566594951865634\n",
      "Batch 145 finished:\n",
      "agent1 return is:  -9.471047893121103\n",
      "agent2 return is:  -2.903105834065105\n",
      "Batch 146 finished:\n",
      "agent1 return is:  -7.743776291992871\n",
      "agent2 return is:  -3.2905575799992555\n",
      "Batch 147 finished:\n",
      "agent1 return is:  -9.51677186206151\n",
      "agent2 return is:  -2.318357182973461\n",
      "Batch 148 finished:\n",
      "agent1 return is:  -8.52012045979836\n",
      "agent2 return is:  -2.8218286550331753\n",
      "Batch 149 finished:\n",
      "agent1 return is:  -5.899156774258159\n",
      "agent2 return is:  -1.625495131125116\n",
      "Batch 150 finished:\n",
      "agent1 return is:  -7.046555018130066\n",
      "agent2 return is:  -2.004764889182754\n",
      "Batch 151 finished:\n",
      "agent1 return is:  -8.021498623415042\n",
      "agent2 return is:  -1.6060458397818689\n",
      "Batch 152 finished:\n",
      "agent1 return is:  -7.487522243331776\n",
      "agent2 return is:  -2.3428192950394005\n",
      "Batch 153 finished:\n",
      "agent1 return is:  -7.475456334485163\n",
      "agent2 return is:  -1.4861334951483682\n",
      "Batch 154 finished:\n",
      "agent1 return is:  -7.013117541604102\n",
      "agent2 return is:  -2.861883563675982\n",
      "Batch 155 finished:\n",
      "agent1 return is:  -5.8824235614822955\n",
      "agent2 return is:  -1.9509880860325326\n",
      "Batch 156 finished:\n",
      "agent1 return is:  -7.400604429618594\n",
      "agent2 return is:  -2.420894800110114\n",
      "Batch 157 finished:\n",
      "agent1 return is:  -4.921976010375874\n",
      "agent2 return is:  -2.2705394352023474\n",
      "Batch 158 finished:\n",
      "agent1 return is:  -5.401129322082278\n",
      "agent2 return is:  -1.6473161795267304\n",
      "Batch 159 finished:\n",
      "agent1 return is:  -5.137297384950412\n",
      "agent2 return is:  -1.5220127298662485\n",
      "Batch 160 finished:\n",
      "agent1 return is:  -3.6370370744804257\n",
      "agent2 return is:  -1.2782519464363387\n",
      "Batch 161 finished:\n",
      "agent1 return is:  -5.879770249032843\n",
      "agent2 return is:  -1.0109159701536352\n",
      "Batch 162 finished:\n",
      "agent1 return is:  -2.48712749037741\n",
      "agent2 return is:  -0.9023249532001567\n",
      "Batch 163 finished:\n",
      "agent1 return is:  -3.901502302646655\n",
      "agent2 return is:  -1.6730075169064604\n",
      "Batch 164 finished:\n",
      "agent1 return is:  -3.2761434194323558\n",
      "agent2 return is:  -1.041553493671697\n",
      "Batch 165 finished:\n",
      "agent1 return is:  -3.761551021738043\n",
      "agent2 return is:  -1.6056667297853497\n",
      "Batch 166 finished:\n",
      "agent1 return is:  -3.0086535963628025\n",
      "agent2 return is:  -2.6048977202752974\n",
      "Batch 167 finished:\n",
      "agent1 return is:  -3.8847914151379497\n",
      "agent2 return is:  -1.0196959180592513\n",
      "Batch 168 finished:\n",
      "agent1 return is:  -3.1219650602147806\n",
      "agent2 return is:  -1.468796027405078\n",
      "Batch 169 finished:\n",
      "agent1 return is:  -4.0151052756364685\n",
      "agent2 return is:  -0.7072597021840873\n",
      "Batch 170 finished:\n",
      "agent1 return is:  -2.541685783475922\n",
      "agent2 return is:  -1.3171606139079777\n",
      "Batch 171 finished:\n",
      "agent1 return is:  -3.7518964842705635\n",
      "agent2 return is:  -0.72507644872457\n",
      "Batch 172 finished:\n",
      "agent1 return is:  -3.638381265033468\n",
      "agent2 return is:  -1.6569246736930234\n",
      "Batch 173 finished:\n",
      "agent1 return is:  -3.133305870107203\n",
      "agent2 return is:  -1.0487722242172455\n",
      "Batch 174 finished:\n",
      "agent1 return is:  -4.858450744822234\n",
      "agent2 return is:  -1.2117615144328888\n",
      "Batch 175 finished:\n",
      "agent1 return is:  -3.6018448942578734\n",
      "agent2 return is:  -1.2261055847421836\n",
      "Batch 176 finished:\n",
      "agent1 return is:  -3.4778173488229354\n",
      "agent2 return is:  -1.2116327955474948\n",
      "Batch 177 finished:\n",
      "agent1 return is:  -1.950699158751123\n",
      "agent2 return is:  -0.9570087202327942\n",
      "Batch 178 finished:\n",
      "agent1 return is:  -3.8087954496341236\n",
      "agent2 return is:  -1.0291097777643738\n",
      "Batch 179 finished:\n",
      "agent1 return is:  -2.591898460307047\n",
      "agent2 return is:  0.09899812543269002\n",
      "Batch 180 finished:\n",
      "agent1 return is:  -1.2176199017495821\n",
      "agent2 return is:  -0.3024894036830583\n",
      "Batch 181 finished:\n",
      "agent1 return is:  -2.3577360056514816\n",
      "agent2 return is:  -1.6788956915841144\n",
      "Batch 182 finished:\n",
      "agent1 return is:  -1.8505356894013945\n",
      "agent2 return is:  -0.44072626274994714\n",
      "Batch 183 finished:\n",
      "agent1 return is:  -1.2167319841820867\n",
      "agent2 return is:  -0.44638501755893834\n",
      "Batch 184 finished:\n",
      "agent1 return is:  -2.2046926034824215\n",
      "agent2 return is:  -1.3967185100868953\n",
      "Batch 185 finished:\n",
      "agent1 return is:  -0.8107633965597821\n",
      "agent2 return is:  -1.0248466810635906\n",
      "Batch 186 finished:\n",
      "agent1 return is:  -1.306612157279889\n",
      "agent2 return is:  -1.4062461788462484\n",
      "Batch 187 finished:\n",
      "agent1 return is:  -2.3503147247812852\n",
      "agent2 return is:  -1.5472149334507534\n",
      "Batch 188 finished:\n",
      "agent1 return is:  -1.4591394100245294\n",
      "agent2 return is:  -0.6276536307002036\n",
      "Batch 189 finished:\n",
      "agent1 return is:  -1.357357383155385\n",
      "agent2 return is:  -1.31124430412786\n",
      "Batch 190 finished:\n",
      "agent1 return is:  -1.2575806322998047\n",
      "agent2 return is:  -0.6921289543945945\n",
      "Batch 191 finished:\n",
      "agent1 return is:  -1.3550925627355643\n",
      "agent2 return is:  -1.1873760372321267\n",
      "Batch 192 finished:\n",
      "agent1 return is:  -0.467055197642933\n",
      "agent2 return is:  -0.6028662128758233\n",
      "Batch 193 finished:\n",
      "agent1 return is:  -0.8330170979169855\n",
      "agent2 return is:  -0.3512895116200794\n",
      "Batch 194 finished:\n",
      "agent1 return is:  0.027115216951625054\n",
      "agent2 return is:  -0.21564516226833116\n",
      "Batch 195 finished:\n",
      "agent1 return is:  -0.08915012797013466\n",
      "agent2 return is:  -0.614399718109858\n",
      "Batch 196 finished:\n",
      "agent1 return is:  -0.7077316015987609\n",
      "agent2 return is:  -0.9695091667192819\n",
      "Batch 197 finished:\n",
      "agent1 return is:  -0.20178968235492706\n",
      "agent2 return is:  -0.24074658130213777\n",
      "Batch 198 finished:\n",
      "agent1 return is:  -0.4881879296922309\n",
      "agent2 return is:  0.05534200311960488\n",
      "Batch 199 finished:\n",
      "agent1 return is:  -0.8490669375232118\n",
      "agent2 return is:  -0.8968445958876323\n",
      "Batch 200 finished:\n",
      "agent1 return is:  -0.7330311253847366\n",
      "agent2 return is:  -0.12638219515592652\n",
      "Batch 201 finished:\n",
      "agent1 return is:  -0.6078244498585554\n",
      "agent2 return is:  -0.5998102395751824\n",
      "Batch 202 finished:\n",
      "agent1 return is:  -0.46889204079881386\n",
      "agent2 return is:  0.009511666386889578\n",
      "Batch 203 finished:\n",
      "agent1 return is:  -0.6977125346216109\n",
      "agent2 return is:  -0.37697466171598415\n",
      "Batch 204 finished:\n",
      "agent1 return is:  -0.07506249322909408\n",
      "agent2 return is:  -1.0347301872104824\n",
      "Batch 205 finished:\n",
      "agent1 return is:  -0.5568364185203348\n",
      "agent2 return is:  0.23556940485581324\n",
      "Batch 206 finished:\n",
      "agent1 return is:  0.27356766595071647\n",
      "agent2 return is:  -0.42074550448448206\n",
      "Batch 207 finished:\n",
      "agent1 return is:  0.17148855664250176\n",
      "agent2 return is:  -0.6663758640730204\n",
      "Batch 208 finished:\n",
      "agent1 return is:  -0.30008216706392776\n",
      "agent2 return is:  -0.17323852550818827\n",
      "Batch 209 finished:\n",
      "agent1 return is:  -0.2691940381512811\n",
      "agent2 return is:  -0.449661243037739\n",
      "Batch 210 finished:\n",
      "agent1 return is:  0.2384175983132193\n",
      "agent2 return is:  -0.38704613787323916\n",
      "Batch 211 finished:\n",
      "agent1 return is:  0.1303065648397201\n",
      "agent2 return is:  -0.9825431052287286\n",
      "Batch 212 finished:\n",
      "agent1 return is:  0.295642854687306\n",
      "agent2 return is:  -1.614576517812433\n",
      "Batch 213 finished:\n",
      "agent1 return is:  0.533112400706689\n",
      "agent2 return is:  -0.3074450886371346\n",
      "Batch 214 finished:\n",
      "agent1 return is:  0.3810820463945672\n",
      "agent2 return is:  -0.8243586885377964\n",
      "Batch 215 finished:\n",
      "agent1 return is:  0.2726132767924618\n",
      "agent2 return is:  -0.7814223152745794\n",
      "Batch 216 finished:\n",
      "agent1 return is:  0.4138958272153924\n",
      "agent2 return is:  -0.7709879873322228\n",
      "Batch 217 finished:\n",
      "agent1 return is:  0.825377650892645\n",
      "agent2 return is:  -0.6089663439275075\n",
      "Batch 218 finished:\n",
      "agent1 return is:  0.6090113025692259\n",
      "agent2 return is:  -0.18026809655341774\n",
      "Batch 219 finished:\n",
      "agent1 return is:  0.10313754156248613\n",
      "agent2 return is:  -0.9428667971568218\n",
      "Batch 220 finished:\n",
      "agent1 return is:  0.49505629461349054\n",
      "agent2 return is:  -0.5648169500890473\n",
      "Batch 221 finished:\n",
      "agent1 return is:  0.3547903545186984\n",
      "agent2 return is:  0.027322087263469075\n",
      "Batch 222 finished:\n",
      "agent1 return is:  0.6952510226953029\n",
      "agent2 return is:  -0.7500014537209205\n",
      "Batch 223 finished:\n",
      "agent1 return is:  0.17639054373432453\n",
      "agent2 return is:  0.027875087290080258\n",
      "Batch 224 finished:\n",
      "agent1 return is:  -0.05263210509511862\n",
      "agent2 return is:  -0.23216752094609824\n",
      "Batch 225 finished:\n",
      "agent1 return is:  0.3742083770870462\n",
      "agent2 return is:  -0.444634123056711\n",
      "Batch 226 finished:\n",
      "agent1 return is:  0.14201579682821694\n",
      "agent2 return is:  -1.1588799420591358\n",
      "Batch 227 finished:\n",
      "agent1 return is:  0.6546456263528877\n",
      "agent2 return is:  -0.19836678431533433\n",
      "Batch 228 finished:\n",
      "agent1 return is:  -0.06111456919160088\n",
      "agent2 return is:  -0.9164859455423124\n",
      "Batch 229 finished:\n",
      "agent1 return is:  0.44067408478173137\n",
      "agent2 return is:  -0.6498577953631843\n",
      "Batch 230 finished:\n",
      "agent1 return is:  0.43029945670711145\n",
      "agent2 return is:  0.0997087764473058\n",
      "Batch 231 finished:\n",
      "agent1 return is:  0.8223378429512451\n",
      "agent2 return is:  -0.03954117035656844\n",
      "Batch 232 finished:\n",
      "agent1 return is:  0.4649111792424585\n",
      "agent2 return is:  -0.3238762426240278\n",
      "Batch 233 finished:\n",
      "agent1 return is:  0.5882948107846533\n",
      "agent2 return is:  0.51960889248096\n",
      "Batch 234 finished:\n",
      "agent1 return is:  0.7089892941321259\n",
      "agent2 return is:  0.012390532983069788\n",
      "Batch 235 finished:\n",
      "agent1 return is:  0.8206506268552205\n",
      "agent2 return is:  -0.0044213197128537204\n",
      "Batch 236 finished:\n",
      "agent1 return is:  0.8381222367314513\n",
      "agent2 return is:  0.49556068301314254\n",
      "Batch 237 finished:\n",
      "agent1 return is:  0.6018172686887668\n",
      "agent2 return is:  0.7849809355082547\n",
      "Batch 238 finished:\n",
      "agent1 return is:  0.5316920953643399\n",
      "agent2 return is:  0.5768432329860081\n",
      "Batch 239 finished:\n",
      "agent1 return is:  0.7952123974218107\n",
      "agent2 return is:  0.6805663664329545\n",
      "Batch 240 finished:\n",
      "agent1 return is:  0.872335222363511\n",
      "agent2 return is:  0.4052587615806852\n",
      "Batch 241 finished:\n",
      "agent1 return is:  0.7425342284325693\n",
      "agent2 return is:  0.30741310094431057\n",
      "Batch 242 finished:\n",
      "agent1 return is:  0.739973948613794\n",
      "agent2 return is:  0.5004005970688378\n",
      "Batch 243 finished:\n",
      "agent1 return is:  0.5371449765871315\n",
      "agent2 return is:  0.540347406248135\n",
      "Batch 244 finished:\n",
      "agent1 return is:  0.7703585139649338\n",
      "agent2 return is:  0.5289762661704434\n",
      "Batch 245 finished:\n",
      "agent1 return is:  0.3910560499249546\n",
      "agent2 return is:  0.6640088542138287\n",
      "Batch 246 finished:\n",
      "agent1 return is:  0.9377879516346342\n",
      "agent2 return is:  0.6048386471722471\n",
      "Batch 247 finished:\n",
      "agent1 return is:  1.1347513436868635\n",
      "agent2 return is:  0.6772196380491725\n",
      "Batch 248 finished:\n",
      "agent1 return is:  0.47818207079608743\n",
      "agent2 return is:  -0.24503927227616826\n",
      "Batch 249 finished:\n",
      "agent1 return is:  0.8266662376475854\n",
      "agent2 return is:  0.3967442207011798\n",
      "Batch 250 finished:\n",
      "agent1 return is:  0.7379376127578603\n",
      "agent2 return is:  0.5644602224787252\n",
      "Batch 251 finished:\n",
      "agent1 return is:  0.646831092771082\n",
      "agent2 return is:  0.2285557540053746\n",
      "Batch 252 finished:\n",
      "agent1 return is:  0.7609210259259219\n",
      "agent2 return is:  0.44756241575748346\n",
      "Batch 253 finished:\n",
      "agent1 return is:  0.985269734168168\n",
      "agent2 return is:  0.5410077678564775\n",
      "Batch 254 finished:\n",
      "agent1 return is:  0.8902840788987341\n",
      "agent2 return is:  0.6988769420348001\n",
      "Batch 255 finished:\n",
      "agent1 return is:  0.9205636859854158\n",
      "agent2 return is:  0.15627390432643834\n",
      "Batch 256 finished:\n",
      "agent1 return is:  0.6444441765511191\n",
      "agent2 return is:  0.2841713007880767\n",
      "Batch 257 finished:\n",
      "agent1 return is:  1.1661999229431945\n",
      "agent2 return is:  0.6818055716404967\n",
      "Batch 258 finished:\n",
      "agent1 return is:  0.8364527098102641\n",
      "agent2 return is:  0.4556127100477499\n",
      "Batch 259 finished:\n",
      "agent1 return is:  0.8727052423461774\n",
      "agent2 return is:  0.713575452952872\n",
      "Batch 260 finished:\n",
      "agent1 return is:  1.140876260310535\n",
      "agent2 return is:  0.6414616252322735\n",
      "Batch 261 finished:\n",
      "agent1 return is:  0.9747409756102736\n",
      "agent2 return is:  0.618416150472584\n",
      "Batch 262 finished:\n",
      "agent1 return is:  0.6757156365637426\n",
      "agent2 return is:  0.9130462950580529\n",
      "Batch 263 finished:\n",
      "agent1 return is:  0.8376166392331785\n",
      "agent2 return is:  0.797667355911162\n",
      "Batch 264 finished:\n",
      "agent1 return is:  0.6071430226602383\n",
      "agent2 return is:  0.9256311749484689\n",
      "Batch 265 finished:\n",
      "agent1 return is:  0.5853446128089779\n",
      "agent2 return is:  0.8164036860666627\n",
      "Batch 266 finished:\n",
      "agent1 return is:  0.9601949161065677\n",
      "agent2 return is:  0.8917488842831248\n",
      "Batch 267 finished:\n",
      "agent1 return is:  0.9390102119736579\n",
      "agent2 return is:  0.720838562064168\n",
      "Batch 268 finished:\n",
      "agent1 return is:  0.9608226598340494\n",
      "agent2 return is:  0.6425317309614503\n",
      "Batch 269 finished:\n",
      "agent1 return is:  0.8090510522263585\n",
      "agent2 return is:  0.5776151223880683\n",
      "Batch 270 finished:\n",
      "agent1 return is:  0.7274334972035883\n",
      "agent2 return is:  0.7797626823689014\n",
      "Batch 271 finished:\n",
      "agent1 return is:  0.8342292224002986\n",
      "agent2 return is:  0.7835016997333926\n",
      "Batch 272 finished:\n",
      "agent1 return is:  1.0766912387307896\n",
      "agent2 return is:  0.6153324425582167\n",
      "Batch 273 finished:\n",
      "agent1 return is:  0.9557799327451159\n",
      "agent2 return is:  0.3829699739426581\n",
      "Batch 274 finished:\n",
      "agent1 return is:  0.7218773233380347\n",
      "agent2 return is:  0.6458380320678475\n",
      "Batch 275 finished:\n",
      "agent1 return is:  1.1045250132236155\n",
      "agent2 return is:  0.1791892133693565\n",
      "Batch 276 finished:\n",
      "agent1 return is:  1.0914022857310746\n",
      "agent2 return is:  0.7194103357948642\n",
      "Batch 277 finished:\n",
      "agent1 return is:  0.8389935658997566\n",
      "agent2 return is:  0.6699068677445031\n",
      "Batch 278 finished:\n",
      "agent1 return is:  1.083276412111314\n",
      "agent2 return is:  0.6590035924602403\n",
      "Batch 279 finished:\n",
      "agent1 return is:  1.089990079912335\n",
      "agent2 return is:  0.5989396395791432\n",
      "Batch 280 finished:\n",
      "agent1 return is:  1.0796162833181424\n",
      "agent2 return is:  0.8665343980109483\n",
      "Batch 281 finished:\n",
      "agent1 return is:  0.5907562773826921\n",
      "agent2 return is:  0.9294535496323766\n",
      "Batch 282 finished:\n",
      "agent1 return is:  0.7418404750423933\n",
      "agent2 return is:  0.7747224258841863\n",
      "Batch 283 finished:\n",
      "agent1 return is:  0.8347948688667193\n",
      "agent2 return is:  0.7166635351805106\n",
      "Batch 284 finished:\n",
      "agent1 return is:  0.9515115921319434\n",
      "agent2 return is:  1.0541393211764323\n",
      "Batch 285 finished:\n",
      "agent1 return is:  1.064104671249435\n",
      "agent2 return is:  1.0031164985805447\n",
      "Batch 286 finished:\n",
      "agent1 return is:  0.7771220072726148\n",
      "agent2 return is:  0.9785894213716146\n",
      "Batch 287 finished:\n",
      "agent1 return is:  0.8662107256206362\n",
      "agent2 return is:  1.114219900815363\n",
      "Batch 288 finished:\n",
      "agent1 return is:  0.8743944798916335\n",
      "agent2 return is:  0.8652659579018663\n",
      "Batch 289 finished:\n",
      "agent1 return is:  0.8840992300023874\n",
      "agent2 return is:  0.9909305821909681\n",
      "Batch 290 finished:\n",
      "agent1 return is:  1.000668236651066\n",
      "agent2 return is:  0.3699347847526091\n",
      "Batch 291 finished:\n",
      "agent1 return is:  0.7118295963318513\n",
      "agent2 return is:  1.045117201348095\n",
      "Batch 292 finished:\n",
      "agent1 return is:  0.9709489510011504\n",
      "agent2 return is:  1.1714966209839386\n",
      "Batch 293 finished:\n",
      "agent1 return is:  0.8547437639487792\n",
      "agent2 return is:  1.2797357644143865\n",
      "Batch 294 finished:\n",
      "agent1 return is:  0.974477789139411\n",
      "agent2 return is:  1.1148767497355623\n",
      "Batch 295 finished:\n",
      "agent1 return is:  0.9487064520324298\n",
      "agent2 return is:  0.8867469175110816\n",
      "Batch 296 finished:\n",
      "agent1 return is:  0.8245227454440367\n",
      "agent2 return is:  1.361998757491999\n",
      "Batch 297 finished:\n",
      "agent1 return is:  0.8903470095965264\n",
      "agent2 return is:  0.7798558682715002\n",
      "Batch 298 finished:\n",
      "agent1 return is:  0.501704089804509\n",
      "agent2 return is:  1.1758974866228402\n",
      "Batch 299 finished:\n",
      "agent1 return is:  0.564755374471106\n",
      "agent2 return is:  1.238040804984093\n",
      "Batch 300 finished:\n",
      "agent1 return is:  0.7834251414542044\n",
      "agent2 return is:  1.4417481536554622\n",
      "Batch 301 finished:\n",
      "agent1 return is:  0.7645744050431378\n",
      "agent2 return is:  1.3768435020551915\n",
      "Batch 302 finished:\n",
      "agent1 return is:  0.8168649092498318\n",
      "agent2 return is:  1.616979109339276\n",
      "Batch 303 finished:\n",
      "agent1 return is:  1.0643473821556857\n",
      "agent2 return is:  1.4108765171518631\n",
      "Batch 304 finished:\n",
      "agent1 return is:  0.3283546209388714\n",
      "agent2 return is:  0.9636968544527528\n",
      "Batch 305 finished:\n",
      "agent1 return is:  1.087645600268131\n",
      "agent2 return is:  1.1616826312600952\n",
      "Batch 306 finished:\n",
      "agent1 return is:  0.8297646518148754\n",
      "agent2 return is:  1.3526311374735984\n",
      "Batch 307 finished:\n",
      "agent1 return is:  1.1184993836769208\n",
      "agent2 return is:  1.5358601468153918\n",
      "Batch 308 finished:\n",
      "agent1 return is:  0.9211888408651755\n",
      "agent2 return is:  1.5439858154312711\n",
      "Batch 309 finished:\n",
      "agent1 return is:  1.1239312494054594\n",
      "agent2 return is:  1.3766000379249186\n",
      "Batch 310 finished:\n",
      "agent1 return is:  1.070371450525729\n",
      "agent2 return is:  1.2486997317365829\n",
      "Batch 311 finished:\n",
      "agent1 return is:  0.900246993426354\n",
      "agent2 return is:  1.6326732052324333\n",
      "Batch 312 finished:\n",
      "agent1 return is:  0.8939462108957018\n",
      "agent2 return is:  1.4466428205734974\n",
      "Batch 313 finished:\n",
      "agent1 return is:  0.766008885520069\n",
      "agent2 return is:  1.4174173363302809\n",
      "Batch 314 finished:\n",
      "agent1 return is:  0.9692773612677875\n",
      "agent2 return is:  1.587157198457812\n",
      "Batch 315 finished:\n",
      "agent1 return is:  0.8477393355392444\n",
      "agent2 return is:  1.635916773627181\n",
      "Batch 316 finished:\n",
      "agent1 return is:  0.863598466477756\n",
      "agent2 return is:  1.8485326488900253\n",
      "Batch 317 finished:\n",
      "agent1 return is:  1.014381398923697\n",
      "agent2 return is:  1.761949751455525\n",
      "Batch 318 finished:\n",
      "agent1 return is:  1.0723087234419162\n",
      "agent2 return is:  1.7749861023175706\n",
      "Batch 319 finished:\n",
      "agent1 return is:  0.9844925625453507\n",
      "agent2 return is:  2.055548328900478\n",
      "Batch 320 finished:\n",
      "agent1 return is:  1.0856571075991863\n",
      "agent2 return is:  1.8864906260870482\n",
      "Batch 321 finished:\n",
      "agent1 return is:  0.8292239135325781\n",
      "agent2 return is:  1.8412694902594384\n",
      "Batch 322 finished:\n",
      "agent1 return is:  0.9662452099389416\n",
      "agent2 return is:  1.6576490705613236\n",
      "Batch 323 finished:\n",
      "agent1 return is:  0.9450542193408864\n",
      "agent2 return is:  1.7530051198452443\n",
      "Batch 324 finished:\n",
      "agent1 return is:  0.9319466561077594\n",
      "agent2 return is:  1.7383109058560469\n",
      "Batch 325 finished:\n",
      "agent1 return is:  0.8657090529199818\n",
      "agent2 return is:  1.8258550307093753\n",
      "Batch 326 finished:\n",
      "agent1 return is:  0.9672166081729354\n",
      "agent2 return is:  1.8009781193578536\n",
      "Batch 327 finished:\n",
      "agent1 return is:  0.9688186677657891\n",
      "agent2 return is:  1.8545277997995127\n",
      "Batch 328 finished:\n",
      "agent1 return is:  0.724891522486294\n",
      "agent2 return is:  1.8179979646667719\n",
      "Batch 329 finished:\n",
      "agent1 return is:  0.7001457296471417\n",
      "agent2 return is:  1.6409890676732017\n",
      "Batch 330 finished:\n",
      "agent1 return is:  0.6496052672429391\n",
      "agent2 return is:  1.9146186455807337\n",
      "Batch 331 finished:\n",
      "agent1 return is:  0.7558037421661661\n",
      "agent2 return is:  1.591528284474316\n",
      "Batch 332 finished:\n",
      "agent1 return is:  0.7212361058586144\n",
      "agent2 return is:  1.6864612402627162\n",
      "Batch 333 finished:\n",
      "agent1 return is:  0.5933687209905434\n",
      "agent2 return is:  1.6874060340764556\n",
      "Batch 334 finished:\n",
      "agent1 return is:  0.47789291255630706\n",
      "agent2 return is:  1.5587907199184232\n",
      "Batch 335 finished:\n",
      "agent1 return is:  0.8282693962100172\n",
      "agent2 return is:  1.7928445267635253\n",
      "Batch 336 finished:\n",
      "agent1 return is:  0.863892037525803\n",
      "agent2 return is:  1.740686081755739\n",
      "Batch 337 finished:\n",
      "agent1 return is:  0.6275584712062401\n",
      "agent2 return is:  1.888828097683961\n",
      "Batch 338 finished:\n",
      "agent1 return is:  0.9080456622063426\n",
      "agent2 return is:  1.7305012091789385\n",
      "Batch 339 finished:\n",
      "agent1 return is:  0.7868343129987823\n",
      "agent2 return is:  1.6731793358668323\n",
      "Batch 340 finished:\n",
      "agent1 return is:  0.7835225601040408\n",
      "agent2 return is:  1.9185764180462364\n",
      "Batch 341 finished:\n",
      "agent1 return is:  0.7696862954701482\n",
      "agent2 return is:  1.700991341265818\n",
      "Batch 342 finished:\n",
      "agent1 return is:  0.85548137965\n",
      "agent2 return is:  1.7890515344548383\n",
      "Batch 343 finished:\n",
      "agent1 return is:  0.2959052886648953\n",
      "agent2 return is:  1.5859972761225176\n",
      "Batch 344 finished:\n",
      "agent1 return is:  0.8437960976778531\n",
      "agent2 return is:  1.7525231959419494\n",
      "Batch 345 finished:\n",
      "agent1 return is:  0.5332702288459932\n",
      "agent2 return is:  1.9959522954013527\n",
      "Batch 346 finished:\n",
      "agent1 return is:  0.796089732733576\n",
      "agent2 return is:  1.842043356525283\n",
      "Batch 347 finished:\n",
      "agent1 return is:  0.71561715715492\n",
      "agent2 return is:  1.902687994041497\n",
      "Batch 348 finished:\n",
      "agent1 return is:  0.8388044751673791\n",
      "agent2 return is:  2.091517413135587\n",
      "Batch 349 finished:\n",
      "agent1 return is:  0.8326435695923956\n",
      "agent2 return is:  1.6571634158580708\n",
      "Batch 350 finished:\n",
      "agent1 return is:  0.8259631062589153\n",
      "agent2 return is:  2.0038943909671785\n",
      "Batch 351 finished:\n",
      "agent1 return is:  0.5886673194828009\n",
      "agent2 return is:  1.9998283346901526\n",
      "Batch 352 finished:\n",
      "agent1 return is:  0.6045974479641203\n",
      "agent2 return is:  1.6709675880839654\n",
      "Batch 353 finished:\n",
      "agent1 return is:  0.5934313286954642\n",
      "agent2 return is:  1.8377911874236257\n",
      "Batch 354 finished:\n",
      "agent1 return is:  0.5173650349867667\n",
      "agent2 return is:  1.623506122107019\n",
      "Batch 355 finished:\n",
      "agent1 return is:  0.8221528031379102\n",
      "agent2 return is:  1.7380864404858252\n",
      "Batch 356 finished:\n",
      "agent1 return is:  0.7100985241587856\n",
      "agent2 return is:  1.8027646567572164\n",
      "Batch 357 finished:\n",
      "agent1 return is:  0.7472301495974525\n",
      "agent2 return is:  1.8839882128489225\n",
      "Batch 358 finished:\n",
      "agent1 return is:  0.49240174310696017\n",
      "agent2 return is:  1.9285474396224487\n",
      "Batch 359 finished:\n",
      "agent1 return is:  0.6381746933622436\n",
      "agent2 return is:  1.8642350140361037\n",
      "Batch 360 finished:\n",
      "agent1 return is:  0.7340244248565105\n",
      "agent2 return is:  1.777534113320089\n",
      "Batch 361 finished:\n",
      "agent1 return is:  0.894919800328122\n",
      "agent2 return is:  1.7567146208915856\n",
      "Batch 362 finished:\n",
      "agent1 return is:  0.9384833055604576\n",
      "agent2 return is:  1.5812583102506306\n",
      "Batch 363 finished:\n",
      "agent1 return is:  0.8171500374288321\n",
      "agent2 return is:  1.7862062170636035\n",
      "Batch 364 finished:\n",
      "agent1 return is:  0.6546997154841914\n",
      "agent2 return is:  1.8340250794056392\n",
      "Batch 365 finished:\n",
      "agent1 return is:  0.7541029982793792\n",
      "agent2 return is:  1.658391309517082\n",
      "Batch 366 finished:\n",
      "agent1 return is:  0.8410718734783235\n",
      "agent2 return is:  1.4623867582840182\n",
      "Batch 367 finished:\n",
      "agent1 return is:  0.833956893298449\n",
      "agent2 return is:  1.8179450474627836\n",
      "Batch 368 finished:\n",
      "agent1 return is:  0.7359385154298821\n",
      "agent2 return is:  1.8984882817802213\n",
      "Batch 369 finished:\n",
      "agent1 return is:  0.8099883510866275\n",
      "agent2 return is:  1.509551442852716\n",
      "Batch 370 finished:\n",
      "agent1 return is:  0.30700340146595345\n",
      "agent2 return is:  1.6307576791253258\n",
      "Batch 371 finished:\n",
      "agent1 return is:  0.6932335365999639\n",
      "agent2 return is:  1.3926048188957192\n",
      "Batch 372 finished:\n",
      "agent1 return is:  0.9275081216154779\n",
      "agent2 return is:  1.6523726152000673\n",
      "Batch 373 finished:\n",
      "agent1 return is:  0.8938151012348001\n",
      "agent2 return is:  1.7549824378869907\n",
      "Batch 374 finished:\n",
      "agent1 return is:  0.950639345460634\n",
      "agent2 return is:  1.595879233614848\n",
      "Batch 375 finished:\n",
      "agent1 return is:  0.9355335122112716\n",
      "agent2 return is:  1.9280073352192366\n",
      "Batch 376 finished:\n",
      "agent1 return is:  0.7972810594516863\n",
      "agent2 return is:  1.5492374911481734\n",
      "Batch 377 finished:\n",
      "agent1 return is:  0.9621606126872178\n",
      "agent2 return is:  2.0578768261683935\n",
      "Batch 378 finished:\n",
      "agent1 return is:  0.6775845017764199\n",
      "agent2 return is:  2.051676184184464\n",
      "Batch 379 finished:\n",
      "agent1 return is:  0.7992862501010716\n",
      "agent2 return is:  2.24153510475597\n",
      "Batch 380 finished:\n",
      "agent1 return is:  0.9743445738569092\n",
      "agent2 return is:  2.140587097599863\n",
      "Batch 381 finished:\n",
      "agent1 return is:  0.9615646140300836\n",
      "agent2 return is:  2.1959445542517293\n",
      "Batch 382 finished:\n",
      "agent1 return is:  0.8615889864593123\n",
      "agent2 return is:  1.9029852880765346\n",
      "Batch 383 finished:\n",
      "agent1 return is:  0.9308321098947065\n",
      "agent2 return is:  2.521917677570883\n",
      "Batch 384 finished:\n",
      "agent1 return is:  1.0434123241866113\n",
      "agent2 return is:  2.331449189379252\n",
      "Batch 385 finished:\n",
      "agent1 return is:  1.0821831374383968\n",
      "agent2 return is:  2.255804159122997\n",
      "Batch 386 finished:\n",
      "agent1 return is:  1.065124110596835\n",
      "agent2 return is:  2.5761207855350428\n",
      "Batch 387 finished:\n",
      "agent1 return is:  0.9961750118189222\n",
      "agent2 return is:  2.265579532028454\n",
      "Batch 388 finished:\n",
      "agent1 return is:  1.2144509155721726\n",
      "agent2 return is:  2.380850708294373\n",
      "Batch 389 finished:\n",
      "agent1 return is:  1.0571302074227924\n",
      "agent2 return is:  2.4148996611588895\n",
      "Batch 390 finished:\n",
      "agent1 return is:  1.0717881770104587\n",
      "agent2 return is:  2.308505263424335\n",
      "Batch 391 finished:\n",
      "agent1 return is:  1.0871375824459832\n",
      "agent2 return is:  2.4407291318952304\n",
      "Batch 392 finished:\n",
      "agent1 return is:  0.8903685516199513\n",
      "agent2 return is:  2.685134236219052\n",
      "Batch 393 finished:\n",
      "agent1 return is:  0.8291557607090962\n",
      "agent2 return is:  2.3870166230857564\n",
      "Batch 394 finished:\n",
      "agent1 return is:  1.1556781952869097\n",
      "agent2 return is:  2.2220587255973623\n",
      "Batch 395 finished:\n",
      "agent1 return is:  1.1926763603089752\n",
      "agent2 return is:  2.4299649200600792\n",
      "Batch 396 finished:\n",
      "agent1 return is:  1.078344865325076\n",
      "agent2 return is:  2.5660484048812817\n",
      "Batch 397 finished:\n",
      "agent1 return is:  1.197344700295338\n",
      "agent2 return is:  2.4805718147299176\n",
      "Batch 398 finished:\n",
      "agent1 return is:  1.2423713211361194\n",
      "agent2 return is:  2.7913021538061447\n",
      "Batch 399 finished:\n",
      "agent1 return is:  1.3167812679071271\n",
      "agent2 return is:  2.459499221512297\n",
      "Batch 400 finished:\n",
      "agent1 return is:  1.387010767174594\n",
      "agent2 return is:  2.5811352186605507\n",
      "Batch 401 finished:\n",
      "agent1 return is:  1.4217183954613395\n",
      "agent2 return is:  3.0390705545329375\n",
      "Batch 402 finished:\n",
      "agent1 return is:  1.3986920952213477\n",
      "agent2 return is:  2.4239015549256617\n",
      "Batch 403 finished:\n",
      "agent1 return is:  1.1080238794473534\n",
      "agent2 return is:  2.7671286877495787\n",
      "Batch 404 finished:\n",
      "agent1 return is:  1.6161406840072958\n",
      "agent2 return is:  3.0332639785162874\n",
      "Batch 405 finished:\n",
      "agent1 return is:  1.1446714326672107\n",
      "agent2 return is:  2.8738494490770012\n",
      "Batch 406 finished:\n",
      "agent1 return is:  1.6581822333190068\n",
      "agent2 return is:  3.0105764666276054\n",
      "Batch 407 finished:\n",
      "agent1 return is:  1.4970136496202773\n",
      "agent2 return is:  3.633087147831897\n",
      "Batch 408 finished:\n",
      "agent1 return is:  1.597816184672702\n",
      "agent2 return is:  3.3541247812454067\n",
      "Batch 409 finished:\n",
      "agent1 return is:  1.3035969750473402\n",
      "agent2 return is:  3.1447625044831398\n",
      "Batch 410 finished:\n",
      "agent1 return is:  1.4329507263751147\n",
      "agent2 return is:  3.736117845900697\n",
      "Batch 411 finished:\n",
      "agent1 return is:  1.5680496161585644\n",
      "agent2 return is:  3.635721977425434\n",
      "Batch 412 finished:\n",
      "agent1 return is:  1.7392452976485542\n",
      "agent2 return is:  3.758744782085097\n",
      "Batch 413 finished:\n",
      "agent1 return is:  1.0187249077383207\n",
      "agent2 return is:  3.700127608610409\n",
      "Batch 414 finished:\n",
      "agent1 return is:  1.5433499761455463\n",
      "agent2 return is:  3.806237080179539\n",
      "Batch 415 finished:\n",
      "agent1 return is:  1.613370786493336\n",
      "agent2 return is:  3.751754756571021\n",
      "Batch 416 finished:\n",
      "agent1 return is:  1.383570074937768\n",
      "agent2 return is:  3.80165050223096\n",
      "Batch 417 finished:\n",
      "agent1 return is:  1.3172210388087773\n",
      "agent2 return is:  3.5757714560143903\n",
      "Batch 418 finished:\n",
      "agent1 return is:  1.1882379780914396\n",
      "agent2 return is:  3.582670066567513\n",
      "Batch 419 finished:\n",
      "agent1 return is:  1.436126930465904\n",
      "agent2 return is:  3.437013593930555\n",
      "Batch 420 finished:\n",
      "agent1 return is:  0.9204855273357326\n",
      "agent2 return is:  3.5241306560276113\n",
      "Batch 421 finished:\n",
      "agent1 return is:  1.527174813900402\n",
      "agent2 return is:  3.7292427910596655\n",
      "Batch 422 finished:\n",
      "agent1 return is:  1.5102897712467078\n",
      "agent2 return is:  3.054654147645992\n",
      "Batch 423 finished:\n",
      "agent1 return is:  1.5279996506184987\n",
      "agent2 return is:  2.670995307809663\n",
      "Batch 424 finished:\n",
      "agent1 return is:  1.3013631817449198\n",
      "agent2 return is:  3.470811981081531\n",
      "Batch 425 finished:\n",
      "agent1 return is:  1.448401315059701\n",
      "agent2 return is:  3.3327700901548782\n",
      "Batch 426 finished:\n",
      "agent1 return is:  1.4617815918069779\n",
      "agent2 return is:  3.3040772410307238\n",
      "Batch 427 finished:\n",
      "agent1 return is:  1.4221668888347638\n",
      "agent2 return is:  3.1867485867854035\n",
      "Batch 428 finished:\n",
      "agent1 return is:  1.5937660791597215\n",
      "agent2 return is:  3.5096655050038192\n",
      "Batch 429 finished:\n",
      "agent1 return is:  1.6627008558892298\n",
      "agent2 return is:  3.5566553275326647\n",
      "Batch 430 finished:\n",
      "agent1 return is:  1.3918024361507628\n",
      "agent2 return is:  3.3240597090010473\n",
      "Batch 431 finished:\n",
      "agent1 return is:  1.3387122796082411\n",
      "agent2 return is:  3.330474271576427\n",
      "Batch 432 finished:\n",
      "agent1 return is:  1.3549475679589351\n",
      "agent2 return is:  3.5037538636215637\n",
      "Batch 433 finished:\n",
      "agent1 return is:  1.4563352061919521\n",
      "agent2 return is:  3.3875217551958188\n",
      "Batch 434 finished:\n",
      "agent1 return is:  1.6408306653275766\n",
      "agent2 return is:  3.3722151292779308\n",
      "Batch 435 finished:\n",
      "agent1 return is:  1.5784014924147358\n",
      "agent2 return is:  3.479530637975402\n",
      "Batch 436 finished:\n",
      "agent1 return is:  1.561191696747298\n",
      "agent2 return is:  3.598108464753639\n",
      "Batch 437 finished:\n",
      "agent1 return is:  1.6845726841092863\n",
      "agent2 return is:  3.801530657464684\n",
      "Batch 438 finished:\n",
      "agent1 return is:  1.4922457847367783\n",
      "agent2 return is:  3.592573535896843\n",
      "Batch 439 finished:\n",
      "agent1 return is:  1.6394661702981792\n",
      "agent2 return is:  3.3603093228523813\n",
      "Batch 440 finished:\n",
      "agent1 return is:  1.2921901720289304\n",
      "agent2 return is:  3.5081213340904256\n",
      "Batch 441 finished:\n",
      "agent1 return is:  1.8842204584127094\n",
      "agent2 return is:  3.7201030061577267\n",
      "Batch 442 finished:\n",
      "agent1 return is:  1.8411531820082614\n",
      "agent2 return is:  3.936478892768952\n",
      "Batch 443 finished:\n",
      "agent1 return is:  1.4987688310167187\n",
      "agent2 return is:  3.871373035015873\n",
      "Batch 444 finished:\n",
      "agent1 return is:  1.6388856769614062\n",
      "agent2 return is:  3.721263464201952\n",
      "Batch 445 finished:\n",
      "agent1 return is:  1.4819308106377413\n",
      "agent2 return is:  4.019019173892893\n",
      "Batch 446 finished:\n",
      "agent1 return is:  1.7230759422666955\n",
      "agent2 return is:  3.8816730858387936\n",
      "Batch 447 finished:\n",
      "agent1 return is:  1.4779800935303888\n",
      "agent2 return is:  3.557708627298677\n",
      "Batch 448 finished:\n",
      "agent1 return is:  1.48242417706869\n",
      "agent2 return is:  4.281214821808989\n",
      "Batch 449 finished:\n",
      "agent1 return is:  1.5977726228867333\n",
      "agent2 return is:  4.02242536988623\n",
      "Batch 450 finished:\n",
      "agent1 return is:  1.6153387658436809\n",
      "agent2 return is:  4.202043135464489\n",
      "Batch 451 finished:\n",
      "agent1 return is:  1.5008138044423687\n",
      "agent2 return is:  4.386618722068859\n",
      "Batch 452 finished:\n",
      "agent1 return is:  1.4206616342938299\n",
      "agent2 return is:  4.323345826682553\n",
      "Batch 453 finished:\n",
      "agent1 return is:  1.6643822714122345\n",
      "agent2 return is:  4.172471585123258\n",
      "Batch 454 finished:\n",
      "agent1 return is:  1.3471082720976582\n",
      "agent2 return is:  4.302208223092167\n",
      "Batch 455 finished:\n",
      "agent1 return is:  1.3061618171457177\n",
      "agent2 return is:  4.3352654685770435\n",
      "Batch 456 finished:\n",
      "agent1 return is:  1.4824816961888811\n",
      "agent2 return is:  4.314515692069239\n",
      "Batch 457 finished:\n",
      "agent1 return is:  1.0634024963108393\n",
      "agent2 return is:  4.4495797514881525\n",
      "Batch 458 finished:\n",
      "agent1 return is:  1.3608770353583153\n",
      "agent2 return is:  4.498659714229603\n",
      "Batch 459 finished:\n",
      "agent1 return is:  1.305775254172196\n",
      "agent2 return is:  4.414981585155493\n",
      "Batch 460 finished:\n",
      "agent1 return is:  1.2036324355045136\n",
      "agent2 return is:  4.584078495383531\n",
      "Batch 461 finished:\n",
      "agent1 return is:  1.6194278547428125\n",
      "agent2 return is:  4.461981717017794\n",
      "Batch 462 finished:\n",
      "agent1 return is:  0.9933426218312421\n",
      "agent2 return is:  4.785517224730478\n",
      "Batch 463 finished:\n",
      "agent1 return is:  1.5842360394381683\n",
      "agent2 return is:  4.717389404445581\n",
      "Batch 464 finished:\n",
      "agent1 return is:  1.3338827213813786\n",
      "agent2 return is:  4.836882030626942\n",
      "Batch 465 finished:\n",
      "agent1 return is:  1.4553526738463267\n",
      "agent2 return is:  5.128103389106001\n",
      "Batch 466 finished:\n",
      "agent1 return is:  1.5663842507492127\n",
      "agent2 return is:  5.110313605146326\n",
      "Batch 467 finished:\n",
      "agent1 return is:  1.243399041815159\n",
      "agent2 return is:  4.768837259443874\n",
      "Batch 468 finished:\n",
      "agent1 return is:  1.4032328842125754\n",
      "agent2 return is:  4.828146144196504\n",
      "Batch 469 finished:\n",
      "agent1 return is:  1.1943876921829673\n",
      "agent2 return is:  4.815877424457726\n",
      "Batch 470 finished:\n",
      "agent1 return is:  1.4712981454689977\n",
      "agent2 return is:  4.947433471806463\n",
      "Batch 471 finished:\n",
      "agent1 return is:  1.1784886728740098\n",
      "agent2 return is:  5.1135350070791015\n",
      "Batch 472 finished:\n",
      "agent1 return is:  1.4025818658995828\n",
      "agent2 return is:  4.745008672200775\n",
      "Batch 473 finished:\n",
      "agent1 return is:  1.2091940532833467\n",
      "agent2 return is:  4.9142629911045015\n",
      "Batch 474 finished:\n",
      "agent1 return is:  1.4888461019279742\n",
      "agent2 return is:  4.785557474139548\n",
      "Batch 475 finished:\n",
      "agent1 return is:  1.3374589375007258\n",
      "agent2 return is:  5.09155496684077\n",
      "Batch 476 finished:\n",
      "agent1 return is:  1.4567842734308583\n",
      "agent2 return is:  5.097371398265612\n",
      "Batch 477 finished:\n",
      "agent1 return is:  1.4785569305685424\n",
      "agent2 return is:  5.314781916703009\n",
      "Batch 478 finished:\n",
      "agent1 return is:  1.384715843901823\n",
      "agent2 return is:  5.0734809269345975\n",
      "Batch 479 finished:\n",
      "agent1 return is:  1.3942625194796754\n",
      "agent2 return is:  5.264953563251252\n",
      "Batch 480 finished:\n",
      "agent1 return is:  1.2609019753944086\n",
      "agent2 return is:  4.898393888537083\n",
      "Batch 481 finished:\n",
      "agent1 return is:  1.489958107766364\n",
      "agent2 return is:  5.060143378989283\n",
      "Batch 482 finished:\n",
      "agent1 return is:  1.3382911131046127\n",
      "agent2 return is:  5.100618155862523\n",
      "Batch 483 finished:\n",
      "agent1 return is:  1.4122002313575537\n",
      "agent2 return is:  4.925021850836545\n",
      "Batch 484 finished:\n",
      "agent1 return is:  1.204132440868096\n",
      "agent2 return is:  4.933480207700544\n",
      "Batch 485 finished:\n",
      "agent1 return is:  1.3004649501157077\n",
      "agent2 return is:  4.923140325283752\n",
      "Batch 486 finished:\n",
      "agent1 return is:  1.4748078277660912\n",
      "agent2 return is:  4.507279747091966\n",
      "Batch 487 finished:\n",
      "agent1 return is:  1.4389805106218714\n",
      "agent2 return is:  5.031676475814384\n",
      "Batch 488 finished:\n",
      "agent1 return is:  1.1560863218328246\n",
      "agent2 return is:  5.204194227431515\n",
      "Batch 489 finished:\n",
      "agent1 return is:  1.4946562026874997\n",
      "agent2 return is:  5.0461465232623155\n",
      "Batch 490 finished:\n",
      "agent1 return is:  1.2636635100384213\n",
      "agent2 return is:  5.268483698205271\n",
      "Batch 491 finished:\n",
      "agent1 return is:  1.0801950645120562\n",
      "agent2 return is:  5.201276382071457\n",
      "Batch 492 finished:\n",
      "agent1 return is:  1.3882221023077506\n",
      "agent2 return is:  5.1288328795056675\n",
      "Batch 493 finished:\n",
      "agent1 return is:  1.3979078027361225\n",
      "agent2 return is:  5.163686448876257\n",
      "Batch 494 finished:\n",
      "agent1 return is:  1.0308349447275313\n",
      "agent2 return is:  4.812329697392534\n",
      "Batch 495 finished:\n",
      "agent1 return is:  1.22453880592387\n",
      "agent2 return is:  4.942128800080395\n",
      "Batch 496 finished:\n",
      "agent1 return is:  1.14411748051874\n",
      "agent2 return is:  5.056374669874092\n",
      "Batch 497 finished:\n",
      "agent1 return is:  1.373420034851601\n",
      "agent2 return is:  5.2831059165731755\n",
      "Batch 498 finished:\n",
      "agent1 return is:  1.2906506897766894\n",
      "agent2 return is:  5.013832128671142\n",
      "Batch 499 finished:\n",
      "agent1 return is:  1.1788298963793649\n",
      "agent2 return is:  5.302752849388714\n",
      "Batch 500 finished:\n",
      "agent1 return is:  1.2569335881119281\n",
      "agent2 return is:  4.996941335245015\n",
      "Batch 501 finished:\n",
      "agent1 return is:  1.3101895971604112\n",
      "agent2 return is:  5.078440075912941\n",
      "Batch 502 finished:\n",
      "agent1 return is:  1.302919504066364\n",
      "agent2 return is:  5.141587718444974\n",
      "Batch 503 finished:\n",
      "agent1 return is:  1.2966780892359235\n",
      "agent2 return is:  5.255027429368788\n",
      "Batch 504 finished:\n",
      "agent1 return is:  1.0295657212729044\n",
      "agent2 return is:  5.513179881637949\n",
      "Batch 505 finished:\n",
      "agent1 return is:  1.3142691282693688\n",
      "agent2 return is:  5.274044831936016\n",
      "Batch 506 finished:\n",
      "agent1 return is:  1.0662240159744703\n",
      "agent2 return is:  5.399833222070871\n",
      "Batch 507 finished:\n",
      "agent1 return is:  1.2987198087154006\n",
      "agent2 return is:  5.254356611716956\n",
      "Batch 508 finished:\n",
      "agent1 return is:  1.3161095933611748\n",
      "agent2 return is:  5.44176555824308\n",
      "Batch 509 finished:\n",
      "agent1 return is:  1.3440038401323873\n",
      "agent2 return is:  5.48077375323932\n",
      "Batch 510 finished:\n",
      "agent1 return is:  1.3960552722248547\n",
      "agent2 return is:  5.4992917937105315\n",
      "Batch 511 finished:\n",
      "agent1 return is:  1.2961658998417775\n",
      "agent2 return is:  5.4698969080838555\n",
      "Batch 512 finished:\n",
      "agent1 return is:  1.2611394761263206\n",
      "agent2 return is:  5.670282037084507\n",
      "Batch 513 finished:\n",
      "agent1 return is:  1.1723652484822145\n",
      "agent2 return is:  5.626907773705192\n",
      "Batch 514 finished:\n",
      "agent1 return is:  1.0823688391198638\n",
      "agent2 return is:  5.9648084012579545\n",
      "Batch 515 finished:\n",
      "agent1 return is:  1.2756793598275105\n",
      "agent2 return is:  5.836486624844417\n",
      "Batch 516 finished:\n",
      "agent1 return is:  1.15760825311627\n",
      "agent2 return is:  5.243602829530198\n",
      "Batch 517 finished:\n",
      "agent1 return is:  1.2999922673017017\n",
      "agent2 return is:  5.857895191238532\n",
      "Batch 518 finished:\n",
      "agent1 return is:  1.3440011848707745\n",
      "agent2 return is:  5.784292761990067\n",
      "Batch 519 finished:\n",
      "agent1 return is:  1.3043651838605315\n",
      "agent2 return is:  5.8095128365340525\n",
      "Batch 520 finished:\n",
      "agent1 return is:  1.1582305764208762\n",
      "agent2 return is:  5.7527968218133125\n",
      "Batch 521 finished:\n",
      "agent1 return is:  1.3473293726896882\n",
      "agent2 return is:  5.958765240232914\n",
      "Batch 522 finished:\n",
      "agent1 return is:  1.3019053881170972\n",
      "agent2 return is:  5.997282465137449\n",
      "Batch 523 finished:\n",
      "agent1 return is:  1.43958535655399\n",
      "agent2 return is:  6.296525498606181\n",
      "Batch 524 finished:\n",
      "agent1 return is:  1.300287058860262\n",
      "agent2 return is:  6.121140316050088\n",
      "Batch 525 finished:\n",
      "agent1 return is:  1.046948517372961\n",
      "agent2 return is:  6.252580116458418\n",
      "Batch 526 finished:\n",
      "agent1 return is:  1.2078398879891257\n",
      "agent2 return is:  6.048340215057374\n",
      "Batch 527 finished:\n",
      "agent1 return is:  1.2024174778318852\n",
      "agent2 return is:  5.862933616937809\n",
      "Batch 528 finished:\n",
      "agent1 return is:  1.2158373275238614\n",
      "agent2 return is:  5.9660732355238295\n",
      "Batch 529 finished:\n",
      "agent1 return is:  1.180740381498986\n",
      "agent2 return is:  5.77444188592891\n",
      "Batch 530 finished:\n",
      "agent1 return is:  1.2828628567559621\n",
      "agent2 return is:  5.922078269301524\n",
      "Batch 531 finished:\n",
      "agent1 return is:  1.3026232724490496\n",
      "agent2 return is:  6.136432413653167\n",
      "Batch 532 finished:\n",
      "agent1 return is:  1.4212764868584398\n",
      "agent2 return is:  6.265543754528783\n",
      "Batch 533 finished:\n",
      "agent1 return is:  1.3376098877097908\n",
      "agent2 return is:  6.3731364331200115\n",
      "Batch 534 finished:\n",
      "agent1 return is:  1.4163444491492154\n",
      "agent2 return is:  6.029424485079259\n",
      "Batch 535 finished:\n",
      "agent1 return is:  1.4613673810286025\n",
      "agent2 return is:  6.600012510298173\n",
      "Batch 536 finished:\n",
      "agent1 return is:  1.2574836936604563\n",
      "agent2 return is:  5.9858587528522715\n",
      "Batch 537 finished:\n",
      "agent1 return is:  1.291000662129652\n",
      "agent2 return is:  6.060901757652346\n",
      "Batch 538 finished:\n",
      "agent1 return is:  1.4061670216495807\n",
      "agent2 return is:  6.235733299006492\n",
      "Batch 539 finished:\n",
      "agent1 return is:  1.0676829433969646\n",
      "agent2 return is:  6.271448948202972\n",
      "Batch 540 finished:\n",
      "agent1 return is:  1.3999533949198995\n",
      "agent2 return is:  6.3335368991004835\n",
      "Batch 541 finished:\n",
      "agent1 return is:  1.3174325728554677\n",
      "agent2 return is:  6.157940637994409\n",
      "Batch 542 finished:\n",
      "agent1 return is:  1.3717005508543862\n",
      "agent2 return is:  6.264534991572065\n",
      "Batch 543 finished:\n",
      "agent1 return is:  1.3146321887709664\n",
      "agent2 return is:  6.358646149943215\n",
      "Batch 544 finished:\n",
      "agent1 return is:  1.3535178042350458\n",
      "agent2 return is:  6.324225524891564\n",
      "Batch 545 finished:\n",
      "agent1 return is:  1.0699378158362134\n",
      "agent2 return is:  6.432020534526197\n",
      "Batch 546 finished:\n",
      "agent1 return is:  1.3188454974984007\n",
      "agent2 return is:  6.483318541982074\n",
      "Batch 547 finished:\n",
      "agent1 return is:  1.2867347293861897\n",
      "agent2 return is:  6.374113704318863\n",
      "Batch 548 finished:\n",
      "agent1 return is:  1.4725696900502863\n",
      "agent2 return is:  6.110392100293311\n",
      "Batch 549 finished:\n",
      "agent1 return is:  1.4835205623293501\n",
      "agent2 return is:  6.402310920443643\n",
      "Batch 550 finished:\n",
      "agent1 return is:  1.5091596929701203\n",
      "agent2 return is:  6.234897108314106\n",
      "Batch 551 finished:\n",
      "agent1 return is:  1.55728232689313\n",
      "agent2 return is:  6.423779143082415\n",
      "Batch 552 finished:\n",
      "agent1 return is:  1.5587653850875598\n",
      "agent2 return is:  6.511856529822992\n",
      "Batch 553 finished:\n",
      "agent1 return is:  1.4576419120415576\n",
      "agent2 return is:  6.712581009821413\n",
      "Batch 554 finished:\n",
      "agent1 return is:  1.4880681340170723\n",
      "agent2 return is:  6.502451799225211\n",
      "Batch 555 finished:\n",
      "agent1 return is:  1.5724562911586373\n",
      "agent2 return is:  6.53129140284625\n",
      "Batch 556 finished:\n",
      "agent1 return is:  1.4751073844514764\n",
      "agent2 return is:  6.724871128248817\n",
      "Batch 557 finished:\n",
      "agent1 return is:  1.7335660555195922\n",
      "agent2 return is:  6.564811581545846\n",
      "Batch 558 finished:\n",
      "agent1 return is:  1.735236349805619\n",
      "agent2 return is:  6.793528836384811\n",
      "Batch 559 finished:\n",
      "agent1 return is:  1.7427264782966088\n",
      "agent2 return is:  6.351464907399863\n",
      "Batch 560 finished:\n",
      "agent1 return is:  1.6190741321009647\n",
      "agent2 return is:  6.6149273331304315\n",
      "Batch 561 finished:\n",
      "agent1 return is:  1.5356834315180683\n",
      "agent2 return is:  6.842456550978293\n",
      "Batch 562 finished:\n",
      "agent1 return is:  1.58102425249825\n",
      "agent2 return is:  6.700256829838131\n",
      "Batch 563 finished:\n",
      "agent1 return is:  1.568474992478212\n",
      "agent2 return is:  6.555669990271245\n",
      "Batch 564 finished:\n",
      "agent1 return is:  1.6405999194420526\n",
      "agent2 return is:  6.875677530262372\n",
      "Batch 565 finished:\n",
      "agent1 return is:  1.4733703877095716\n",
      "agent2 return is:  6.921175383697768\n",
      "Batch 566 finished:\n",
      "agent1 return is:  1.5950025864400361\n",
      "agent2 return is:  7.011368427122518\n",
      "Batch 567 finished:\n",
      "agent1 return is:  1.6927057480337913\n",
      "agent2 return is:  7.059604728369228\n",
      "Batch 568 finished:\n",
      "agent1 return is:  1.2279165774490428\n",
      "agent2 return is:  7.097065118492161\n",
      "Batch 569 finished:\n",
      "agent1 return is:  1.7497989559591083\n",
      "agent2 return is:  6.916503842572341\n",
      "Batch 570 finished:\n",
      "agent1 return is:  1.6461152901540141\n",
      "agent2 return is:  7.253920271407649\n",
      "Batch 571 finished:\n",
      "agent1 return is:  1.544101542700357\n",
      "agent2 return is:  6.440193195341333\n",
      "Batch 572 finished:\n",
      "agent1 return is:  1.5598019143232205\n",
      "agent2 return is:  6.864491151173134\n",
      "Batch 573 finished:\n",
      "agent1 return is:  1.6277719851618044\n",
      "agent2 return is:  6.6960464955859145\n",
      "Batch 574 finished:\n",
      "agent1 return is:  1.3910604948631367\n",
      "agent2 return is:  6.662544067078459\n",
      "Batch 575 finished:\n",
      "agent1 return is:  1.6503741825341962\n",
      "agent2 return is:  6.9287586387387465\n",
      "Batch 576 finished:\n",
      "agent1 return is:  1.6742706377282608\n",
      "agent2 return is:  6.801225976048031\n",
      "Batch 577 finished:\n",
      "agent1 return is:  1.3390675689010014\n",
      "agent2 return is:  6.917206941111806\n",
      "Batch 578 finished:\n",
      "agent1 return is:  1.4947014066351236\n",
      "agent2 return is:  7.053118697206411\n",
      "Batch 579 finished:\n",
      "agent1 return is:  1.4998828490633678\n",
      "agent2 return is:  7.016873231021692\n",
      "Batch 580 finished:\n",
      "agent1 return is:  1.5639996914718541\n",
      "agent2 return is:  6.6865274876645\n",
      "Batch 581 finished:\n",
      "agent1 return is:  1.4285236111750674\n",
      "agent2 return is:  6.211016464267901\n",
      "Batch 582 finished:\n",
      "agent1 return is:  1.735686299770327\n",
      "agent2 return is:  6.529901350796224\n",
      "Batch 583 finished:\n",
      "agent1 return is:  1.4374091332189538\n",
      "agent2 return is:  6.744049360113522\n",
      "Batch 584 finished:\n",
      "agent1 return is:  1.4396491871306\n",
      "agent2 return is:  6.768146893953626\n",
      "Batch 585 finished:\n",
      "agent1 return is:  1.55006839276498\n",
      "agent2 return is:  6.5786941453126975\n",
      "Batch 586 finished:\n",
      "agent1 return is:  1.4692489809106417\n",
      "agent2 return is:  7.122473641740908\n",
      "Batch 587 finished:\n",
      "agent1 return is:  1.340083810289544\n",
      "agent2 return is:  6.770288218604778\n",
      "Batch 588 finished:\n",
      "agent1 return is:  1.5003113440920846\n",
      "agent2 return is:  7.0512891315691135\n",
      "Batch 589 finished:\n",
      "agent1 return is:  1.3520014511072602\n",
      "agent2 return is:  7.064656538105728\n",
      "Batch 590 finished:\n",
      "agent1 return is:  1.2990408235557975\n",
      "agent2 return is:  6.981435478008605\n",
      "Batch 591 finished:\n",
      "agent1 return is:  1.3994384900450316\n",
      "agent2 return is:  6.783601828749813\n",
      "Batch 592 finished:\n",
      "agent1 return is:  1.3686753215779128\n",
      "agent2 return is:  6.76127275819813\n",
      "Batch 593 finished:\n",
      "agent1 return is:  1.0254281909727356\n",
      "agent2 return is:  6.484099859135483\n",
      "Batch 594 finished:\n",
      "agent1 return is:  1.3989376320594327\n",
      "agent2 return is:  6.635281763849309\n",
      "Batch 595 finished:\n",
      "agent1 return is:  1.3517704636804655\n",
      "agent2 return is:  7.150811324794871\n",
      "Batch 596 finished:\n",
      "agent1 return is:  1.4268593153817877\n",
      "agent2 return is:  7.116110936033067\n",
      "Batch 597 finished:\n",
      "agent1 return is:  1.3252952147000818\n",
      "agent2 return is:  6.933704916414525\n",
      "Batch 598 finished:\n",
      "agent1 return is:  1.3618562277260264\n",
      "agent2 return is:  6.578616882582477\n",
      "Batch 599 finished:\n",
      "agent1 return is:  1.364646739913129\n",
      "agent2 return is:  6.623675288207362\n",
      "Batch 600 finished:\n",
      "agent1 return is:  1.3027164406896747\n",
      "agent2 return is:  7.337090951944256\n",
      "Batch 601 finished:\n",
      "agent1 return is:  1.5950231183969086\n",
      "agent2 return is:  7.11511961816916\n",
      "Batch 602 finished:\n",
      "agent1 return is:  1.6193454761282953\n",
      "agent2 return is:  6.992305214185338\n",
      "Batch 603 finished:\n",
      "agent1 return is:  1.5211055085111647\n",
      "agent2 return is:  6.977559719758686\n",
      "Batch 604 finished:\n",
      "agent1 return is:  1.3389349432205466\n",
      "agent2 return is:  7.298353325154256\n",
      "Batch 605 finished:\n",
      "agent1 return is:  1.4277341596216997\n",
      "agent2 return is:  7.419164597318146\n",
      "Batch 606 finished:\n",
      "agent1 return is:  1.3304473480742574\n",
      "agent2 return is:  7.255130049228463\n",
      "Batch 607 finished:\n",
      "agent1 return is:  1.1816563063398833\n",
      "agent2 return is:  7.116184844820821\n",
      "Batch 608 finished:\n",
      "agent1 return is:  1.2014647194549208\n",
      "agent2 return is:  7.411479869035264\n",
      "Batch 609 finished:\n",
      "agent1 return is:  1.1175554077032492\n",
      "agent2 return is:  7.447913490057973\n",
      "Batch 610 finished:\n",
      "agent1 return is:  1.3133803779827233\n",
      "agent2 return is:  7.661990331348883\n",
      "Batch 611 finished:\n",
      "agent1 return is:  1.3958623424793146\n",
      "agent2 return is:  7.482810612849907\n",
      "Batch 612 finished:\n",
      "agent1 return is:  1.2721872514664323\n",
      "agent2 return is:  7.7344369594201545\n",
      "Batch 613 finished:\n",
      "agent1 return is:  1.2750872610095794\n",
      "agent2 return is:  7.86888261860139\n",
      "Batch 614 finished:\n",
      "agent1 return is:  1.1467904491251646\n",
      "agent2 return is:  7.752775504790084\n",
      "Batch 615 finished:\n",
      "agent1 return is:  1.2065702454189275\n",
      "agent2 return is:  7.441376783795366\n",
      "Batch 616 finished:\n",
      "agent1 return is:  1.0378942457884415\n",
      "agent2 return is:  7.864370441995099\n",
      "Batch 617 finished:\n",
      "agent1 return is:  1.0968134534609726\n",
      "agent2 return is:  7.747251358189853\n",
      "Batch 618 finished:\n",
      "agent1 return is:  0.8913963223857388\n",
      "agent2 return is:  7.964781113800251\n",
      "Batch 619 finished:\n",
      "agent1 return is:  1.0206306861602101\n",
      "agent2 return is:  8.088965234793912\n",
      "Batch 620 finished:\n",
      "agent1 return is:  0.8236521430190711\n",
      "agent2 return is:  8.116097425093432\n",
      "Batch 621 finished:\n",
      "agent1 return is:  0.674157957330654\n",
      "agent2 return is:  8.041714790110277\n",
      "Batch 622 finished:\n",
      "agent1 return is:  0.9926446849187434\n",
      "agent2 return is:  8.142899533042083\n",
      "Batch 623 finished:\n",
      "agent1 return is:  0.994041014880183\n",
      "agent2 return is:  7.652151148952272\n",
      "Batch 624 finished:\n",
      "agent1 return is:  1.0823017389513399\n",
      "agent2 return is:  8.230024881021128\n",
      "Batch 625 finished:\n",
      "agent1 return is:  0.8221991044669227\n",
      "agent2 return is:  8.094122879726548\n",
      "Batch 626 finished:\n",
      "agent1 return is:  0.687619659384104\n",
      "agent2 return is:  8.301462424986077\n",
      "Batch 627 finished:\n",
      "agent1 return is:  0.8393691727391841\n",
      "agent2 return is:  8.075745565040446\n",
      "Batch 628 finished:\n",
      "agent1 return is:  0.6733966351886904\n",
      "agent2 return is:  8.422315128517711\n",
      "Batch 629 finished:\n",
      "agent1 return is:  0.8198742919839617\n",
      "agent2 return is:  8.284330420178188\n",
      "Batch 630 finished:\n",
      "agent1 return is:  0.7644219220946793\n",
      "agent2 return is:  8.102094633494364\n",
      "Batch 631 finished:\n",
      "agent1 return is:  0.6834334221691117\n",
      "agent2 return is:  8.281922686878369\n",
      "Batch 632 finished:\n",
      "agent1 return is:  0.7722827615506693\n",
      "agent2 return is:  8.31539870764286\n",
      "Batch 633 finished:\n",
      "agent1 return is:  0.9229227574831681\n",
      "agent2 return is:  7.979046103771948\n",
      "Batch 634 finished:\n",
      "agent1 return is:  1.0640899876786591\n",
      "agent2 return is:  7.9447053941435675\n",
      "Batch 635 finished:\n",
      "agent1 return is:  0.745283418425287\n",
      "agent2 return is:  8.162146890713181\n",
      "Batch 636 finished:\n",
      "agent1 return is:  0.7096095032583496\n",
      "agent2 return is:  8.366927283976331\n",
      "Batch 637 finished:\n",
      "agent1 return is:  0.6378414080257917\n",
      "agent2 return is:  8.24586893292923\n",
      "Batch 638 finished:\n",
      "agent1 return is:  0.9894357690676681\n",
      "agent2 return is:  8.257618079245372\n",
      "Batch 639 finished:\n",
      "agent1 return is:  0.7867288934020478\n",
      "agent2 return is:  8.276624094514904\n",
      "Batch 640 finished:\n",
      "agent1 return is:  0.8365519541290227\n",
      "agent2 return is:  8.22373064943217\n",
      "Batch 641 finished:\n",
      "agent1 return is:  0.8817461629221628\n",
      "agent2 return is:  8.093814717349911\n",
      "Batch 642 finished:\n",
      "agent1 return is:  0.651112937168085\n",
      "agent2 return is:  7.992541721170934\n",
      "Batch 643 finished:\n",
      "agent1 return is:  0.9713181962722902\n",
      "agent2 return is:  8.30442801631084\n",
      "Batch 644 finished:\n",
      "agent1 return is:  0.5294995598877813\n",
      "agent2 return is:  8.149868768271741\n",
      "Batch 645 finished:\n",
      "agent1 return is:  0.5951979749587921\n",
      "agent2 return is:  8.362700166490889\n",
      "Batch 646 finished:\n",
      "agent1 return is:  0.6604506600561232\n",
      "agent2 return is:  8.435940623653405\n",
      "Batch 647 finished:\n",
      "agent1 return is:  0.6777019502194916\n",
      "agent2 return is:  8.45541650895171\n",
      "Batch 648 finished:\n",
      "agent1 return is:  0.9621275453823008\n",
      "agent2 return is:  7.944073110985697\n",
      "Batch 649 finished:\n",
      "agent1 return is:  0.637029192945822\n",
      "agent2 return is:  8.580241296945658\n",
      "Batch 650 finished:\n",
      "agent1 return is:  0.813667102361036\n",
      "agent2 return is:  8.419732550376134\n",
      "Batch 651 finished:\n",
      "agent1 return is:  1.1028455190169566\n",
      "agent2 return is:  8.404708030030381\n",
      "Batch 652 finished:\n",
      "agent1 return is:  0.9001009417666178\n",
      "agent2 return is:  8.368578751217562\n",
      "Batch 653 finished:\n",
      "agent1 return is:  0.9516831589438894\n",
      "agent2 return is:  8.486690408943204\n",
      "Batch 654 finished:\n",
      "agent1 return is:  1.0914819436508703\n",
      "agent2 return is:  8.317069890176025\n",
      "Batch 655 finished:\n",
      "agent1 return is:  0.7864008738676502\n",
      "agent2 return is:  8.48641753674507\n",
      "Batch 656 finished:\n",
      "agent1 return is:  1.059802527725672\n",
      "agent2 return is:  8.484048614588595\n",
      "Batch 657 finished:\n",
      "agent1 return is:  0.8010113096598389\n",
      "agent2 return is:  8.01849842483556\n",
      "Batch 658 finished:\n",
      "agent1 return is:  1.067518820356854\n",
      "agent2 return is:  8.123858453698276\n",
      "Batch 659 finished:\n",
      "agent1 return is:  1.1421063343245494\n",
      "agent2 return is:  8.052193615546587\n",
      "Batch 660 finished:\n",
      "agent1 return is:  0.964689127953366\n",
      "agent2 return is:  7.83406879071447\n",
      "Batch 661 finished:\n",
      "agent1 return is:  0.9794743929102978\n",
      "agent2 return is:  7.963915281345057\n",
      "Batch 662 finished:\n",
      "agent1 return is:  0.7879994041270676\n",
      "agent2 return is:  8.29925822644644\n",
      "Batch 663 finished:\n",
      "agent1 return is:  0.8801909776832898\n",
      "agent2 return is:  8.216827751678117\n",
      "Batch 664 finished:\n",
      "agent1 return is:  0.787570861310261\n",
      "agent2 return is:  8.238413887688028\n",
      "Batch 665 finished:\n",
      "agent1 return is:  1.07807482039175\n",
      "agent2 return is:  8.215320081002183\n",
      "Batch 666 finished:\n",
      "agent1 return is:  1.115290603832642\n",
      "agent2 return is:  8.053048778142948\n",
      "Batch 667 finished:\n",
      "agent1 return is:  0.875206827810209\n",
      "agent2 return is:  8.181246695372023\n",
      "Batch 668 finished:\n",
      "agent1 return is:  0.7672301085239561\n",
      "agent2 return is:  8.172978474489815\n",
      "Batch 669 finished:\n",
      "agent1 return is:  1.0276881864361274\n",
      "agent2 return is:  7.994704452262223\n",
      "Batch 670 finished:\n",
      "agent1 return is:  1.1371223434806172\n",
      "agent2 return is:  7.851821569783004\n",
      "Batch 671 finished:\n",
      "agent1 return is:  1.0242855428047186\n",
      "agent2 return is:  7.928582231344878\n",
      "Batch 672 finished:\n",
      "agent1 return is:  0.8697991133485091\n",
      "agent2 return is:  7.940839886534826\n",
      "Batch 673 finished:\n",
      "agent1 return is:  1.1894377597166976\n",
      "agent2 return is:  7.789266609234191\n",
      "Batch 674 finished:\n",
      "agent1 return is:  1.1738483280377436\n",
      "agent2 return is:  7.750768375418501\n",
      "Batch 675 finished:\n",
      "agent1 return is:  1.2671728009814356\n",
      "agent2 return is:  8.002717113551885\n",
      "Batch 676 finished:\n",
      "agent1 return is:  1.1746915764433625\n",
      "agent2 return is:  7.951915007973531\n",
      "Batch 677 finished:\n",
      "agent1 return is:  1.2441385637068005\n",
      "agent2 return is:  7.88333441436243\n",
      "Batch 678 finished:\n",
      "agent1 return is:  1.3705008631692852\n",
      "agent2 return is:  7.8398357598152915\n",
      "Batch 679 finished:\n",
      "agent1 return is:  1.3269409538894519\n",
      "agent2 return is:  7.995346008302269\n",
      "Batch 680 finished:\n",
      "agent1 return is:  1.1654359301494728\n",
      "agent2 return is:  7.93165299644838\n",
      "Batch 681 finished:\n",
      "agent1 return is:  1.0439058118667282\n",
      "agent2 return is:  7.999353220487662\n",
      "Batch 682 finished:\n",
      "agent1 return is:  1.2771450426497781\n",
      "agent2 return is:  8.064908767289625\n",
      "Batch 683 finished:\n",
      "agent1 return is:  1.0736029162788607\n",
      "agent2 return is:  8.092604885267198\n",
      "Batch 684 finished:\n",
      "agent1 return is:  1.039261991113237\n",
      "agent2 return is:  8.019087345920543\n",
      "Batch 685 finished:\n",
      "agent1 return is:  1.1569496806195734\n",
      "agent2 return is:  7.8508271191393915\n",
      "Batch 686 finished:\n",
      "agent1 return is:  1.171526458333496\n",
      "agent2 return is:  8.01306746382449\n",
      "Batch 687 finished:\n",
      "agent1 return is:  1.1071352270454413\n",
      "agent2 return is:  8.024018531288117\n",
      "Batch 688 finished:\n",
      "agent1 return is:  0.9687618039582446\n",
      "agent2 return is:  7.99635632616946\n",
      "Batch 689 finished:\n",
      "agent1 return is:  1.3118385025309154\n",
      "agent2 return is:  8.069615614606784\n",
      "Batch 690 finished:\n",
      "agent1 return is:  1.0848128316534709\n",
      "agent2 return is:  8.052344700226236\n",
      "Batch 691 finished:\n",
      "agent1 return is:  1.1694827197570798\n",
      "agent2 return is:  8.019625651935865\n",
      "Batch 692 finished:\n",
      "agent1 return is:  1.2127965524882067\n",
      "agent2 return is:  8.015243106652317\n",
      "Batch 693 finished:\n",
      "agent1 return is:  0.8403080015345159\n",
      "agent2 return is:  7.99520526713511\n",
      "Batch 694 finished:\n",
      "agent1 return is:  1.0735118101350123\n",
      "agent2 return is:  7.957761395999071\n",
      "Batch 695 finished:\n",
      "agent1 return is:  1.009761529029165\n",
      "agent2 return is:  7.979943880199124\n",
      "Batch 696 finished:\n",
      "agent1 return is:  0.8809544620110799\n",
      "agent2 return is:  7.796675340455616\n",
      "Batch 697 finished:\n",
      "agent1 return is:  0.8222386859108308\n",
      "agent2 return is:  7.803281565859427\n",
      "Batch 698 finished:\n",
      "agent1 return is:  0.8586765816716131\n",
      "agent2 return is:  7.709783516741215\n",
      "Batch 699 finished:\n",
      "agent1 return is:  1.0298946457202964\n",
      "agent2 return is:  7.677385018684688\n",
      "Batch 700 finished:\n",
      "agent1 return is:  0.9708330566248096\n",
      "agent2 return is:  7.792467805606414\n",
      "Batch 701 finished:\n",
      "agent1 return is:  0.8022008609169623\n",
      "agent2 return is:  7.859394017002332\n",
      "Batch 702 finished:\n",
      "agent1 return is:  1.1140268137233236\n",
      "agent2 return is:  7.879805093465008\n",
      "Batch 703 finished:\n",
      "agent1 return is:  1.0687654227951544\n",
      "agent2 return is:  8.027227284782608\n",
      "Batch 704 finished:\n",
      "agent1 return is:  0.7947319765186938\n",
      "agent2 return is:  7.955544286015266\n",
      "Batch 705 finished:\n",
      "agent1 return is:  0.9692732322027907\n",
      "agent2 return is:  7.961776957244202\n",
      "Batch 706 finished:\n",
      "agent1 return is:  1.0056430095132969\n",
      "agent2 return is:  7.957282202326759\n",
      "Batch 707 finished:\n",
      "agent1 return is:  1.0833784797776131\n",
      "agent2 return is:  8.096389796993652\n",
      "Batch 708 finished:\n",
      "agent1 return is:  1.0595452506744607\n",
      "agent2 return is:  8.15254829246102\n",
      "Batch 709 finished:\n",
      "agent1 return is:  0.9438440586992342\n",
      "agent2 return is:  8.180505361274045\n",
      "Batch 710 finished:\n",
      "agent1 return is:  1.0660024188266093\n",
      "agent2 return is:  8.238427375719493\n",
      "Batch 711 finished:\n",
      "agent1 return is:  1.2805237819976827\n",
      "agent2 return is:  7.9742741163215225\n",
      "Batch 712 finished:\n",
      "agent1 return is:  1.2264865636495264\n",
      "agent2 return is:  8.09310084225506\n",
      "Batch 713 finished:\n",
      "agent1 return is:  1.030750149813728\n",
      "agent2 return is:  8.350206889805072\n",
      "Batch 714 finished:\n",
      "agent1 return is:  1.12392149744435\n",
      "agent2 return is:  8.433274666791132\n",
      "Batch 715 finished:\n",
      "agent1 return is:  0.9775316373001974\n",
      "agent2 return is:  8.344021759237833\n",
      "Batch 716 finished:\n",
      "agent1 return is:  0.8582114419320491\n",
      "agent2 return is:  8.05830658525574\n",
      "Batch 717 finished:\n",
      "agent1 return is:  1.0154962267450032\n",
      "agent2 return is:  8.207962254918044\n",
      "Batch 718 finished:\n",
      "agent1 return is:  1.2856969652718495\n",
      "agent2 return is:  8.259543554509918\n",
      "Batch 719 finished:\n",
      "agent1 return is:  1.1988164335867033\n",
      "agent2 return is:  8.244393703116646\n",
      "Batch 720 finished:\n",
      "agent1 return is:  0.9461890171018347\n",
      "agent2 return is:  8.264531088622896\n",
      "Batch 721 finished:\n",
      "agent1 return is:  1.1387676440541497\n",
      "agent2 return is:  8.302269886136344\n",
      "Batch 722 finished:\n",
      "agent1 return is:  0.8686707625390997\n",
      "agent2 return is:  8.305971966240431\n",
      "Batch 723 finished:\n",
      "agent1 return is:  1.0219259692383589\n",
      "agent2 return is:  8.250780276714721\n",
      "Batch 724 finished:\n",
      "agent1 return is:  0.935989872954889\n",
      "agent2 return is:  8.264768713035718\n",
      "Batch 725 finished:\n",
      "agent1 return is:  0.9170533531896099\n",
      "agent2 return is:  8.281447048459949\n",
      "Batch 726 finished:\n",
      "agent1 return is:  1.0080487173524253\n",
      "agent2 return is:  8.427672898266502\n",
      "Batch 727 finished:\n",
      "agent1 return is:  1.1014060226352202\n",
      "agent2 return is:  8.431086069580193\n",
      "Batch 728 finished:\n",
      "agent1 return is:  0.880551066690252\n",
      "agent2 return is:  8.480833406781962\n",
      "Batch 729 finished:\n",
      "agent1 return is:  0.9850297765591853\n",
      "agent2 return is:  8.637302350564013\n",
      "Batch 730 finished:\n",
      "agent1 return is:  1.1397974776468267\n",
      "agent2 return is:  8.570648356926277\n",
      "Batch 731 finished:\n",
      "agent1 return is:  1.1748089256626197\n",
      "agent2 return is:  8.589530787297068\n",
      "Batch 732 finished:\n",
      "agent1 return is:  1.2065007637787484\n",
      "agent2 return is:  8.528581482511305\n",
      "Batch 733 finished:\n",
      "agent1 return is:  1.1909242706720238\n",
      "agent2 return is:  8.525380551017285\n",
      "Batch 734 finished:\n",
      "agent1 return is:  1.2466696980775325\n",
      "agent2 return is:  8.329678307990374\n",
      "Batch 735 finished:\n",
      "agent1 return is:  1.2038204496558487\n",
      "agent2 return is:  8.5061297282606\n",
      "Batch 736 finished:\n",
      "agent1 return is:  1.0761299236194086\n",
      "agent2 return is:  8.612674672410964\n",
      "Batch 737 finished:\n",
      "agent1 return is:  1.4195050518208556\n",
      "agent2 return is:  8.471107488473457\n",
      "Batch 738 finished:\n",
      "agent1 return is:  1.1112682200486435\n",
      "agent2 return is:  8.641539895727494\n",
      "Batch 739 finished:\n",
      "agent1 return is:  1.0566115590757768\n",
      "agent2 return is:  8.6605181825303\n",
      "Batch 740 finished:\n",
      "agent1 return is:  1.0971159464403302\n",
      "agent2 return is:  8.50668523738409\n",
      "Batch 741 finished:\n",
      "agent1 return is:  1.1894295011341298\n",
      "agent2 return is:  8.517301203275851\n",
      "Batch 742 finished:\n",
      "agent1 return is:  0.8318012966468734\n",
      "agent2 return is:  8.416228292402952\n",
      "Batch 743 finished:\n",
      "agent1 return is:  0.5968055620738102\n",
      "agent2 return is:  8.504110798421872\n",
      "Batch 744 finished:\n",
      "agent1 return is:  1.0703212926137287\n",
      "agent2 return is:  8.571449112908503\n",
      "Batch 745 finished:\n",
      "agent1 return is:  0.9313188018230848\n",
      "agent2 return is:  8.540478432055828\n",
      "Batch 746 finished:\n",
      "agent1 return is:  0.990182784177967\n",
      "agent2 return is:  8.56193659321703\n",
      "Batch 747 finished:\n",
      "agent1 return is:  1.0175491578427374\n",
      "agent2 return is:  8.46737369202444\n",
      "Batch 748 finished:\n",
      "agent1 return is:  1.0786609657645845\n",
      "agent2 return is:  8.56363625130357\n",
      "Batch 749 finished:\n",
      "agent1 return is:  1.0259194615000147\n",
      "agent2 return is:  8.551964287800686\n",
      "Batch 750 finished:\n",
      "agent1 return is:  1.0417608992948062\n",
      "agent2 return is:  8.439656767393526\n",
      "Batch 751 finished:\n",
      "agent1 return is:  1.0524512349593285\n",
      "agent2 return is:  8.421063845531638\n",
      "Batch 752 finished:\n",
      "agent1 return is:  0.945727249195629\n",
      "agent2 return is:  8.45957085851707\n",
      "Batch 753 finished:\n",
      "agent1 return is:  0.9698702882204717\n",
      "agent2 return is:  8.306293060050507\n",
      "Batch 754 finished:\n",
      "agent1 return is:  1.0581830904746377\n",
      "agent2 return is:  8.387364787960454\n",
      "Batch 755 finished:\n",
      "agent1 return is:  0.6595501239546583\n",
      "agent2 return is:  8.550888492541024\n",
      "Batch 756 finished:\n",
      "agent1 return is:  0.9574794823007142\n",
      "agent2 return is:  8.374912988433655\n",
      "Batch 757 finished:\n",
      "agent1 return is:  0.911787646909137\n",
      "agent2 return is:  8.378781409747706\n",
      "Batch 758 finished:\n",
      "agent1 return is:  0.7753273064879946\n",
      "agent2 return is:  8.184832539152406\n",
      "Batch 759 finished:\n",
      "agent1 return is:  0.9274614643503235\n",
      "agent2 return is:  8.3893136727748\n",
      "Batch 760 finished:\n",
      "agent1 return is:  1.0160528239475006\n",
      "agent2 return is:  8.600920320017812\n",
      "Batch 761 finished:\n",
      "agent1 return is:  0.9499507767446888\n",
      "agent2 return is:  8.598697256255349\n",
      "Batch 762 finished:\n",
      "agent1 return is:  0.9235245889854086\n",
      "agent2 return is:  8.617291062537799\n",
      "Batch 763 finished:\n",
      "agent1 return is:  0.9274242604039882\n",
      "agent2 return is:  8.558971818867665\n",
      "Batch 764 finished:\n",
      "agent1 return is:  1.031116874353709\n",
      "agent2 return is:  8.600011272136939\n",
      "Batch 765 finished:\n",
      "agent1 return is:  0.9761638440134027\n",
      "agent2 return is:  8.57449088777599\n",
      "Batch 766 finished:\n",
      "agent1 return is:  0.8639829958571785\n",
      "agent2 return is:  8.750665298071715\n",
      "Batch 767 finished:\n",
      "agent1 return is:  0.8747107685852664\n",
      "agent2 return is:  8.635223813108997\n",
      "Batch 768 finished:\n",
      "agent1 return is:  1.0189705027399725\n",
      "agent2 return is:  8.679005786299076\n",
      "Batch 769 finished:\n",
      "agent1 return is:  1.0818318677337062\n",
      "agent2 return is:  8.640652642247723\n",
      "Batch 770 finished:\n",
      "agent1 return is:  1.0030446772161625\n",
      "agent2 return is:  8.503112895450446\n",
      "Batch 771 finished:\n",
      "agent1 return is:  0.8351904877240657\n",
      "agent2 return is:  8.749213286811418\n",
      "Batch 772 finished:\n",
      "agent1 return is:  1.020038067645927\n",
      "agent2 return is:  8.740654283600474\n",
      "Batch 773 finished:\n",
      "agent1 return is:  0.8214120315242024\n",
      "agent2 return is:  8.669512230701214\n",
      "Batch 774 finished:\n",
      "agent1 return is:  0.7388058274728226\n",
      "agent2 return is:  8.735569964948539\n",
      "Batch 775 finished:\n",
      "agent1 return is:  0.6802500991397205\n",
      "agent2 return is:  8.554504494889642\n",
      "Batch 776 finished:\n",
      "agent1 return is:  0.9207499271480077\n",
      "agent2 return is:  8.612809400832496\n",
      "Batch 777 finished:\n",
      "agent1 return is:  0.9359785156687028\n",
      "agent2 return is:  8.662467258494512\n",
      "Batch 778 finished:\n",
      "agent1 return is:  0.7963716969570507\n",
      "agent2 return is:  8.577198634590408\n",
      "Batch 779 finished:\n",
      "agent1 return is:  0.9123997712983902\n",
      "agent2 return is:  8.317733202496338\n",
      "Batch 780 finished:\n",
      "agent1 return is:  0.5645659508716945\n",
      "agent2 return is:  8.55118150548353\n",
      "Batch 781 finished:\n",
      "agent1 return is:  0.71618988349259\n",
      "agent2 return is:  8.503960610647335\n",
      "Batch 782 finished:\n",
      "agent1 return is:  0.8410304352132109\n",
      "agent2 return is:  8.541068207121016\n",
      "Batch 783 finished:\n",
      "agent1 return is:  0.8004956374506458\n",
      "agent2 return is:  8.56423219280351\n",
      "Batch 784 finished:\n",
      "agent1 return is:  0.7940399395102786\n",
      "agent2 return is:  8.715747888542143\n",
      "Batch 785 finished:\n",
      "agent1 return is:  0.852188966786356\n",
      "agent2 return is:  8.71812310081311\n",
      "Batch 786 finished:\n",
      "agent1 return is:  0.9054945334849019\n",
      "agent2 return is:  8.818151778181637\n",
      "Batch 787 finished:\n",
      "agent1 return is:  0.7262026411264884\n",
      "agent2 return is:  8.878667189949365\n",
      "Batch 788 finished:\n",
      "agent1 return is:  0.9081317896232974\n",
      "agent2 return is:  8.86642733357172\n",
      "Batch 789 finished:\n",
      "agent1 return is:  0.6185750696168043\n",
      "agent2 return is:  8.81805815521466\n",
      "Batch 790 finished:\n",
      "agent1 return is:  0.7903405326425668\n",
      "agent2 return is:  8.76634250492547\n",
      "Batch 791 finished:\n",
      "agent1 return is:  0.8836675190645984\n",
      "agent2 return is:  8.968730030896756\n",
      "Batch 792 finished:\n",
      "agent1 return is:  0.8768244844280911\n",
      "agent2 return is:  9.03859142368034\n",
      "Batch 793 finished:\n",
      "agent1 return is:  0.13627783080296577\n",
      "agent2 return is:  9.034026849916737\n",
      "Batch 794 finished:\n",
      "agent1 return is:  0.7148049269071935\n",
      "agent2 return is:  9.0255041508173\n",
      "Batch 795 finished:\n",
      "agent1 return is:  0.7454455674203548\n",
      "agent2 return is:  9.037975208840168\n",
      "Batch 796 finished:\n",
      "agent1 return is:  0.8302344576716363\n",
      "agent2 return is:  9.03219033638183\n",
      "Batch 797 finished:\n",
      "agent1 return is:  0.8387419726348608\n",
      "agent2 return is:  8.89672544602686\n",
      "Batch 798 finished:\n",
      "agent1 return is:  0.7215473971348918\n",
      "agent2 return is:  8.971592113687507\n",
      "Batch 799 finished:\n",
      "agent1 return is:  0.6079162919258208\n",
      "agent2 return is:  9.02517700638479\n",
      "Batch 800 finished:\n",
      "agent1 return is:  0.33435954806511176\n",
      "agent2 return is:  9.045485451356715\n",
      "Batch 801 finished:\n",
      "agent1 return is:  0.4850249409891168\n",
      "agent2 return is:  8.896825422462088\n",
      "Batch 802 finished:\n",
      "agent1 return is:  0.5763970908037337\n",
      "agent2 return is:  8.926403517316833\n",
      "Batch 803 finished:\n",
      "agent1 return is:  0.3951525561119867\n",
      "agent2 return is:  8.819442453664141\n",
      "Batch 804 finished:\n",
      "agent1 return is:  0.954414257643324\n",
      "agent2 return is:  8.842314464011872\n",
      "Batch 805 finished:\n",
      "agent1 return is:  0.8076429248562367\n",
      "agent2 return is:  8.828397789765098\n",
      "Batch 806 finished:\n",
      "agent1 return is:  0.8184791562389278\n",
      "agent2 return is:  8.797952677379913\n",
      "Batch 807 finished:\n",
      "agent1 return is:  0.75249694336832\n",
      "agent2 return is:  8.839654309703986\n",
      "Batch 808 finished:\n",
      "agent1 return is:  0.9404511578920733\n",
      "agent2 return is:  8.689884213328106\n",
      "Batch 809 finished:\n",
      "agent1 return is:  0.8127795408114691\n",
      "agent2 return is:  8.764664776732685\n",
      "Batch 810 finished:\n",
      "agent1 return is:  0.8721412409405702\n",
      "agent2 return is:  8.876841603845028\n",
      "Batch 811 finished:\n",
      "agent1 return is:  0.6590054021711012\n",
      "agent2 return is:  8.913186600770084\n",
      "Batch 812 finished:\n",
      "agent1 return is:  0.8337016915319516\n",
      "agent2 return is:  8.788174025459135\n",
      "Batch 813 finished:\n",
      "agent1 return is:  0.44734686606748536\n",
      "agent2 return is:  8.882712470456628\n",
      "Batch 814 finished:\n",
      "agent1 return is:  1.1802736214099274\n",
      "agent2 return is:  8.793189615197985\n",
      "Batch 815 finished:\n",
      "agent1 return is:  0.8321307695789217\n",
      "agent2 return is:  8.86342183805625\n",
      "Batch 816 finished:\n",
      "agent1 return is:  0.42945931442939367\n",
      "agent2 return is:  8.787492061861045\n",
      "Batch 817 finished:\n",
      "agent1 return is:  1.0146414326666315\n",
      "agent2 return is:  8.686896227212518\n",
      "Batch 818 finished:\n",
      "agent1 return is:  1.0919581494291206\n",
      "agent2 return is:  8.649660086139832\n",
      "Batch 819 finished:\n",
      "agent1 return is:  0.38916924692502447\n",
      "agent2 return is:  8.706779459900318\n",
      "Batch 820 finished:\n",
      "agent1 return is:  0.7221272015850732\n",
      "agent2 return is:  8.70117803396109\n",
      "Batch 821 finished:\n",
      "agent1 return is:  0.7219840706430932\n",
      "agent2 return is:  8.683309979859827\n",
      "Batch 822 finished:\n",
      "agent1 return is:  0.9250265000520379\n",
      "agent2 return is:  8.682750891012727\n",
      "Batch 823 finished:\n",
      "agent1 return is:  0.9697433776694615\n",
      "agent2 return is:  8.813600924365218\n",
      "Batch 824 finished:\n",
      "agent1 return is:  0.9162519912073772\n",
      "agent2 return is:  8.840746356208122\n",
      "Batch 825 finished:\n",
      "agent1 return is:  0.9761763326520502\n",
      "agent2 return is:  8.701367574447346\n",
      "Batch 826 finished:\n",
      "agent1 return is:  0.1736046966322926\n",
      "agent2 return is:  8.480687376592197\n",
      "Batch 827 finished:\n",
      "agent1 return is:  0.5332376528119314\n",
      "agent2 return is:  8.587680974031606\n",
      "Batch 828 finished:\n",
      "agent1 return is:  0.6568875976779173\n",
      "agent2 return is:  8.677309793813759\n",
      "Batch 829 finished:\n",
      "agent1 return is:  0.3920778790802456\n",
      "agent2 return is:  8.61026442912625\n",
      "Batch 830 finished:\n",
      "agent1 return is:  0.6836320634077122\n",
      "agent2 return is:  8.577677471572223\n",
      "Batch 831 finished:\n",
      "agent1 return is:  0.7884949552430343\n",
      "agent2 return is:  8.541648256555842\n",
      "Batch 832 finished:\n",
      "agent1 return is:  0.2500469447881727\n",
      "agent2 return is:  8.57113831440829\n",
      "Batch 833 finished:\n",
      "agent1 return is:  0.20791009916633857\n",
      "agent2 return is:  8.225852842795275\n",
      "Batch 834 finished:\n",
      "agent1 return is:  0.16855321391707256\n",
      "agent2 return is:  8.655141720659046\n",
      "Batch 835 finished:\n",
      "agent1 return is:  0.517978447623729\n",
      "agent2 return is:  8.59888907875407\n",
      "Batch 836 finished:\n",
      "agent1 return is:  0.22592557074731495\n",
      "agent2 return is:  8.574719758256101\n",
      "Batch 837 finished:\n",
      "agent1 return is:  0.6255619295378649\n",
      "agent2 return is:  8.620048023514936\n",
      "Batch 838 finished:\n",
      "agent1 return is:  0.15861493189117443\n",
      "agent2 return is:  8.812175445716697\n",
      "Batch 839 finished:\n",
      "agent1 return is:  0.2564264470999306\n",
      "agent2 return is:  8.810315093654658\n",
      "Batch 840 finished:\n",
      "agent1 return is:  -0.0649347920325062\n",
      "agent2 return is:  8.899267002615218\n",
      "Batch 841 finished:\n",
      "agent1 return is:  0.25043468468278307\n",
      "agent2 return is:  8.880178241890222\n",
      "Batch 842 finished:\n",
      "agent1 return is:  0.6590641731515374\n",
      "agent2 return is:  8.842007689855958\n",
      "Batch 843 finished:\n",
      "agent1 return is:  0.3944230552697983\n",
      "agent2 return is:  8.8418548233936\n",
      "Batch 844 finished:\n",
      "agent1 return is:  0.8146705677713388\n",
      "agent2 return is:  8.831740848194702\n",
      "Batch 845 finished:\n",
      "agent1 return is:  0.019436847191377893\n",
      "agent2 return is:  8.906542874474171\n",
      "Batch 846 finished:\n",
      "agent1 return is:  -0.05528398125562656\n",
      "agent2 return is:  8.934448616523857\n",
      "Batch 847 finished:\n",
      "agent1 return is:  0.43910543584482714\n",
      "agent2 return is:  8.859862021841245\n",
      "Batch 848 finished:\n",
      "agent1 return is:  0.6758496497317578\n",
      "agent2 return is:  8.926506570952176\n",
      "Batch 849 finished:\n",
      "agent1 return is:  0.29383590303362705\n",
      "agent2 return is:  8.875140793791235\n",
      "Batch 850 finished:\n",
      "agent1 return is:  0.5508265262908162\n",
      "agent2 return is:  8.847338340107385\n",
      "Batch 851 finished:\n",
      "agent1 return is:  0.5922009177118432\n",
      "agent2 return is:  8.634616407936015\n",
      "Batch 852 finished:\n",
      "agent1 return is:  1.032166930018316\n",
      "agent2 return is:  8.835655700459977\n",
      "Batch 853 finished:\n",
      "agent1 return is:  0.762177379990078\n",
      "agent2 return is:  8.616394113788283\n",
      "Batch 854 finished:\n",
      "agent1 return is:  1.052114721937363\n",
      "agent2 return is:  8.579075455773623\n",
      "Batch 855 finished:\n",
      "agent1 return is:  1.017646011160147\n",
      "agent2 return is:  8.583977941476025\n",
      "Batch 856 finished:\n",
      "agent1 return is:  0.8491852964230389\n",
      "agent2 return is:  8.440900127883985\n",
      "Batch 857 finished:\n",
      "agent1 return is:  0.7329183636152468\n",
      "agent2 return is:  8.525980117122597\n",
      "Batch 858 finished:\n",
      "agent1 return is:  0.9148665100551587\n",
      "agent2 return is:  8.338494195564216\n",
      "Batch 859 finished:\n",
      "agent1 return is:  0.8561673891319284\n",
      "agent2 return is:  8.575181830119144\n",
      "Batch 860 finished:\n",
      "agent1 return is:  0.8504527356822714\n",
      "agent2 return is:  8.656088036099877\n",
      "Batch 861 finished:\n",
      "agent1 return is:  0.8311996754951257\n",
      "agent2 return is:  8.695906575017885\n",
      "Batch 862 finished:\n",
      "agent1 return is:  0.7424623325809397\n",
      "agent2 return is:  8.77209943779565\n",
      "Batch 863 finished:\n",
      "agent1 return is:  0.8749014479636151\n",
      "agent2 return is:  8.742267736540715\n",
      "Batch 864 finished:\n",
      "agent1 return is:  0.8431072792176884\n",
      "agent2 return is:  8.718382623212591\n",
      "Batch 865 finished:\n",
      "agent1 return is:  0.9287702976789981\n",
      "agent2 return is:  8.568668071792477\n",
      "Batch 866 finished:\n",
      "agent1 return is:  1.0647309449756968\n",
      "agent2 return is:  8.698499238399542\n",
      "Batch 867 finished:\n",
      "agent1 return is:  0.8116319940122328\n",
      "agent2 return is:  8.82246403833938\n",
      "Batch 868 finished:\n",
      "agent1 return is:  0.8914056671601869\n",
      "agent2 return is:  8.715162064084074\n",
      "Batch 869 finished:\n",
      "agent1 return is:  0.886001941074372\n",
      "agent2 return is:  8.732708990284873\n",
      "Batch 870 finished:\n",
      "agent1 return is:  0.9430623793737541\n",
      "agent2 return is:  8.627072071628607\n",
      "Batch 871 finished:\n",
      "agent1 return is:  0.7386159453727614\n",
      "agent2 return is:  8.65506354032866\n",
      "Batch 872 finished:\n",
      "agent1 return is:  0.958055789991779\n",
      "agent2 return is:  8.39541122810352\n",
      "Batch 873 finished:\n",
      "agent1 return is:  1.0004076883408195\n",
      "agent2 return is:  8.476597423759033\n",
      "Batch 874 finished:\n",
      "agent1 return is:  0.6013435118880516\n",
      "agent2 return is:  8.397677232758298\n",
      "Batch 875 finished:\n",
      "agent1 return is:  0.9839835321215484\n",
      "agent2 return is:  8.506182012918472\n",
      "Batch 876 finished:\n",
      "agent1 return is:  0.9978928648666722\n",
      "agent2 return is:  8.469775886832853\n",
      "Batch 877 finished:\n",
      "agent1 return is:  0.7090780723579048\n",
      "agent2 return is:  8.483385727286443\n",
      "Batch 878 finished:\n",
      "agent1 return is:  0.9374239343314211\n",
      "agent2 return is:  8.452861745229075\n",
      "Batch 879 finished:\n",
      "agent1 return is:  0.9147014531974311\n",
      "agent2 return is:  8.6247246276556\n",
      "Batch 880 finished:\n",
      "agent1 return is:  1.0144021518648179\n",
      "agent2 return is:  8.560297898561764\n",
      "Batch 881 finished:\n",
      "agent1 return is:  1.140643707427662\n",
      "agent2 return is:  8.68221475299638\n",
      "Batch 882 finished:\n",
      "agent1 return is:  1.1161212397612787\n",
      "agent2 return is:  8.649412352777157\n",
      "Batch 883 finished:\n",
      "agent1 return is:  0.7151727011646839\n",
      "agent2 return is:  8.670076533377856\n",
      "Batch 884 finished:\n",
      "agent1 return is:  0.9255071909318692\n",
      "agent2 return is:  8.60513152190414\n",
      "Batch 885 finished:\n",
      "agent1 return is:  0.7507034129318577\n",
      "agent2 return is:  8.65301899467913\n",
      "Batch 886 finished:\n",
      "agent1 return is:  0.6928708477928445\n",
      "agent2 return is:  8.693476014722828\n",
      "Batch 887 finished:\n",
      "agent1 return is:  0.6051785167309118\n",
      "agent2 return is:  8.787194574589757\n",
      "Batch 888 finished:\n",
      "agent1 return is:  1.225654424129177\n",
      "agent2 return is:  8.601061953182871\n",
      "Batch 889 finished:\n",
      "agent1 return is:  1.1419035535680955\n",
      "agent2 return is:  8.695419786056714\n",
      "Batch 890 finished:\n",
      "agent1 return is:  0.6241636800724224\n",
      "agent2 return is:  8.591428373394066\n",
      "Batch 891 finished:\n",
      "agent1 return is:  0.9523665208326233\n",
      "agent2 return is:  8.573124936419575\n",
      "Batch 892 finished:\n",
      "agent1 return is:  1.163858970051567\n",
      "agent2 return is:  8.607366507065384\n",
      "Batch 893 finished:\n",
      "agent1 return is:  0.9830482653921747\n",
      "agent2 return is:  8.583240165707874\n",
      "Batch 894 finished:\n",
      "agent1 return is:  0.9711855590642101\n",
      "agent2 return is:  8.517287839794506\n",
      "Batch 895 finished:\n",
      "agent1 return is:  0.8603117810039946\n",
      "agent2 return is:  8.530654668910133\n",
      "Batch 896 finished:\n",
      "agent1 return is:  0.9834371057724003\n",
      "agent2 return is:  8.479900374331937\n",
      "Batch 897 finished:\n",
      "agent1 return is:  0.9042362956975567\n",
      "agent2 return is:  8.574822285360085\n",
      "Batch 898 finished:\n",
      "agent1 return is:  1.226035013239264\n",
      "agent2 return is:  8.657897300305773\n",
      "Batch 899 finished:\n",
      "agent1 return is:  1.1537468518677394\n",
      "agent2 return is:  8.695839237981689\n",
      "Batch 900 finished:\n",
      "agent1 return is:  1.1134529480527655\n",
      "agent2 return is:  8.73348972897951\n",
      "Batch 901 finished:\n",
      "agent1 return is:  0.9858594649939073\n",
      "agent2 return is:  8.854160468809138\n",
      "Batch 902 finished:\n",
      "agent1 return is:  0.9388430376501217\n",
      "agent2 return is:  8.8102689623626\n",
      "Batch 903 finished:\n",
      "agent1 return is:  1.013711897932139\n",
      "agent2 return is:  8.908051976055528\n",
      "Batch 904 finished:\n",
      "agent1 return is:  0.8499109404879348\n",
      "agent2 return is:  8.906958392178185\n",
      "Batch 905 finished:\n",
      "agent1 return is:  0.8087973431341695\n",
      "agent2 return is:  8.848446308311836\n",
      "Batch 906 finished:\n",
      "agent1 return is:  1.0661326484020934\n",
      "agent2 return is:  8.808756458261797\n",
      "Batch 907 finished:\n",
      "agent1 return is:  1.1219505600857826\n",
      "agent2 return is:  8.84037755642618\n",
      "Batch 908 finished:\n",
      "agent1 return is:  1.0791453170464445\n",
      "agent2 return is:  8.72414460986379\n",
      "Batch 909 finished:\n",
      "agent1 return is:  1.1297903665395779\n",
      "agent2 return is:  8.80091182181065\n",
      "Batch 910 finished:\n",
      "agent1 return is:  0.7342899232718114\n",
      "agent2 return is:  8.725886442059704\n",
      "Batch 911 finished:\n",
      "agent1 return is:  1.1445652637627286\n",
      "agent2 return is:  8.71759119891216\n",
      "Batch 912 finished:\n",
      "agent1 return is:  0.7970458232621669\n",
      "agent2 return is:  8.83533433817093\n",
      "Batch 913 finished:\n",
      "agent1 return is:  0.6914735622897962\n",
      "agent2 return is:  8.740523879251118\n",
      "Batch 914 finished:\n",
      "agent1 return is:  1.1409871420079534\n",
      "agent2 return is:  8.739119654846718\n",
      "Batch 915 finished:\n",
      "agent1 return is:  1.219154188031523\n",
      "agent2 return is:  8.75703441632714\n",
      "Batch 916 finished:\n",
      "agent1 return is:  0.7552418715007441\n",
      "agent2 return is:  8.717494649984863\n",
      "Batch 917 finished:\n",
      "agent1 return is:  1.0025702325632013\n",
      "agent2 return is:  8.65318867023436\n",
      "Batch 918 finished:\n",
      "agent1 return is:  1.2488277253731912\n",
      "agent2 return is:  8.659253765504943\n",
      "Batch 919 finished:\n",
      "agent1 return is:  0.8935727843547047\n",
      "agent2 return is:  8.647816410735917\n",
      "Batch 920 finished:\n",
      "agent1 return is:  0.6230577061386933\n",
      "agent2 return is:  8.430357273355392\n",
      "Batch 921 finished:\n",
      "agent1 return is:  1.2221105851302574\n",
      "agent2 return is:  8.488465986171727\n",
      "Batch 922 finished:\n",
      "agent1 return is:  1.2817287495041092\n",
      "agent2 return is:  8.501470985795144\n",
      "Batch 923 finished:\n",
      "agent1 return is:  1.2352980417222366\n",
      "agent2 return is:  8.416194957136483\n",
      "Batch 924 finished:\n",
      "agent1 return is:  1.1613565774915227\n",
      "agent2 return is:  8.387279225143718\n",
      "Batch 925 finished:\n",
      "agent1 return is:  1.2041139481677128\n",
      "agent2 return is:  8.478195585984452\n",
      "Batch 926 finished:\n",
      "agent1 return is:  1.4160354514194249\n",
      "agent2 return is:  8.317319207319416\n",
      "Batch 927 finished:\n",
      "agent1 return is:  0.9722786618328814\n",
      "agent2 return is:  8.569814983247685\n",
      "Batch 928 finished:\n",
      "agent1 return is:  1.2698294855672314\n",
      "agent2 return is:  8.4813311860855\n",
      "Batch 929 finished:\n",
      "agent1 return is:  1.2611332028522309\n",
      "agent2 return is:  8.510416204425294\n",
      "Batch 930 finished:\n",
      "agent1 return is:  1.3145294760026762\n",
      "agent2 return is:  8.508711728908985\n",
      "Batch 931 finished:\n",
      "agent1 return is:  1.2239452536726103\n",
      "agent2 return is:  8.607554965264342\n",
      "Batch 932 finished:\n",
      "agent1 return is:  1.1480133521601825\n",
      "agent2 return is:  8.55534795045592\n",
      "Batch 933 finished:\n",
      "agent1 return is:  1.2801506991294784\n",
      "agent2 return is:  8.483836748942629\n",
      "Batch 934 finished:\n",
      "agent1 return is:  0.8389103816707523\n",
      "agent2 return is:  8.56763150187405\n",
      "Batch 935 finished:\n",
      "agent1 return is:  1.3676602351598668\n",
      "agent2 return is:  8.729595338325492\n",
      "Batch 936 finished:\n",
      "agent1 return is:  1.1853327867772148\n",
      "agent2 return is:  8.653508318961993\n",
      "Batch 937 finished:\n",
      "agent1 return is:  1.2614173360201857\n",
      "agent2 return is:  8.557730853517548\n",
      "Batch 938 finished:\n",
      "agent1 return is:  1.2989936029435\n",
      "agent2 return is:  8.567450471181203\n",
      "Batch 939 finished:\n",
      "agent1 return is:  1.272111174174017\n",
      "agent2 return is:  8.580017706439667\n",
      "Batch 940 finished:\n",
      "agent1 return is:  1.2187594543115767\n",
      "agent2 return is:  8.646851808436693\n",
      "Batch 941 finished:\n",
      "agent1 return is:  1.0844051778773973\n",
      "agent2 return is:  8.808728169540355\n",
      "Batch 942 finished:\n",
      "agent1 return is:  1.202284973789392\n",
      "agent2 return is:  8.723048526689055\n",
      "Batch 943 finished:\n",
      "agent1 return is:  1.2175921868608643\n",
      "agent2 return is:  8.908007833185504\n",
      "Batch 944 finished:\n",
      "agent1 return is:  1.0658006614770659\n",
      "agent2 return is:  8.898771073296984\n",
      "Batch 945 finished:\n",
      "agent1 return is:  1.1973928055346978\n",
      "agent2 return is:  8.85435017696091\n",
      "Batch 946 finished:\n",
      "agent1 return is:  1.1597427447839788\n",
      "agent2 return is:  8.738270196168147\n",
      "Batch 947 finished:\n",
      "agent1 return is:  1.026706729301881\n",
      "agent2 return is:  8.882590939308379\n",
      "Batch 948 finished:\n",
      "agent1 return is:  1.0928061694607933\n",
      "agent2 return is:  8.765788732023259\n",
      "Batch 949 finished:\n",
      "agent1 return is:  1.168565337567021\n",
      "agent2 return is:  8.814135813611298\n",
      "Batch 950 finished:\n",
      "agent1 return is:  1.0708672424802768\n",
      "agent2 return is:  8.761115459064044\n",
      "Batch 951 finished:\n",
      "agent1 return is:  0.9398014664344024\n",
      "agent2 return is:  8.711105626355678\n",
      "Batch 952 finished:\n",
      "agent1 return is:  1.1988381431707416\n",
      "agent2 return is:  8.741736468146176\n",
      "Batch 953 finished:\n",
      "agent1 return is:  1.0591359015822235\n",
      "agent2 return is:  8.739412633358725\n",
      "Batch 954 finished:\n",
      "agent1 return is:  1.1330547629730003\n",
      "agent2 return is:  8.822702225043265\n",
      "Batch 955 finished:\n",
      "agent1 return is:  0.969251339133081\n",
      "agent2 return is:  8.81910178340171\n",
      "Batch 956 finished:\n",
      "agent1 return is:  1.0011137250162567\n",
      "agent2 return is:  8.826332469937125\n",
      "Batch 957 finished:\n",
      "agent1 return is:  1.1015894439872869\n",
      "agent2 return is:  8.845851702782761\n",
      "Batch 958 finished:\n",
      "agent1 return is:  0.8826692995576124\n",
      "agent2 return is:  8.645908206211672\n",
      "Batch 959 finished:\n",
      "agent1 return is:  1.1267014445763832\n",
      "agent2 return is:  8.582131654971002\n",
      "Batch 960 finished:\n",
      "agent1 return is:  1.0597526208781547\n",
      "agent2 return is:  8.617148854685757\n",
      "Batch 961 finished:\n",
      "agent1 return is:  1.0772923246389718\n",
      "agent2 return is:  8.624239072651456\n",
      "Batch 962 finished:\n",
      "agent1 return is:  1.1200572917067482\n",
      "agent2 return is:  8.682517742596024\n",
      "Batch 963 finished:\n",
      "agent1 return is:  1.0837538531405533\n",
      "agent2 return is:  8.883455720907216\n",
      "Batch 964 finished:\n",
      "agent1 return is:  1.073016548885507\n",
      "agent2 return is:  8.890223725967815\n",
      "Batch 965 finished:\n",
      "agent1 return is:  1.0498486024124707\n",
      "agent2 return is:  8.81468038915375\n",
      "Batch 966 finished:\n",
      "agent1 return is:  1.0875443421024236\n",
      "agent2 return is:  8.925689050081289\n",
      "Batch 967 finished:\n",
      "agent1 return is:  0.91421098480006\n",
      "agent2 return is:  8.970074519561033\n",
      "Batch 968 finished:\n",
      "agent1 return is:  1.0370224050309829\n",
      "agent2 return is:  8.921147043417427\n",
      "Batch 969 finished:\n",
      "agent1 return is:  0.9840024822406724\n",
      "agent2 return is:  8.900195463004732\n",
      "Batch 970 finished:\n",
      "agent1 return is:  1.0229014382981494\n",
      "agent2 return is:  9.000672526764776\n",
      "Batch 971 finished:\n",
      "agent1 return is:  0.9463311815676372\n",
      "agent2 return is:  8.98210136510772\n",
      "Batch 972 finished:\n",
      "agent1 return is:  0.9596895285088598\n",
      "agent2 return is:  9.036704321998844\n",
      "Batch 973 finished:\n",
      "agent1 return is:  0.9221076845051374\n",
      "agent2 return is:  9.172868064947474\n",
      "Batch 974 finished:\n",
      "agent1 return is:  1.0694202557894585\n",
      "agent2 return is:  9.263307542799492\n",
      "Batch 975 finished:\n",
      "agent1 return is:  0.8545879008880473\n",
      "agent2 return is:  9.333910934749493\n",
      "Batch 976 finished:\n",
      "agent1 return is:  0.9544478807644726\n",
      "agent2 return is:  9.3426238564724\n",
      "Batch 977 finished:\n",
      "agent1 return is:  1.107629177590709\n",
      "agent2 return is:  9.436635912559623\n",
      "Batch 978 finished:\n",
      "agent1 return is:  0.8527826782304285\n",
      "agent2 return is:  9.540916358072169\n",
      "Batch 979 finished:\n",
      "agent1 return is:  0.9326671315641389\n",
      "agent2 return is:  9.474171606728941\n",
      "Batch 980 finished:\n",
      "agent1 return is:  0.998768615662097\n",
      "agent2 return is:  9.413526230795956\n",
      "Batch 981 finished:\n",
      "agent1 return is:  1.1536672839414988\n",
      "agent2 return is:  9.393731607485961\n",
      "Batch 982 finished:\n",
      "agent1 return is:  0.8518403495654875\n",
      "agent2 return is:  9.37514334433405\n",
      "Batch 983 finished:\n",
      "agent1 return is:  0.8601338606036821\n",
      "agent2 return is:  9.317622997753684\n",
      "Batch 984 finished:\n",
      "agent1 return is:  0.961336024050254\n",
      "agent2 return is:  9.324192387652328\n",
      "Batch 985 finished:\n",
      "agent1 return is:  0.9490527029734939\n",
      "agent2 return is:  9.333190955673558\n",
      "Batch 986 finished:\n",
      "agent1 return is:  0.9004504789328417\n",
      "agent2 return is:  9.32779865556374\n",
      "Batch 987 finished:\n",
      "agent1 return is:  0.6191671885697144\n",
      "agent2 return is:  9.452733864706312\n",
      "Batch 988 finished:\n",
      "agent1 return is:  0.8403349925107433\n",
      "agent2 return is:  9.505726108308174\n",
      "Batch 989 finished:\n",
      "agent1 return is:  1.1044022706781667\n",
      "agent2 return is:  9.467014698411312\n",
      "Batch 990 finished:\n",
      "agent1 return is:  1.1480904740267053\n",
      "agent2 return is:  9.450820950798182\n",
      "Batch 991 finished:\n",
      "agent1 return is:  0.7792031984766334\n",
      "agent2 return is:  9.367944371073014\n",
      "Batch 992 finished:\n",
      "agent1 return is:  0.7495974833530568\n",
      "agent2 return is:  9.417483277476862\n",
      "Batch 993 finished:\n",
      "agent1 return is:  1.0617217259725464\n",
      "agent2 return is:  9.377442964494403\n",
      "Batch 994 finished:\n",
      "agent1 return is:  0.8133731755142647\n",
      "agent2 return is:  9.380633580839238\n",
      "Batch 995 finished:\n",
      "agent1 return is:  1.1253455163188852\n",
      "agent2 return is:  9.484013727536652\n",
      "Batch 996 finished:\n",
      "agent1 return is:  1.0748370484477998\n",
      "agent2 return is:  9.603646921042769\n",
      "Batch 997 finished:\n",
      "agent1 return is:  0.7264846835851628\n",
      "agent2 return is:  9.524662878641667\n",
      "Batch 998 finished:\n",
      "agent1 return is:  0.9551506055246953\n",
      "agent2 return is:  9.318930663545338\n",
      "Batch 999 finished:\n",
      "agent1 return is:  0.7937467076583464\n",
      "agent2 return is:  9.51493875036007\n",
      "Batch 1000 finished:\n",
      "agent1 return is:  0.9422148943752635\n",
      "agent2 return is:  9.554198955824631\n",
      "Batch 1001 finished:\n",
      "agent1 return is:  0.6510968491776455\n",
      "agent2 return is:  9.317963527525706\n",
      "Batch 1002 finished:\n",
      "agent1 return is:  0.7725958075080099\n",
      "agent2 return is:  9.484282411753826\n",
      "Batch 1003 finished:\n",
      "agent1 return is:  0.8781255832688868\n",
      "agent2 return is:  9.30019181841525\n",
      "Batch 1004 finished:\n",
      "agent1 return is:  0.9756618131493597\n",
      "agent2 return is:  9.555170663549916\n",
      "Batch 1005 finished:\n",
      "agent1 return is:  0.9658054358543742\n",
      "agent2 return is:  9.432268871317778\n",
      "Batch 1006 finished:\n",
      "agent1 return is:  0.7219788748220797\n",
      "agent2 return is:  9.437522483729193\n",
      "Batch 1007 finished:\n",
      "agent1 return is:  0.7839778569717615\n",
      "agent2 return is:  9.491352629114294\n",
      "Batch 1008 finished:\n",
      "agent1 return is:  0.7736836336873789\n",
      "agent2 return is:  9.375822657286363\n",
      "Batch 1009 finished:\n",
      "agent1 return is:  0.893473803218291\n",
      "agent2 return is:  9.418960201988334\n",
      "Batch 1010 finished:\n",
      "agent1 return is:  0.7223159685350056\n",
      "agent2 return is:  9.519738744330766\n",
      "Batch 1011 finished:\n",
      "agent1 return is:  0.7547658264059824\n",
      "agent2 return is:  9.568627319916756\n",
      "Batch 1012 finished:\n",
      "agent1 return is:  0.8590093198671251\n",
      "agent2 return is:  9.503790058513264\n",
      "Batch 1013 finished:\n",
      "agent1 return is:  0.8575921080473372\n",
      "agent2 return is:  9.593639447201536\n",
      "Batch 1014 finished:\n",
      "agent1 return is:  0.9287309305491835\n",
      "agent2 return is:  9.686371649413132\n",
      "Batch 1015 finished:\n",
      "agent1 return is:  0.5875058253588713\n",
      "agent2 return is:  9.50831031064708\n",
      "Batch 1016 finished:\n",
      "agent1 return is:  0.8936036704350245\n",
      "agent2 return is:  9.837934099448386\n",
      "Batch 1017 finished:\n",
      "agent1 return is:  0.7128027912281414\n",
      "agent2 return is:  9.810865483640477\n",
      "Batch 1018 finished:\n",
      "agent1 return is:  0.7109874047482437\n",
      "agent2 return is:  9.69551573541468\n",
      "Batch 1019 finished:\n",
      "agent1 return is:  0.8129096625369241\n",
      "agent2 return is:  9.500227286919053\n",
      "Batch 1020 finished:\n",
      "agent1 return is:  0.882869231829929\n",
      "agent2 return is:  9.564418999865197\n",
      "Batch 1021 finished:\n",
      "agent1 return is:  0.795000977156638\n",
      "agent2 return is:  9.622252714087832\n",
      "Batch 1022 finished:\n",
      "agent1 return is:  0.6831181602942251\n",
      "agent2 return is:  9.53940523986114\n",
      "Batch 1023 finished:\n",
      "agent1 return is:  0.7267508523317681\n",
      "agent2 return is:  9.530495637057737\n",
      "Batch 1024 finished:\n",
      "agent1 return is:  0.7825166903555394\n",
      "agent2 return is:  9.621600676294893\n",
      "Batch 1025 finished:\n",
      "agent1 return is:  0.8137142256413112\n",
      "agent2 return is:  9.56622836991931\n",
      "Batch 1026 finished:\n",
      "agent1 return is:  0.9204286074328096\n",
      "agent2 return is:  9.573874393504143\n",
      "Batch 1027 finished:\n",
      "agent1 return is:  0.8871740955917202\n",
      "agent2 return is:  9.535171657140554\n",
      "Batch 1028 finished:\n",
      "agent1 return is:  0.7232163238393116\n",
      "agent2 return is:  9.57077455082183\n",
      "Batch 1029 finished:\n",
      "agent1 return is:  0.7170734426388619\n",
      "agent2 return is:  9.659959501274344\n",
      "Batch 1030 finished:\n",
      "agent1 return is:  0.8359029088074306\n",
      "agent2 return is:  9.69296757306794\n",
      "Batch 1031 finished:\n",
      "agent1 return is:  0.923805581044988\n",
      "agent2 return is:  9.647524213643415\n",
      "Batch 1032 finished:\n",
      "agent1 return is:  0.8518498976595872\n",
      "agent2 return is:  9.594226870784627\n",
      "Batch 1033 finished:\n",
      "agent1 return is:  0.7267648614819022\n",
      "agent2 return is:  9.62938350198262\n",
      "Batch 1034 finished:\n",
      "agent1 return is:  0.7944103631870469\n",
      "agent2 return is:  9.720399112791206\n",
      "Batch 1035 finished:\n",
      "agent1 return is:  0.9143421107683174\n",
      "agent2 return is:  9.693392348865224\n",
      "Batch 1036 finished:\n",
      "agent1 return is:  0.9602978140479481\n",
      "agent2 return is:  9.933103129357512\n",
      "Batch 1037 finished:\n",
      "agent1 return is:  0.8788685953782259\n",
      "agent2 return is:  9.816776762720961\n",
      "Batch 1038 finished:\n",
      "agent1 return is:  0.8503081029952573\n",
      "agent2 return is:  9.819992313726676\n",
      "Batch 1039 finished:\n",
      "agent1 return is:  1.0879601406362376\n",
      "agent2 return is:  9.548958518608199\n",
      "Batch 1040 finished:\n",
      "agent1 return is:  0.8577835482635823\n",
      "agent2 return is:  9.827637227056691\n",
      "Batch 1041 finished:\n",
      "agent1 return is:  0.9502030430961144\n",
      "agent2 return is:  9.923505141488336\n",
      "Batch 1042 finished:\n",
      "agent1 return is:  0.936171925958434\n",
      "agent2 return is:  9.9084444175435\n",
      "Batch 1043 finished:\n",
      "agent1 return is:  0.7775067250903489\n",
      "agent2 return is:  10.02887889611257\n",
      "Batch 1044 finished:\n",
      "agent1 return is:  0.928018797519024\n",
      "agent2 return is:  10.041662053362623\n",
      "Batch 1045 finished:\n",
      "agent1 return is:  0.6798735053458733\n",
      "agent2 return is:  10.042499937432778\n",
      "Batch 1046 finished:\n",
      "agent1 return is:  0.8616447865893437\n",
      "agent2 return is:  9.97875353811823\n",
      "Batch 1047 finished:\n",
      "agent1 return is:  0.8209815762465806\n",
      "agent2 return is:  10.08012599851699\n",
      "Batch 1048 finished:\n",
      "agent1 return is:  0.9734067404909034\n",
      "agent2 return is:  10.076241982699912\n",
      "Batch 1049 finished:\n",
      "agent1 return is:  0.8641259317369645\n",
      "agent2 return is:  10.090868411932894\n",
      "Batch 1050 finished:\n",
      "agent1 return is:  0.7469824666650773\n",
      "agent2 return is:  10.223824172007578\n",
      "Batch 1051 finished:\n",
      "agent1 return is:  0.9211283294310775\n",
      "agent2 return is:  10.151946837734734\n",
      "Batch 1052 finished:\n",
      "agent1 return is:  0.9162677124736047\n",
      "agent2 return is:  10.221633474129575\n",
      "Batch 1053 finished:\n",
      "agent1 return is:  0.8466853923538002\n",
      "agent2 return is:  10.174735787918188\n",
      "Batch 1054 finished:\n",
      "agent1 return is:  0.6781580744374192\n",
      "agent2 return is:  10.290876652617726\n",
      "Batch 1055 finished:\n",
      "agent1 return is:  0.9156081911931138\n",
      "agent2 return is:  10.377162014094338\n",
      "Batch 1056 finished:\n",
      "agent1 return is:  0.8978837653182403\n",
      "agent2 return is:  10.104529493375116\n",
      "Batch 1057 finished:\n",
      "agent1 return is:  0.8293176277241934\n",
      "agent2 return is:  10.33094623991176\n",
      "Batch 1058 finished:\n",
      "agent1 return is:  0.8557296875875462\n",
      "agent2 return is:  10.340200881769402\n",
      "Batch 1059 finished:\n",
      "agent1 return is:  0.6415010744388148\n",
      "agent2 return is:  10.38810788548856\n",
      "Batch 1060 finished:\n",
      "agent1 return is:  0.8232560274523605\n",
      "agent2 return is:  10.312770791323238\n",
      "Batch 1061 finished:\n",
      "agent1 return is:  0.737611017820083\n",
      "agent2 return is:  10.431738501223403\n",
      "Batch 1062 finished:\n",
      "agent1 return is:  0.62671202432882\n",
      "agent2 return is:  10.461277192488751\n",
      "Batch 1063 finished:\n",
      "agent1 return is:  0.678386926850235\n",
      "agent2 return is:  10.539802990490259\n",
      "Batch 1064 finished:\n",
      "agent1 return is:  0.8050800465016885\n",
      "agent2 return is:  10.523290584579092\n",
      "Batch 1065 finished:\n",
      "agent1 return is:  0.5883658080495494\n",
      "agent2 return is:  10.592226899965691\n",
      "Batch 1066 finished:\n",
      "agent1 return is:  0.8923220412898825\n",
      "agent2 return is:  10.58157349888345\n",
      "Batch 1067 finished:\n",
      "agent1 return is:  0.7844884329572163\n",
      "agent2 return is:  10.534285129877867\n",
      "Batch 1068 finished:\n",
      "agent1 return is:  0.8042688705856403\n",
      "agent2 return is:  10.402553305289874\n",
      "Batch 1069 finished:\n",
      "agent1 return is:  0.7059932461242528\n",
      "agent2 return is:  10.601946322072944\n",
      "Batch 1070 finished:\n",
      "agent1 return is:  0.7161758923802184\n",
      "agent2 return is:  10.528947277391756\n",
      "Batch 1071 finished:\n",
      "agent1 return is:  0.6818716960942164\n",
      "agent2 return is:  10.4153492056201\n",
      "Batch 1072 finished:\n",
      "agent1 return is:  0.7644221920867046\n",
      "agent2 return is:  10.42091991296186\n",
      "Batch 1073 finished:\n",
      "agent1 return is:  0.7018936468910313\n",
      "agent2 return is:  10.38073022915467\n",
      "Batch 1074 finished:\n",
      "agent1 return is:  0.776415882179701\n",
      "agent2 return is:  10.35440992037381\n",
      "Batch 1075 finished:\n",
      "agent1 return is:  0.7963744867516518\n",
      "agent2 return is:  10.34691264465873\n",
      "Batch 1076 finished:\n",
      "agent1 return is:  0.8021192654371081\n",
      "agent2 return is:  10.434360698303243\n",
      "Batch 1077 finished:\n",
      "agent1 return is:  0.7577216084849014\n",
      "agent2 return is:  10.422055742949567\n",
      "Batch 1078 finished:\n",
      "agent1 return is:  0.7208093722365949\n",
      "agent2 return is:  10.423685685622923\n",
      "Batch 1079 finished:\n",
      "agent1 return is:  0.7130974804322752\n",
      "agent2 return is:  10.32096819042556\n",
      "Batch 1080 finished:\n",
      "agent1 return is:  0.6301164261838754\n",
      "agent2 return is:  10.393608480876445\n",
      "Batch 1081 finished:\n",
      "agent1 return is:  0.6763578915763144\n",
      "agent2 return is:  10.400765452480508\n",
      "Batch 1082 finished:\n",
      "agent1 return is:  0.7851608635107351\n",
      "agent2 return is:  10.354015399640888\n",
      "Batch 1083 finished:\n",
      "agent1 return is:  0.8315114633167098\n",
      "agent2 return is:  10.450069621947755\n",
      "Batch 1084 finished:\n",
      "agent1 return is:  0.86950908925115\n",
      "agent2 return is:  10.42618796492657\n",
      "Batch 1085 finished:\n",
      "agent1 return is:  0.8816207584209701\n",
      "agent2 return is:  10.31529128891685\n",
      "Batch 1086 finished:\n",
      "agent1 return is:  0.7259905166866703\n",
      "agent2 return is:  10.32194678879869\n",
      "Batch 1087 finished:\n",
      "agent1 return is:  0.5131479731273616\n",
      "agent2 return is:  10.03119644990639\n",
      "Batch 1088 finished:\n",
      "agent1 return is:  0.7677545304714442\n",
      "agent2 return is:  10.113551567013495\n",
      "Batch 1089 finished:\n",
      "agent1 return is:  0.8591261038130984\n",
      "agent2 return is:  10.038987326817859\n",
      "Batch 1090 finished:\n",
      "agent1 return is:  0.8499563709158063\n",
      "agent2 return is:  10.29034264025843\n",
      "Batch 1091 finished:\n",
      "agent1 return is:  0.4848201204274097\n",
      "agent2 return is:  10.377521806602562\n",
      "Batch 1092 finished:\n",
      "agent1 return is:  0.7258143891426891\n",
      "agent2 return is:  10.14657577831774\n",
      "Batch 1093 finished:\n",
      "agent1 return is:  0.6557087224701932\n",
      "agent2 return is:  10.522086233291855\n",
      "Batch 1094 finished:\n",
      "agent1 return is:  0.520457679384511\n",
      "agent2 return is:  10.559974161853951\n",
      "Batch 1095 finished:\n",
      "agent1 return is:  0.6416226848650567\n",
      "agent2 return is:  10.572291907843868\n",
      "Batch 1096 finished:\n",
      "agent1 return is:  0.6484424906452666\n",
      "agent2 return is:  10.424201776736382\n",
      "Batch 1097 finished:\n",
      "agent1 return is:  0.6859703021434422\n",
      "agent2 return is:  10.395051263640411\n",
      "Batch 1098 finished:\n",
      "agent1 return is:  0.7738843125139945\n",
      "agent2 return is:  10.658674332471383\n",
      "Batch 1099 finished:\n",
      "agent1 return is:  0.5551251638505625\n",
      "agent2 return is:  10.690941967087221\n",
      "Batch 1100 finished:\n",
      "agent1 return is:  0.8283384396333594\n",
      "agent2 return is:  10.56392594699949\n",
      "Batch 1101 finished:\n",
      "agent1 return is:  0.8918232970786799\n",
      "agent2 return is:  10.450497978983929\n",
      "Batch 1102 finished:\n",
      "agent1 return is:  0.5614346852179724\n",
      "agent2 return is:  10.747685991210496\n",
      "Batch 1103 finished:\n",
      "agent1 return is:  0.9113960786462565\n",
      "agent2 return is:  10.564275531396195\n",
      "Batch 1104 finished:\n",
      "agent1 return is:  0.7991132641130919\n",
      "agent2 return is:  10.494387892778088\n",
      "Batch 1105 finished:\n",
      "agent1 return is:  0.658229209470941\n",
      "agent2 return is:  10.86366912460004\n",
      "Batch 1106 finished:\n",
      "agent1 return is:  0.8210320085372291\n",
      "agent2 return is:  10.574295855524877\n",
      "Batch 1107 finished:\n",
      "agent1 return is:  0.4770676070571438\n",
      "agent2 return is:  10.778477030313985\n",
      "Batch 1108 finished:\n",
      "agent1 return is:  0.7361480202526325\n",
      "agent2 return is:  10.659977650695048\n",
      "Batch 1109 finished:\n",
      "agent1 return is:  0.9093475254022582\n",
      "agent2 return is:  10.597062492334555\n",
      "Batch 1110 finished:\n",
      "agent1 return is:  0.8943175995455224\n",
      "agent2 return is:  10.781151046099026\n",
      "Batch 1111 finished:\n",
      "agent1 return is:  0.8674289267325697\n",
      "agent2 return is:  10.674488069375595\n",
      "Batch 1112 finished:\n",
      "agent1 return is:  0.736478666116539\n",
      "agent2 return is:  10.835837026107889\n",
      "Batch 1113 finished:\n",
      "agent1 return is:  0.6761020429614099\n",
      "agent2 return is:  10.838689033842886\n",
      "Batch 1114 finished:\n",
      "agent1 return is:  0.7687061119186858\n",
      "agent2 return is:  10.689823917266498\n",
      "Batch 1115 finished:\n",
      "agent1 return is:  0.8455526424621789\n",
      "agent2 return is:  10.88953205365014\n",
      "Batch 1116 finished:\n",
      "agent1 return is:  0.8911654516816596\n",
      "agent2 return is:  10.797020882667585\n",
      "Batch 1117 finished:\n",
      "agent1 return is:  0.8412428747498082\n",
      "agent2 return is:  10.852368389341589\n",
      "Batch 1118 finished:\n",
      "agent1 return is:  0.7974987032223411\n",
      "agent2 return is:  10.69730447820174\n",
      "Batch 1119 finished:\n",
      "agent1 return is:  0.6884275114729361\n",
      "agent2 return is:  10.815289384792319\n",
      "Batch 1120 finished:\n",
      "agent1 return is:  0.7072144982595373\n",
      "agent2 return is:  10.709982291692274\n",
      "Batch 1121 finished:\n",
      "agent1 return is:  0.7439587977188721\n",
      "agent2 return is:  10.839803731575058\n",
      "Batch 1122 finished:\n",
      "agent1 return is:  0.8071616422723225\n",
      "agent2 return is:  10.833011145200867\n",
      "Batch 1123 finished:\n",
      "agent1 return is:  0.8404885117902006\n",
      "agent2 return is:  10.7865638936554\n",
      "Batch 1124 finished:\n",
      "agent1 return is:  0.7333713059629168\n",
      "agent2 return is:  10.80443655078044\n",
      "Batch 1125 finished:\n",
      "agent1 return is:  0.586142756406402\n",
      "agent2 return is:  10.782012767711402\n",
      "Batch 1126 finished:\n",
      "agent1 return is:  0.7655588375730356\n",
      "agent2 return is:  10.759631571519746\n",
      "Batch 1127 finished:\n",
      "agent1 return is:  0.5438656706101264\n",
      "agent2 return is:  10.778669499610551\n",
      "Batch 1128 finished:\n",
      "agent1 return is:  0.6009785359827606\n",
      "agent2 return is:  10.761026219669645\n",
      "Batch 1129 finished:\n",
      "agent1 return is:  0.5342980366955743\n",
      "agent2 return is:  10.712985614441656\n",
      "Batch 1130 finished:\n",
      "agent1 return is:  0.5887897427683743\n",
      "agent2 return is:  10.661162103367115\n",
      "Batch 1131 finished:\n",
      "agent1 return is:  0.6424621192827138\n",
      "agent2 return is:  10.713851108886086\n",
      "Batch 1132 finished:\n",
      "agent1 return is:  0.7341716479688889\n",
      "agent2 return is:  10.774176118941904\n",
      "Batch 1133 finished:\n",
      "agent1 return is:  0.6149597473983914\n",
      "agent2 return is:  10.689748324361702\n",
      "Batch 1134 finished:\n",
      "agent1 return is:  0.5794496598096234\n",
      "agent2 return is:  10.693768937308777\n",
      "Batch 1135 finished:\n",
      "agent1 return is:  0.60966016764361\n",
      "agent2 return is:  10.712443385335833\n",
      "Batch 1136 finished:\n",
      "agent1 return is:  0.608244942971431\n",
      "agent2 return is:  10.617646131019153\n",
      "Batch 1137 finished:\n",
      "agent1 return is:  0.7150126562181469\n",
      "agent2 return is:  10.66386658006848\n",
      "Batch 1138 finished:\n",
      "agent1 return is:  0.6893929147042972\n",
      "agent2 return is:  10.760709986632499\n",
      "Batch 1139 finished:\n",
      "agent1 return is:  0.8978995525847777\n",
      "agent2 return is:  10.795903082625722\n",
      "Batch 1140 finished:\n",
      "agent1 return is:  0.679925184348755\n",
      "agent2 return is:  10.73191352813274\n",
      "Batch 1141 finished:\n",
      "agent1 return is:  0.7162660856255247\n",
      "agent2 return is:  10.862817064460264\n",
      "Batch 1142 finished:\n",
      "agent1 return is:  0.7164500904793949\n",
      "agent2 return is:  10.868685027353678\n",
      "Batch 1143 finished:\n",
      "agent1 return is:  0.6869353831817944\n",
      "agent2 return is:  10.925291794869118\n",
      "Batch 1144 finished:\n",
      "agent1 return is:  0.7423841679912705\n",
      "agent2 return is:  10.894319457871639\n",
      "Batch 1145 finished:\n",
      "agent1 return is:  0.6375272012524553\n",
      "agent2 return is:  10.731334530139776\n",
      "Batch 1146 finished:\n",
      "agent1 return is:  0.7431599881856691\n",
      "agent2 return is:  10.838127261318306\n",
      "Batch 1147 finished:\n",
      "agent1 return is:  0.6867903963364173\n",
      "agent2 return is:  10.789615154054909\n",
      "Batch 1148 finished:\n",
      "agent1 return is:  0.7160998667018571\n",
      "agent2 return is:  10.665413347738703\n",
      "Batch 1149 finished:\n",
      "agent1 return is:  0.6928364274039414\n",
      "agent2 return is:  10.633318462729742\n",
      "Batch 1150 finished:\n",
      "agent1 return is:  0.6336361297731783\n",
      "agent2 return is:  10.672055697711926\n",
      "Batch 1151 finished:\n",
      "agent1 return is:  0.48874389019015063\n",
      "agent2 return is:  10.696029395348944\n",
      "Batch 1152 finished:\n",
      "agent1 return is:  0.6683448434335653\n",
      "agent2 return is:  10.655823459375503\n",
      "Batch 1153 finished:\n",
      "agent1 return is:  0.6807319354782091\n",
      "agent2 return is:  10.593520205646959\n",
      "Batch 1154 finished:\n",
      "agent1 return is:  0.6893691945288385\n",
      "agent2 return is:  10.684915346397862\n",
      "Batch 1155 finished:\n",
      "agent1 return is:  0.7276773696000398\n",
      "agent2 return is:  10.742172097470132\n",
      "Batch 1156 finished:\n",
      "agent1 return is:  0.7443124081916084\n",
      "agent2 return is:  10.648296124086617\n",
      "Batch 1157 finished:\n",
      "agent1 return is:  0.8752496868294399\n",
      "agent2 return is:  10.810943778553433\n",
      "Batch 1158 finished:\n",
      "agent1 return is:  0.7925217628519838\n",
      "agent2 return is:  10.766487921840987\n",
      "Batch 1159 finished:\n",
      "agent1 return is:  0.82635315423033\n",
      "agent2 return is:  10.707975588432681\n",
      "Batch 1160 finished:\n",
      "agent1 return is:  0.8125311005361429\n",
      "agent2 return is:  10.716475335708978\n",
      "Batch 1161 finished:\n",
      "agent1 return is:  0.7134753396259405\n",
      "agent2 return is:  10.775775364614987\n",
      "Batch 1162 finished:\n",
      "agent1 return is:  0.8457990799551223\n",
      "agent2 return is:  10.783422315034851\n",
      "Batch 1163 finished:\n",
      "agent1 return is:  0.4872243024021426\n",
      "agent2 return is:  10.803328307876823\n",
      "Batch 1164 finished:\n",
      "agent1 return is:  0.7541145966950537\n",
      "agent2 return is:  10.7418110995224\n",
      "Batch 1165 finished:\n",
      "agent1 return is:  0.5949535355681876\n",
      "agent2 return is:  10.85127796206861\n",
      "Batch 1166 finished:\n",
      "agent1 return is:  0.4196841687774395\n",
      "agent2 return is:  10.828855915659188\n",
      "Batch 1167 finished:\n",
      "agent1 return is:  0.6757819865065329\n",
      "agent2 return is:  10.765924146523862\n",
      "Batch 1168 finished:\n",
      "agent1 return is:  0.7335366482711341\n",
      "agent2 return is:  10.76611289459786\n",
      "Batch 1169 finished:\n",
      "agent1 return is:  0.7977303390421968\n",
      "agent2 return is:  10.710881889916314\n",
      "Batch 1170 finished:\n",
      "agent1 return is:  0.7439728166289707\n",
      "agent2 return is:  10.751187075887028\n",
      "Batch 1171 finished:\n",
      "agent1 return is:  0.5818976330102307\n",
      "agent2 return is:  10.781934675828124\n",
      "Batch 1172 finished:\n",
      "agent1 return is:  0.8477514722031521\n",
      "agent2 return is:  10.81794547316773\n",
      "Batch 1173 finished:\n",
      "agent1 return is:  0.5481867105494469\n",
      "agent2 return is:  10.911518704414306\n",
      "Batch 1174 finished:\n",
      "agent1 return is:  0.513712109973048\n",
      "agent2 return is:  10.875928283215282\n",
      "Batch 1175 finished:\n",
      "agent1 return is:  0.5478201165676277\n",
      "agent2 return is:  10.862039712542256\n",
      "Batch 1176 finished:\n",
      "agent1 return is:  0.47975240075248643\n",
      "agent2 return is:  10.81297062608021\n",
      "Batch 1177 finished:\n",
      "agent1 return is:  0.5865147959134218\n",
      "agent2 return is:  10.781732704897289\n",
      "Batch 1178 finished:\n",
      "agent1 return is:  0.4844142804974997\n",
      "agent2 return is:  10.807862873271674\n",
      "Batch 1179 finished:\n",
      "agent1 return is:  0.5212118258855284\n",
      "agent2 return is:  10.845180207953597\n",
      "Batch 1180 finished:\n",
      "agent1 return is:  0.36762402975285\n",
      "agent2 return is:  10.954804012836412\n",
      "Batch 1181 finished:\n",
      "agent1 return is:  0.4285636742812314\n",
      "agent2 return is:  10.979206451362213\n",
      "Batch 1182 finished:\n",
      "agent1 return is:  0.4588240388618707\n",
      "agent2 return is:  11.064924810561529\n",
      "Batch 1183 finished:\n",
      "agent1 return is:  0.5655328991098458\n",
      "agent2 return is:  11.078830533338389\n",
      "Batch 1184 finished:\n",
      "agent1 return is:  0.3470308504175241\n",
      "agent2 return is:  11.062860051103547\n",
      "Batch 1185 finished:\n",
      "agent1 return is:  0.47761595430174086\n",
      "agent2 return is:  11.047111712914603\n",
      "Batch 1186 finished:\n",
      "agent1 return is:  0.5831553358023809\n",
      "agent2 return is:  11.032649658577917\n",
      "Batch 1187 finished:\n",
      "agent1 return is:  0.49667699091379947\n",
      "agent2 return is:  11.149296959912169\n",
      "Batch 1188 finished:\n",
      "agent1 return is:  0.6520172848558451\n",
      "agent2 return is:  11.14741126316147\n",
      "Batch 1189 finished:\n",
      "agent1 return is:  0.44852277383826705\n",
      "agent2 return is:  11.15039096419249\n",
      "Batch 1190 finished:\n",
      "agent1 return is:  0.6068392734378112\n",
      "agent2 return is:  11.21552566183664\n",
      "Batch 1191 finished:\n",
      "agent1 return is:  0.6543036449606852\n",
      "agent2 return is:  11.268417430858296\n",
      "Batch 1192 finished:\n",
      "agent1 return is:  0.5683131699135714\n",
      "agent2 return is:  11.265884668337293\n",
      "Batch 1193 finished:\n",
      "agent1 return is:  0.6719807756407336\n",
      "agent2 return is:  11.108616987612631\n",
      "Batch 1194 finished:\n",
      "agent1 return is:  0.6263278199639364\n",
      "agent2 return is:  11.013865160369892\n",
      "Batch 1195 finished:\n",
      "agent1 return is:  0.5143038380000304\n",
      "agent2 return is:  11.32346219964549\n",
      "Batch 1196 finished:\n",
      "agent1 return is:  0.6957305544362341\n",
      "agent2 return is:  11.302271240215802\n",
      "Batch 1197 finished:\n",
      "agent1 return is:  0.6847056489876315\n",
      "agent2 return is:  11.364399760977822\n",
      "Batch 1198 finished:\n",
      "agent1 return is:  0.35281420867797064\n",
      "agent2 return is:  11.272458035683984\n",
      "Batch 1199 finished:\n",
      "agent1 return is:  0.6083627194858728\n",
      "agent2 return is:  11.393272828744255\n",
      "Batch 1200 finished:\n",
      "agent1 return is:  0.6660698476981051\n",
      "agent2 return is:  11.366716787017994\n",
      "Batch 1201 finished:\n",
      "agent1 return is:  0.6831936660470501\n",
      "agent2 return is:  11.375452677286386\n",
      "Batch 1202 finished:\n",
      "agent1 return is:  0.630811490088022\n",
      "agent2 return is:  11.3708705402774\n",
      "Batch 1203 finished:\n",
      "agent1 return is:  0.7400584403490509\n",
      "agent2 return is:  11.437637732912762\n",
      "Batch 1204 finished:\n",
      "agent1 return is:  0.6232062445326381\n",
      "agent2 return is:  11.38458540375574\n",
      "Batch 1205 finished:\n",
      "agent1 return is:  0.651145353931359\n",
      "agent2 return is:  11.424901650537093\n",
      "Batch 1206 finished:\n",
      "agent1 return is:  0.4775564031193231\n",
      "agent2 return is:  11.321019533863296\n",
      "Batch 1207 finished:\n",
      "agent1 return is:  0.5359321049458112\n",
      "agent2 return is:  11.204724350067924\n",
      "Batch 1208 finished:\n",
      "agent1 return is:  0.5527069857987523\n",
      "agent2 return is:  11.40395801885477\n",
      "Batch 1209 finished:\n",
      "agent1 return is:  0.5839384031992854\n",
      "agent2 return is:  11.363967440087482\n",
      "Batch 1210 finished:\n",
      "agent1 return is:  0.5708660374732364\n",
      "agent2 return is:  11.406830170125527\n",
      "Batch 1211 finished:\n",
      "agent1 return is:  0.6071225492211256\n",
      "agent2 return is:  11.481392021568402\n",
      "Batch 1212 finished:\n",
      "agent1 return is:  0.39188157501665527\n",
      "agent2 return is:  11.286789181013225\n",
      "Batch 1213 finished:\n",
      "agent1 return is:  0.5252592008117312\n",
      "agent2 return is:  11.503846766261336\n",
      "Batch 1214 finished:\n",
      "agent1 return is:  0.5246755318698282\n",
      "agent2 return is:  11.457029282747856\n",
      "Batch 1215 finished:\n",
      "agent1 return is:  0.6129994639079052\n",
      "agent2 return is:  11.500257801437822\n",
      "Batch 1216 finished:\n",
      "agent1 return is:  0.46506707918434037\n",
      "agent2 return is:  11.182629417906796\n",
      "Batch 1217 finished:\n",
      "agent1 return is:  0.3438631181367541\n",
      "agent2 return is:  11.554962755235342\n",
      "Batch 1218 finished:\n",
      "agent1 return is:  0.4200373264938709\n",
      "agent2 return is:  11.232402136474503\n",
      "Batch 1219 finished:\n",
      "agent1 return is:  0.4437050415940474\n",
      "agent2 return is:  11.567991081784074\n",
      "Batch 1220 finished:\n",
      "agent1 return is:  0.4575464128586387\n",
      "agent2 return is:  11.541243149959373\n",
      "Batch 1221 finished:\n",
      "agent1 return is:  0.5056902435522463\n",
      "agent2 return is:  11.377003262857226\n",
      "Batch 1222 finished:\n",
      "agent1 return is:  0.4394246471646215\n",
      "agent2 return is:  11.553225835075308\n",
      "Batch 1223 finished:\n",
      "agent1 return is:  0.5499469600759517\n",
      "agent2 return is:  11.53963007653725\n",
      "Batch 1224 finished:\n",
      "agent1 return is:  0.5000404622434803\n",
      "agent2 return is:  11.537997538085275\n",
      "Batch 1225 finished:\n",
      "agent1 return is:  0.5197884971230862\n",
      "agent2 return is:  11.383123902616374\n",
      "Batch 1226 finished:\n",
      "agent1 return is:  0.4834838745230145\n",
      "agent2 return is:  11.39270505217612\n",
      "Batch 1227 finished:\n",
      "agent1 return is:  0.5405844503455914\n",
      "agent2 return is:  11.447075179656906\n",
      "Batch 1228 finished:\n",
      "agent1 return is:  0.49232892392322997\n",
      "agent2 return is:  11.542462764661686\n",
      "Batch 1229 finished:\n",
      "agent1 return is:  0.4773901983749962\n",
      "agent2 return is:  11.537958176831646\n",
      "Batch 1230 finished:\n",
      "agent1 return is:  0.3334491576054117\n",
      "agent2 return is:  11.565740734688777\n",
      "Batch 1231 finished:\n",
      "agent1 return is:  0.5246428689072095\n",
      "agent2 return is:  11.621442753068997\n",
      "Batch 1232 finished:\n",
      "agent1 return is:  0.5915088175431382\n",
      "agent2 return is:  11.66116544216274\n",
      "Batch 1233 finished:\n",
      "agent1 return is:  0.35603583375680325\n",
      "agent2 return is:  11.725290385973281\n",
      "Batch 1234 finished:\n",
      "agent1 return is:  0.5067601549569118\n",
      "agent2 return is:  11.737838074693034\n",
      "Batch 1235 finished:\n",
      "agent1 return is:  0.5883733683190674\n",
      "agent2 return is:  11.765641122595934\n",
      "Batch 1236 finished:\n",
      "agent1 return is:  0.27417822208786996\n",
      "agent2 return is:  11.64593642639446\n",
      "Batch 1237 finished:\n",
      "agent1 return is:  0.2800021525864687\n",
      "agent2 return is:  11.759497022275617\n",
      "Batch 1238 finished:\n",
      "agent1 return is:  0.5494712586115479\n",
      "agent2 return is:  11.813228638470244\n",
      "Batch 1239 finished:\n",
      "agent1 return is:  0.6337712914907525\n",
      "agent2 return is:  11.716373852665953\n",
      "Batch 1240 finished:\n",
      "agent1 return is:  0.5412602487695941\n",
      "agent2 return is:  11.828646749873254\n",
      "Batch 1241 finished:\n",
      "agent1 return is:  0.615639840283074\n",
      "agent2 return is:  11.696567599255996\n",
      "Batch 1242 finished:\n",
      "agent1 return is:  0.28996273542772644\n",
      "agent2 return is:  11.78785089772392\n",
      "Batch 1243 finished:\n",
      "agent1 return is:  0.3653557515621402\n",
      "agent2 return is:  11.64385978958272\n",
      "Batch 1244 finished:\n",
      "agent1 return is:  0.37295651207489205\n",
      "agent2 return is:  11.717807555022773\n",
      "Batch 1245 finished:\n",
      "agent1 return is:  0.7261629589360323\n",
      "agent2 return is:  11.677745375573458\n",
      "Batch 1246 finished:\n",
      "agent1 return is:  0.333126184720053\n",
      "agent2 return is:  11.605930529857599\n",
      "Batch 1247 finished:\n",
      "agent1 return is:  0.3888430760640579\n",
      "agent2 return is:  11.796703707879338\n",
      "Batch 1248 finished:\n",
      "agent1 return is:  0.6044161965453886\n",
      "agent2 return is:  11.83506610064529\n",
      "Batch 1249 finished:\n",
      "agent1 return is:  0.46251062185020503\n",
      "agent2 return is:  11.82684719249633\n",
      "Batch 1250 finished:\n",
      "agent1 return is:  0.2976541491627667\n",
      "agent2 return is:  11.762480507548982\n",
      "Batch 1251 finished:\n",
      "agent1 return is:  0.6675349829087333\n",
      "agent2 return is:  11.821011938945887\n",
      "Batch 1252 finished:\n",
      "agent1 return is:  0.7329531667422091\n",
      "agent2 return is:  11.713155895715722\n",
      "Batch 1253 finished:\n",
      "agent1 return is:  0.3266538853008868\n",
      "agent2 return is:  11.534454832383982\n",
      "Batch 1254 finished:\n",
      "agent1 return is:  0.5783955581857732\n",
      "agent2 return is:  11.741106577984565\n",
      "Batch 1255 finished:\n",
      "agent1 return is:  0.6967895837557866\n",
      "agent2 return is:  11.924097952575828\n",
      "Batch 1256 finished:\n",
      "agent1 return is:  0.3558089471453667\n",
      "agent2 return is:  11.818846646118011\n",
      "Batch 1257 finished:\n",
      "agent1 return is:  0.4569640178646263\n",
      "agent2 return is:  11.815577209594265\n",
      "Batch 1258 finished:\n",
      "agent1 return is:  0.5147799490478517\n",
      "agent2 return is:  11.802636638174139\n",
      "Batch 1259 finished:\n",
      "agent1 return is:  0.37264385230582964\n",
      "agent2 return is:  11.95587197250937\n",
      "Batch 1260 finished:\n",
      "agent1 return is:  0.4622889351396088\n",
      "agent2 return is:  11.954021872887363\n",
      "Batch 1261 finished:\n",
      "agent1 return is:  0.39333175925198516\n",
      "agent2 return is:  11.930720981552152\n",
      "Batch 1262 finished:\n",
      "agent1 return is:  0.20063434155527357\n",
      "agent2 return is:  11.993361139454457\n",
      "Batch 1263 finished:\n",
      "agent1 return is:  0.08125711861128418\n",
      "agent2 return is:  11.953025060384396\n",
      "Batch 1264 finished:\n",
      "agent1 return is:  0.16600436491119924\n",
      "agent2 return is:  12.029602799697983\n",
      "Batch 1265 finished:\n",
      "agent1 return is:  0.04207284727573443\n",
      "agent2 return is:  11.938821303592874\n",
      "Batch 1266 finished:\n",
      "agent1 return is:  0.3143974172336984\n",
      "agent2 return is:  12.04730607729995\n",
      "Batch 1267 finished:\n",
      "agent1 return is:  0.18906439597612068\n",
      "agent2 return is:  12.031150584907195\n",
      "Batch 1268 finished:\n",
      "agent1 return is:  0.26855632871372714\n",
      "agent2 return is:  11.840902885303123\n",
      "Batch 1269 finished:\n",
      "agent1 return is:  0.30350662256205807\n",
      "agent2 return is:  11.975208879693984\n",
      "Batch 1270 finished:\n",
      "agent1 return is:  0.33401034507925187\n",
      "agent2 return is:  12.01492476804015\n",
      "Batch 1271 finished:\n",
      "agent1 return is:  0.4149003894375892\n",
      "agent2 return is:  12.092465345647817\n",
      "Batch 1272 finished:\n",
      "agent1 return is:  0.24603085105077502\n",
      "agent2 return is:  12.029016266779127\n",
      "Batch 1273 finished:\n",
      "agent1 return is:  0.1753465400877327\n",
      "agent2 return is:  11.581010135590923\n",
      "Batch 1274 finished:\n",
      "agent1 return is:  0.43465639678651957\n",
      "agent2 return is:  11.860023030519844\n",
      "Batch 1275 finished:\n",
      "agent1 return is:  0.44060568312812676\n",
      "agent2 return is:  12.001484413188717\n",
      "Batch 1276 finished:\n",
      "agent1 return is:  0.2646255269950028\n",
      "agent2 return is:  12.006883335677042\n",
      "Batch 1277 finished:\n",
      "agent1 return is:  0.2824902016047962\n",
      "agent2 return is:  11.826602944005636\n",
      "Batch 1278 finished:\n",
      "agent1 return is:  0.13824508564272048\n",
      "agent2 return is:  12.050348706185538\n",
      "Batch 1279 finished:\n",
      "agent1 return is:  0.32648827630419175\n",
      "agent2 return is:  11.464565497976901\n",
      "Batch 1280 finished:\n",
      "agent1 return is:  0.4422467705515517\n",
      "agent2 return is:  11.87020875742176\n",
      "Batch 1281 finished:\n",
      "agent1 return is:  0.2853513397431696\n",
      "agent2 return is:  11.843039414204426\n",
      "Batch 1282 finished:\n",
      "agent1 return is:  0.16311548589859645\n",
      "agent2 return is:  11.80508582582275\n",
      "Batch 1283 finished:\n",
      "agent1 return is:  -0.006538931209004228\n",
      "agent2 return is:  11.599444885638881\n",
      "Batch 1284 finished:\n",
      "agent1 return is:  0.35585491655872237\n",
      "agent2 return is:  11.736996114906642\n",
      "Batch 1285 finished:\n",
      "agent1 return is:  0.3553149716154736\n",
      "agent2 return is:  11.88050049218754\n",
      "Batch 1286 finished:\n",
      "agent1 return is:  0.23648344529835644\n",
      "agent2 return is:  11.769802915268947\n",
      "Batch 1287 finished:\n",
      "agent1 return is:  0.35691684138252017\n",
      "agent2 return is:  11.791154669740408\n",
      "Batch 1288 finished:\n",
      "agent1 return is:  0.2538385465604568\n",
      "agent2 return is:  11.724039079797725\n",
      "Batch 1289 finished:\n",
      "agent1 return is:  0.14481554479644698\n",
      "agent2 return is:  11.88290605183597\n",
      "Batch 1290 finished:\n",
      "agent1 return is:  0.40720380948873425\n",
      "agent2 return is:  11.84715091731238\n",
      "Batch 1291 finished:\n",
      "agent1 return is:  0.3222600796011674\n",
      "agent2 return is:  11.86180915385604\n",
      "Batch 1292 finished:\n",
      "agent1 return is:  0.14048559480897363\n",
      "agent2 return is:  11.606239790074547\n",
      "Batch 1293 finished:\n",
      "agent1 return is:  0.42427731254512424\n",
      "agent2 return is:  11.902546210774446\n",
      "Batch 1294 finished:\n",
      "agent1 return is:  0.4334687995649318\n",
      "agent2 return is:  11.817059215129774\n",
      "Batch 1295 finished:\n",
      "agent1 return is:  -0.1608033699064803\n",
      "agent2 return is:  11.97043037541944\n",
      "Batch 1296 finished:\n",
      "agent1 return is:  0.03086158182827836\n",
      "agent2 return is:  11.895889453015975\n",
      "Batch 1297 finished:\n",
      "agent1 return is:  0.318514789059992\n",
      "agent2 return is:  11.873577342887348\n",
      "Batch 1298 finished:\n",
      "agent1 return is:  0.4944751069682364\n",
      "agent2 return is:  11.68786448095238\n",
      "Batch 1299 finished:\n",
      "agent1 return is:  0.4390071053976542\n",
      "agent2 return is:  11.946713391864884\n",
      "Batch 1300 finished:\n",
      "agent1 return is:  0.3099217186417359\n",
      "agent2 return is:  11.88031637328697\n",
      "Batch 1301 finished:\n",
      "agent1 return is:  0.1662036645331682\n",
      "agent2 return is:  11.717321767906313\n",
      "Batch 1302 finished:\n",
      "agent1 return is:  0.605039524792377\n",
      "agent2 return is:  11.525478437486154\n",
      "Batch 1303 finished:\n",
      "agent1 return is:  0.4518221296278622\n",
      "agent2 return is:  11.923095080496678\n",
      "Batch 1304 finished:\n",
      "agent1 return is:  0.3377953065333357\n",
      "agent2 return is:  11.991692958715305\n",
      "Batch 1305 finished:\n",
      "agent1 return is:  0.4599079314448769\n",
      "agent2 return is:  11.868663548319336\n",
      "Batch 1306 finished:\n",
      "agent1 return is:  0.5685279495116223\n",
      "agent2 return is:  11.978873206255821\n",
      "Batch 1307 finished:\n",
      "agent1 return is:  0.512319823505182\n",
      "agent2 return is:  11.779132071939603\n",
      "Batch 1308 finished:\n",
      "agent1 return is:  0.4236629492924025\n",
      "agent2 return is:  11.593051588390685\n",
      "Batch 1309 finished:\n",
      "agent1 return is:  0.3439891564715365\n",
      "agent2 return is:  11.838401536763973\n",
      "Batch 1310 finished:\n",
      "agent1 return is:  0.5820065849686076\n",
      "agent2 return is:  11.788832164028843\n",
      "Batch 1311 finished:\n",
      "agent1 return is:  0.5317037749532381\n",
      "agent2 return is:  11.96744209791381\n",
      "Batch 1312 finished:\n",
      "agent1 return is:  0.48222061606521194\n",
      "agent2 return is:  11.807240264930904\n",
      "Batch 1313 finished:\n",
      "agent1 return is:  0.24379380499744008\n",
      "agent2 return is:  11.923982478371737\n",
      "Batch 1314 finished:\n",
      "agent1 return is:  0.2015655726778478\n",
      "agent2 return is:  12.003662953578617\n",
      "Batch 1315 finished:\n",
      "agent1 return is:  0.3887432308122973\n",
      "agent2 return is:  11.820799202925002\n",
      "Batch 1316 finished:\n",
      "agent1 return is:  0.4515544256068648\n",
      "agent2 return is:  11.84857332178985\n",
      "Batch 1317 finished:\n",
      "agent1 return is:  0.5170313026740347\n",
      "agent2 return is:  12.003947537511923\n",
      "Batch 1318 finished:\n",
      "agent1 return is:  0.21989591887403764\n",
      "agent2 return is:  11.930999189248048\n",
      "Batch 1319 finished:\n",
      "agent1 return is:  0.39592604025580136\n",
      "agent2 return is:  11.930290488213947\n",
      "Batch 1320 finished:\n",
      "agent1 return is:  0.5541697602511502\n",
      "agent2 return is:  12.078321626123003\n",
      "Batch 1321 finished:\n",
      "agent1 return is:  0.5029029149178617\n",
      "agent2 return is:  11.97597417102537\n",
      "Batch 1322 finished:\n",
      "agent1 return is:  0.44881559992987263\n",
      "agent2 return is:  12.147878625824703\n",
      "Batch 1323 finished:\n",
      "agent1 return is:  0.4751797620966014\n",
      "agent2 return is:  12.123139956998775\n",
      "Batch 1324 finished:\n",
      "agent1 return is:  0.21054804549389589\n",
      "agent2 return is:  12.003264652373609\n",
      "Batch 1325 finished:\n",
      "agent1 return is:  0.5338297816941533\n",
      "agent2 return is:  12.139466181316447\n",
      "Batch 1326 finished:\n",
      "agent1 return is:  0.36466437462111223\n",
      "agent2 return is:  12.123727132599758\n",
      "Batch 1327 finished:\n",
      "agent1 return is:  0.6270348722493092\n",
      "agent2 return is:  12.213373931104709\n",
      "Batch 1328 finished:\n",
      "agent1 return is:  0.23058101066041325\n",
      "agent2 return is:  12.259681020660302\n",
      "Batch 1329 finished:\n",
      "agent1 return is:  0.2800454857656811\n",
      "agent2 return is:  12.12214642110445\n",
      "Batch 1330 finished:\n",
      "agent1 return is:  0.2325118002957947\n",
      "agent2 return is:  12.265431012397018\n",
      "Batch 1331 finished:\n",
      "agent1 return is:  0.45213119572626537\n",
      "agent2 return is:  12.240238323086245\n",
      "Batch 1332 finished:\n",
      "agent1 return is:  0.49253625774919646\n",
      "agent2 return is:  12.338387225227148\n",
      "Batch 1333 finished:\n",
      "agent1 return is:  0.21985341531595579\n",
      "agent2 return is:  12.2484318033197\n",
      "Batch 1334 finished:\n",
      "agent1 return is:  0.27271048683823607\n",
      "agent2 return is:  12.163690898325575\n",
      "Batch 1335 finished:\n",
      "agent1 return is:  0.24921867469188014\n",
      "agent2 return is:  11.979799549871593\n",
      "Batch 1336 finished:\n",
      "agent1 return is:  0.2830319276889034\n",
      "agent2 return is:  12.05116247483503\n",
      "Batch 1337 finished:\n",
      "agent1 return is:  0.21744471667660298\n",
      "agent2 return is:  12.052464594885132\n",
      "Batch 1338 finished:\n",
      "agent1 return is:  0.2649655826852288\n",
      "agent2 return is:  12.007958021640135\n",
      "Batch 1339 finished:\n",
      "agent1 return is:  0.5219089317670509\n",
      "agent2 return is:  11.99236381084589\n",
      "Batch 1340 finished:\n",
      "agent1 return is:  0.4673657767348407\n",
      "agent2 return is:  11.96846839426516\n",
      "Batch 1341 finished:\n",
      "agent1 return is:  0.416006531524943\n",
      "agent2 return is:  11.901801130898436\n",
      "Batch 1342 finished:\n",
      "agent1 return is:  0.2102857560138398\n",
      "agent2 return is:  11.946825770997169\n",
      "Batch 1343 finished:\n",
      "agent1 return is:  0.42809437888161017\n",
      "agent2 return is:  11.928916059583603\n",
      "Batch 1344 finished:\n",
      "agent1 return is:  0.5066280813775061\n",
      "agent2 return is:  11.971254033374082\n",
      "Batch 1345 finished:\n",
      "agent1 return is:  0.33970020338517126\n",
      "agent2 return is:  12.057246265847187\n",
      "Batch 1346 finished:\n",
      "agent1 return is:  0.4225030723430101\n",
      "agent2 return is:  12.075687472399526\n",
      "Batch 1347 finished:\n",
      "agent1 return is:  0.31368329785077076\n",
      "agent2 return is:  12.125905074179373\n",
      "Batch 1348 finished:\n",
      "agent1 return is:  0.3950263169972318\n",
      "agent2 return is:  11.978297505346102\n",
      "Batch 1349 finished:\n",
      "agent1 return is:  0.1775376847667818\n",
      "agent2 return is:  11.918998838911016\n",
      "Batch 1350 finished:\n",
      "agent1 return is:  0.150849865924475\n",
      "agent2 return is:  11.971752400574324\n",
      "Batch 1351 finished:\n",
      "agent1 return is:  0.30484887657145465\n",
      "agent2 return is:  11.94814005233309\n",
      "Batch 1352 finished:\n",
      "agent1 return is:  0.14561441928796354\n",
      "agent2 return is:  11.75913846676141\n",
      "Batch 1353 finished:\n",
      "agent1 return is:  0.30445897738549665\n",
      "agent2 return is:  11.85979407149475\n",
      "Batch 1354 finished:\n",
      "agent1 return is:  0.3533865802615038\n",
      "agent2 return is:  11.937169973541867\n",
      "Batch 1355 finished:\n",
      "agent1 return is:  0.11652244084825462\n",
      "agent2 return is:  11.959227582935743\n",
      "Batch 1356 finished:\n",
      "agent1 return is:  0.41757730384518366\n",
      "agent2 return is:  11.9994310583204\n",
      "Batch 1357 finished:\n",
      "agent1 return is:  0.2968417655355708\n",
      "agent2 return is:  11.971295111709987\n",
      "Batch 1358 finished:\n",
      "agent1 return is:  0.3218751930450877\n",
      "agent2 return is:  12.057534585468982\n",
      "Batch 1359 finished:\n",
      "agent1 return is:  0.5143413546763818\n",
      "agent2 return is:  12.064246568615177\n",
      "Batch 1360 finished:\n",
      "agent1 return is:  0.1855561767720221\n",
      "agent2 return is:  11.932405935938391\n",
      "Batch 1361 finished:\n",
      "agent1 return is:  0.4445979087354923\n",
      "agent2 return is:  11.921955035983235\n",
      "Batch 1362 finished:\n",
      "agent1 return is:  0.17736946833493558\n",
      "agent2 return is:  11.851960515268892\n",
      "Batch 1363 finished:\n",
      "agent1 return is:  0.28977571526286716\n",
      "agent2 return is:  11.960596660941746\n",
      "Batch 1364 finished:\n",
      "agent1 return is:  0.005236360736069395\n",
      "agent2 return is:  12.008789174114298\n",
      "Batch 1365 finished:\n",
      "agent1 return is:  0.37606707504965375\n",
      "agent2 return is:  11.963557026690696\n",
      "Batch 1366 finished:\n",
      "agent1 return is:  0.37506942854611997\n",
      "agent2 return is:  11.938202677431736\n",
      "Batch 1367 finished:\n",
      "agent1 return is:  0.4102119769741573\n",
      "agent2 return is:  11.841256533460074\n",
      "Batch 1368 finished:\n",
      "agent1 return is:  0.2763052677060769\n",
      "agent2 return is:  11.954419992380995\n",
      "Batch 1369 finished:\n",
      "agent1 return is:  0.24456230349712427\n",
      "agent2 return is:  12.097348867150492\n",
      "Batch 1370 finished:\n",
      "agent1 return is:  0.38215878351020927\n",
      "agent2 return is:  12.10769143973566\n",
      "Batch 1371 finished:\n",
      "agent1 return is:  0.2984720236660648\n",
      "agent2 return is:  11.910453933717495\n",
      "Batch 1372 finished:\n",
      "agent1 return is:  0.06957225511620313\n",
      "agent2 return is:  12.110186111813956\n",
      "Batch 1373 finished:\n",
      "agent1 return is:  0.42567540037350093\n",
      "agent2 return is:  12.098113516586785\n",
      "Batch 1374 finished:\n",
      "agent1 return is:  0.17218266397561438\n",
      "agent2 return is:  12.197798768703725\n",
      "Batch 1375 finished:\n",
      "agent1 return is:  0.19456471235162212\n",
      "agent2 return is:  11.988495460766984\n",
      "Batch 1376 finished:\n",
      "agent1 return is:  0.42849382730339075\n",
      "agent2 return is:  12.006424523343233\n",
      "Batch 1377 finished:\n",
      "agent1 return is:  0.21622840726655634\n",
      "agent2 return is:  12.155623043859574\n",
      "Batch 1378 finished:\n",
      "agent1 return is:  0.3338689947142087\n",
      "agent2 return is:  12.204364995081278\n",
      "Batch 1379 finished:\n",
      "agent1 return is:  0.24856365871189623\n",
      "agent2 return is:  12.17108195634369\n",
      "Batch 1380 finished:\n",
      "agent1 return is:  0.011121244414960298\n",
      "agent2 return is:  12.197685200379539\n",
      "Batch 1381 finished:\n",
      "agent1 return is:  0.2645268102874492\n",
      "agent2 return is:  12.208008202953309\n",
      "Batch 1382 finished:\n",
      "agent1 return is:  0.3652438346998006\n",
      "agent2 return is:  12.254588289695795\n",
      "Batch 1383 finished:\n",
      "agent1 return is:  0.2728376560997018\n",
      "agent2 return is:  12.23936861361991\n",
      "Batch 1384 finished:\n",
      "agent1 return is:  0.25003712943945344\n",
      "agent2 return is:  12.210205520569541\n",
      "Batch 1385 finished:\n",
      "agent1 return is:  0.25776086767599143\n",
      "agent2 return is:  12.18814576967494\n",
      "Batch 1386 finished:\n",
      "agent1 return is:  0.2892122036586\n",
      "agent2 return is:  12.212987600908455\n",
      "Batch 1387 finished:\n",
      "agent1 return is:  0.20184245547956325\n",
      "agent2 return is:  12.242365616574409\n",
      "Batch 1388 finished:\n",
      "agent1 return is:  0.44222678912821456\n",
      "agent2 return is:  12.156589011997905\n",
      "Batch 1389 finished:\n",
      "agent1 return is:  -0.08458011443080879\n",
      "agent2 return is:  12.293665963014849\n",
      "Batch 1390 finished:\n",
      "agent1 return is:  0.34821143093872325\n",
      "agent2 return is:  12.145091910647892\n",
      "Batch 1391 finished:\n",
      "agent1 return is:  0.2689459177954925\n",
      "agent2 return is:  12.22916166412484\n",
      "Batch 1392 finished:\n",
      "agent1 return is:  0.5088546608070899\n",
      "agent2 return is:  12.256615366489505\n",
      "Batch 1393 finished:\n",
      "agent1 return is:  0.3111436535288603\n",
      "agent2 return is:  11.867518607042584\n",
      "Batch 1394 finished:\n",
      "agent1 return is:  0.27891082719877847\n",
      "agent2 return is:  12.281525754707346\n",
      "Batch 1395 finished:\n",
      "agent1 return is:  0.13396812991242724\n",
      "agent2 return is:  12.242143695162031\n",
      "Batch 1396 finished:\n",
      "agent1 return is:  0.3203677172565066\n",
      "agent2 return is:  12.2479598181426\n",
      "Batch 1397 finished:\n",
      "agent1 return is:  0.2802787245867914\n",
      "agent2 return is:  12.261083448114139\n",
      "Batch 1398 finished:\n",
      "agent1 return is:  0.32839536064284963\n",
      "agent2 return is:  12.26224222022486\n",
      "Batch 1399 finished:\n",
      "agent1 return is:  0.19048507206481435\n",
      "agent2 return is:  12.305167291748047\n",
      "Batch 1400 finished:\n",
      "agent1 return is:  0.29163774172059287\n",
      "agent2 return is:  12.065960195125271\n",
      "Batch 1401 finished:\n",
      "agent1 return is:  0.16113783674044696\n",
      "agent2 return is:  12.334657954676125\n",
      "Batch 1402 finished:\n",
      "agent1 return is:  0.14788644513670715\n",
      "agent2 return is:  12.318301939448196\n",
      "Batch 1403 finished:\n",
      "agent1 return is:  -0.04259475790952976\n",
      "agent2 return is:  12.234619466648393\n",
      "Batch 1404 finished:\n",
      "agent1 return is:  0.298893710195964\n",
      "agent2 return is:  12.215455851597117\n",
      "Batch 1405 finished:\n",
      "agent1 return is:  0.20108888187366641\n",
      "agent2 return is:  12.25094664603603\n",
      "Batch 1406 finished:\n",
      "agent1 return is:  0.28569495990425486\n",
      "agent2 return is:  12.147555251542963\n",
      "Batch 1407 finished:\n",
      "agent1 return is:  0.14775910769435507\n",
      "agent2 return is:  12.07197886570555\n",
      "Batch 1408 finished:\n",
      "agent1 return is:  0.2671240900501609\n",
      "agent2 return is:  12.253895741155759\n",
      "Batch 1409 finished:\n",
      "agent1 return is:  0.25183529103081514\n",
      "agent2 return is:  12.259690795789869\n",
      "Batch 1410 finished:\n",
      "agent1 return is:  0.0005008969981847716\n",
      "agent2 return is:  12.263478379082935\n",
      "Batch 1411 finished:\n",
      "agent1 return is:  -0.024463970653314446\n",
      "agent2 return is:  12.127133151959644\n",
      "Batch 1412 finished:\n",
      "agent1 return is:  -0.12174025716771975\n",
      "agent2 return is:  12.20891412843536\n",
      "Batch 1413 finished:\n",
      "agent1 return is:  0.1583438380284983\n",
      "agent2 return is:  12.185431025018286\n",
      "Batch 1414 finished:\n",
      "agent1 return is:  0.30484605765569106\n",
      "agent2 return is:  12.417430063409503\n",
      "Batch 1415 finished:\n",
      "agent1 return is:  0.2954489286601505\n",
      "agent2 return is:  12.40066700318232\n",
      "Batch 1416 finished:\n",
      "agent1 return is:  0.16772654579505908\n",
      "agent2 return is:  12.375140343821238\n",
      "Batch 1417 finished:\n",
      "agent1 return is:  0.3475887985224643\n",
      "agent2 return is:  12.398420030030858\n",
      "Batch 1418 finished:\n",
      "agent1 return is:  0.018308928604159502\n",
      "agent2 return is:  12.446218546236123\n",
      "Batch 1419 finished:\n",
      "agent1 return is:  0.18148900556355893\n",
      "agent2 return is:  12.37073828330612\n",
      "Batch 1420 finished:\n",
      "agent1 return is:  0.3273376582438894\n",
      "agent2 return is:  12.437564744773885\n",
      "Batch 1421 finished:\n",
      "agent1 return is:  -0.1263484532785681\n",
      "agent2 return is:  12.479094483431345\n",
      "Batch 1422 finished:\n",
      "agent1 return is:  0.2900574475201767\n",
      "agent2 return is:  12.475598258871749\n",
      "Batch 1423 finished:\n",
      "agent1 return is:  -0.12543571085734018\n",
      "agent2 return is:  12.47968543024497\n",
      "Batch 1424 finished:\n",
      "agent1 return is:  0.22400999358863127\n",
      "agent2 return is:  12.414751992918418\n",
      "Batch 1425 finished:\n",
      "agent1 return is:  0.3306407929743383\n",
      "agent2 return is:  12.424572115483999\n",
      "Batch 1426 finished:\n",
      "agent1 return is:  0.36261727543384514\n",
      "agent2 return is:  12.44716369356707\n",
      "Batch 1427 finished:\n",
      "agent1 return is:  -0.026173249615990338\n",
      "agent2 return is:  12.5182167137094\n",
      "Batch 1428 finished:\n",
      "agent1 return is:  0.02337053604203551\n",
      "agent2 return is:  12.526566767709575\n",
      "Batch 1429 finished:\n",
      "agent1 return is:  0.12047338090868294\n",
      "agent2 return is:  12.5630441283466\n",
      "Batch 1430 finished:\n",
      "agent1 return is:  0.19774347953490456\n",
      "agent2 return is:  12.56099126782414\n",
      "Batch 1431 finished:\n",
      "agent1 return is:  -0.03719283566515302\n",
      "agent2 return is:  12.584734240021948\n",
      "Batch 1432 finished:\n",
      "agent1 return is:  0.21719545475241603\n",
      "agent2 return is:  12.583093637575695\n",
      "Batch 1433 finished:\n",
      "agent1 return is:  0.06115551198223308\n",
      "agent2 return is:  12.585405421459683\n",
      "Batch 1434 finished:\n",
      "agent1 return is:  -0.3229028180417478\n",
      "agent2 return is:  12.603876935662765\n",
      "Batch 1435 finished:\n",
      "agent1 return is:  -0.11080349056576469\n",
      "agent2 return is:  12.61594268495847\n",
      "Batch 1436 finished:\n",
      "agent1 return is:  0.16986333102866347\n",
      "agent2 return is:  12.56310913383436\n",
      "Batch 1437 finished:\n",
      "agent1 return is:  0.12329297565173566\n",
      "agent2 return is:  12.606981555635299\n",
      "Batch 1438 finished:\n",
      "agent1 return is:  0.3555142337865882\n",
      "agent2 return is:  12.458077061755713\n",
      "Batch 1439 finished:\n",
      "agent1 return is:  0.11369190667513605\n",
      "agent2 return is:  12.620222485550203\n",
      "Batch 1440 finished:\n",
      "agent1 return is:  -0.08124894631979158\n",
      "agent2 return is:  12.624782670413058\n",
      "Batch 1441 finished:\n",
      "agent1 return is:  0.31773737309735145\n",
      "agent2 return is:  12.548157243356465\n",
      "Batch 1442 finished:\n",
      "agent1 return is:  0.08967444976837427\n",
      "agent2 return is:  12.675973032485823\n",
      "Batch 1443 finished:\n",
      "agent1 return is:  -0.46514224488331224\n",
      "agent2 return is:  12.59947600876026\n",
      "Batch 1444 finished:\n",
      "agent1 return is:  0.05773921290335652\n",
      "agent2 return is:  12.726422840576141\n",
      "Batch 1445 finished:\n",
      "agent1 return is:  -0.07031382146709203\n",
      "agent2 return is:  12.508650098829992\n",
      "Batch 1446 finished:\n",
      "agent1 return is:  0.28710466549231006\n",
      "agent2 return is:  12.724031760158976\n",
      "Batch 1447 finished:\n",
      "agent1 return is:  0.18865598634838493\n",
      "agent2 return is:  12.661038933774755\n",
      "Batch 1448 finished:\n",
      "agent1 return is:  -0.09217223475137305\n",
      "agent2 return is:  12.645359096672838\n",
      "Batch 1449 finished:\n",
      "agent1 return is:  -0.07955698219586095\n",
      "agent2 return is:  12.756516395738913\n",
      "Batch 1450 finished:\n",
      "agent1 return is:  0.17245513055961825\n",
      "agent2 return is:  12.761125845440962\n",
      "Batch 1451 finished:\n",
      "agent1 return is:  0.20739952481281973\n",
      "agent2 return is:  12.770914880164819\n",
      "Batch 1452 finished:\n",
      "agent1 return is:  0.10886911550242055\n",
      "agent2 return is:  12.81012638177916\n",
      "Batch 1453 finished:\n",
      "agent1 return is:  0.1134197178180694\n",
      "agent2 return is:  12.747093328315527\n",
      "Batch 1454 finished:\n",
      "agent1 return is:  0.20278072322590326\n",
      "agent2 return is:  12.746314759355203\n",
      "Batch 1455 finished:\n",
      "agent1 return is:  0.19242509529127494\n",
      "agent2 return is:  12.758014087817553\n",
      "Batch 1456 finished:\n",
      "agent1 return is:  0.06238821378414802\n",
      "agent2 return is:  12.830251337905626\n",
      "Batch 1457 finished:\n",
      "agent1 return is:  0.1642987176274443\n",
      "agent2 return is:  12.79853068003764\n",
      "Batch 1458 finished:\n",
      "agent1 return is:  0.30429494350795394\n",
      "agent2 return is:  12.703615066411174\n",
      "Batch 1459 finished:\n",
      "agent1 return is:  0.17551229121467118\n",
      "agent2 return is:  12.862967797143419\n",
      "Batch 1460 finished:\n",
      "agent1 return is:  -0.03321421605733303\n",
      "agent2 return is:  12.920045481245399\n",
      "Batch 1461 finished:\n",
      "agent1 return is:  -0.1942057848075565\n",
      "agent2 return is:  12.904701384898214\n",
      "Batch 1462 finished:\n",
      "agent1 return is:  -0.021951985527268306\n",
      "agent2 return is:  12.893541405565811\n",
      "Batch 1463 finished:\n",
      "agent1 return is:  0.29569232706088\n",
      "agent2 return is:  12.736572198509714\n",
      "Batch 1464 finished:\n",
      "agent1 return is:  0.15434265587938473\n",
      "agent2 return is:  12.932512658915302\n",
      "Batch 1465 finished:\n",
      "agent1 return is:  0.0030437298618733732\n",
      "agent2 return is:  12.91032577303632\n",
      "Batch 1466 finished:\n",
      "agent1 return is:  0.15662785246146843\n",
      "agent2 return is:  12.931954008772346\n",
      "Batch 1467 finished:\n",
      "agent1 return is:  0.022684137624128735\n",
      "agent2 return is:  12.900181819925724\n",
      "Batch 1468 finished:\n",
      "agent1 return is:  -0.45869793142829696\n",
      "agent2 return is:  12.962405377401485\n",
      "Batch 1469 finished:\n",
      "agent1 return is:  0.12569843205819178\n",
      "agent2 return is:  12.910736056379148\n",
      "Batch 1470 finished:\n",
      "agent1 return is:  0.10195397224811734\n",
      "agent2 return is:  12.723494944987056\n",
      "Batch 1471 finished:\n",
      "agent1 return is:  -0.09847504800058002\n",
      "agent2 return is:  12.857260267483523\n",
      "Batch 1472 finished:\n",
      "agent1 return is:  -0.023654038030349767\n",
      "agent2 return is:  12.943471467593774\n",
      "Batch 1473 finished:\n",
      "agent1 return is:  0.1370226696381251\n",
      "agent2 return is:  12.884685250538825\n",
      "Batch 1474 finished:\n",
      "agent1 return is:  0.028923654407459365\n",
      "agent2 return is:  12.905983554299826\n",
      "Batch 1475 finished:\n",
      "agent1 return is:  -0.2342912131553819\n",
      "agent2 return is:  12.758703386143187\n",
      "Batch 1476 finished:\n",
      "agent1 return is:  0.16930264753306895\n",
      "agent2 return is:  12.91887420438767\n",
      "Batch 1477 finished:\n",
      "agent1 return is:  0.20666688539721254\n",
      "agent2 return is:  12.937657775759419\n",
      "Batch 1478 finished:\n",
      "agent1 return is:  0.07334494423654447\n",
      "agent2 return is:  12.912170870551282\n",
      "Batch 1479 finished:\n",
      "agent1 return is:  0.34321157885973075\n",
      "agent2 return is:  12.867142299343067\n",
      "Batch 1480 finished:\n",
      "agent1 return is:  -0.18053864044978202\n",
      "agent2 return is:  12.82476186881448\n",
      "Batch 1481 finished:\n",
      "agent1 return is:  0.05672815421701127\n",
      "agent2 return is:  12.863506634706592\n",
      "Batch 1482 finished:\n",
      "agent1 return is:  0.15521783887866764\n",
      "agent2 return is:  12.782069056348732\n",
      "Batch 1483 finished:\n",
      "agent1 return is:  0.17322079195777793\n",
      "agent2 return is:  12.760243019533235\n",
      "Batch 1484 finished:\n",
      "agent1 return is:  -0.11226465023326815\n",
      "agent2 return is:  12.696731770749414\n",
      "Batch 1485 finished:\n",
      "agent1 return is:  0.11991935802100351\n",
      "agent2 return is:  12.686397378092586\n",
      "Batch 1486 finished:\n",
      "agent1 return is:  0.14991598166514616\n",
      "agent2 return is:  12.739505680078096\n",
      "Batch 1487 finished:\n",
      "agent1 return is:  0.11996265727397082\n",
      "agent2 return is:  12.752341140468054\n",
      "Batch 1488 finished:\n",
      "agent1 return is:  0.11459546493108765\n",
      "agent2 return is:  12.728529586963255\n",
      "Batch 1489 finished:\n",
      "agent1 return is:  0.012955217557467855\n",
      "agent2 return is:  12.7198648528591\n",
      "Batch 1490 finished:\n",
      "agent1 return is:  0.13121076206767893\n",
      "agent2 return is:  12.715337369416918\n",
      "Batch 1491 finished:\n",
      "agent1 return is:  -0.08564916353937782\n",
      "agent2 return is:  12.777434574275803\n",
      "Batch 1492 finished:\n",
      "agent1 return is:  0.15626922424235684\n",
      "agent2 return is:  12.645966290408117\n",
      "Batch 1493 finished:\n",
      "agent1 return is:  0.13059230043228026\n",
      "agent2 return is:  12.728112858507934\n",
      "Batch 1494 finished:\n",
      "agent1 return is:  0.1600796699688312\n",
      "agent2 return is:  12.744489593810851\n",
      "Batch 1495 finished:\n",
      "agent1 return is:  0.07416219169474786\n",
      "agent2 return is:  12.762228811666155\n",
      "Batch 1496 finished:\n",
      "agent1 return is:  0.056115393497485073\n",
      "agent2 return is:  12.783399255794905\n",
      "Batch 1497 finished:\n",
      "agent1 return is:  0.18923400033000254\n",
      "agent2 return is:  12.826546370319694\n",
      "Batch 1498 finished:\n",
      "agent1 return is:  -0.17894160357252453\n",
      "agent2 return is:  12.805080271780326\n",
      "Batch 1499 finished:\n",
      "agent1 return is:  0.04379246756103514\n",
      "agent2 return is:  12.780354340061967\n",
      "Batch 1500 finished:\n",
      "agent1 return is:  -0.09162070372304568\n",
      "agent2 return is:  12.855158880160548\n",
      "Batch 1501 finished:\n",
      "agent1 return is:  -0.14904728380978627\n",
      "agent2 return is:  12.926831808358303\n",
      "Batch 1502 finished:\n",
      "agent1 return is:  0.1857835583457385\n",
      "agent2 return is:  12.829155512720398\n",
      "Batch 1503 finished:\n",
      "agent1 return is:  -0.21724546452430665\n",
      "agent2 return is:  12.875043751132338\n",
      "Batch 1504 finished:\n",
      "agent1 return is:  0.35510009460796876\n",
      "agent2 return is:  12.886869921812902\n",
      "Batch 1505 finished:\n",
      "agent1 return is:  0.07724370741850294\n",
      "agent2 return is:  12.783756785381666\n",
      "Batch 1506 finished:\n",
      "agent1 return is:  0.3901635986782229\n",
      "agent2 return is:  12.97204921851177\n",
      "Batch 1507 finished:\n",
      "agent1 return is:  0.3352449354665375\n",
      "agent2 return is:  12.938446218837203\n",
      "Batch 1508 finished:\n",
      "agent1 return is:  0.18496861453595637\n",
      "agent2 return is:  12.951684807513505\n",
      "Batch 1509 finished:\n",
      "agent1 return is:  0.011766381420329444\n",
      "agent2 return is:  12.934937101237187\n",
      "Batch 1510 finished:\n",
      "agent1 return is:  0.1277103111214361\n",
      "agent2 return is:  12.910102494835247\n",
      "Batch 1511 finished:\n",
      "agent1 return is:  0.25330549710184036\n",
      "agent2 return is:  12.915653023687176\n",
      "Batch 1512 finished:\n",
      "agent1 return is:  0.13585486069104052\n",
      "agent2 return is:  12.949114867742455\n",
      "Batch 1513 finished:\n",
      "agent1 return is:  0.32556195675787714\n",
      "agent2 return is:  12.970162581747196\n",
      "Batch 1514 finished:\n",
      "agent1 return is:  -0.032036572485574885\n",
      "agent2 return is:  13.043558200769725\n",
      "Batch 1515 finished:\n",
      "agent1 return is:  0.3499633006138382\n",
      "agent2 return is:  13.013375283142825\n",
      "Batch 1516 finished:\n",
      "agent1 return is:  0.4645171515137889\n",
      "agent2 return is:  13.047811339055734\n",
      "Batch 1517 finished:\n",
      "agent1 return is:  -0.19595821603658833\n",
      "agent2 return is:  12.995774393445668\n",
      "Batch 1518 finished:\n",
      "agent1 return is:  0.23835523031498726\n",
      "agent2 return is:  13.00264645564853\n",
      "Batch 1519 finished:\n",
      "agent1 return is:  0.09474419584528376\n",
      "agent2 return is:  12.950937302931367\n",
      "Batch 1520 finished:\n",
      "agent1 return is:  0.22142831468991947\n",
      "agent2 return is:  12.882133010923308\n",
      "Batch 1521 finished:\n",
      "agent1 return is:  0.23462522172040934\n",
      "agent2 return is:  12.918323923523161\n",
      "Batch 1522 finished:\n",
      "agent1 return is:  0.17788831726309545\n",
      "agent2 return is:  12.928005997652463\n",
      "Batch 1523 finished:\n",
      "agent1 return is:  0.2694759820594596\n",
      "agent2 return is:  12.746771101092527\n",
      "Batch 1524 finished:\n",
      "agent1 return is:  0.25284473262337703\n",
      "agent2 return is:  12.86909756124711\n",
      "Batch 1525 finished:\n",
      "agent1 return is:  0.244202571831563\n",
      "agent2 return is:  12.869467773705932\n",
      "Batch 1526 finished:\n",
      "agent1 return is:  0.00393985130007872\n",
      "agent2 return is:  12.875219947032218\n",
      "Batch 1527 finished:\n",
      "agent1 return is:  0.23579491303921996\n",
      "agent2 return is:  12.814470408747997\n",
      "Batch 1528 finished:\n",
      "agent1 return is:  0.21456739417711657\n",
      "agent2 return is:  12.811825895256717\n",
      "Batch 1529 finished:\n",
      "agent1 return is:  0.24521614828242508\n",
      "agent2 return is:  12.740064729025875\n",
      "Batch 1530 finished:\n",
      "agent1 return is:  0.11094010406715837\n",
      "agent2 return is:  12.809925770076877\n",
      "Batch 1531 finished:\n",
      "agent1 return is:  0.26630258097260023\n",
      "agent2 return is:  12.798352257632128\n",
      "Batch 1532 finished:\n",
      "agent1 return is:  0.14884274528427743\n",
      "agent2 return is:  12.755557576472274\n",
      "Batch 1533 finished:\n",
      "agent1 return is:  0.2694936709821276\n",
      "agent2 return is:  12.631850628660274\n",
      "Batch 1534 finished:\n",
      "agent1 return is:  0.03453802955310767\n",
      "agent2 return is:  12.598456165299943\n",
      "Batch 1535 finished:\n",
      "agent1 return is:  0.17468648091819006\n",
      "agent2 return is:  12.755744498749989\n",
      "Batch 1536 finished:\n",
      "agent1 return is:  0.027271353191883917\n",
      "agent2 return is:  12.724957929577098\n",
      "Batch 1537 finished:\n",
      "agent1 return is:  0.27496785343354885\n",
      "agent2 return is:  12.690331195042102\n",
      "Batch 1538 finished:\n",
      "agent1 return is:  0.11639951395909218\n",
      "agent2 return is:  12.720761586345342\n",
      "Batch 1539 finished:\n",
      "agent1 return is:  0.26987475164195873\n",
      "agent2 return is:  12.602335282868605\n",
      "Batch 1540 finished:\n",
      "agent1 return is:  0.24160569512592983\n",
      "agent2 return is:  12.761117135484614\n",
      "Batch 1541 finished:\n",
      "agent1 return is:  0.10744120770852979\n",
      "agent2 return is:  12.724130441990395\n",
      "Batch 1542 finished:\n",
      "agent1 return is:  0.23594033078317272\n",
      "agent2 return is:  12.739747268024253\n",
      "Batch 1543 finished:\n",
      "agent1 return is:  0.24202193814146378\n",
      "agent2 return is:  12.726122303307765\n",
      "Batch 1544 finished:\n",
      "agent1 return is:  0.23651723121153628\n",
      "agent2 return is:  12.622904329575368\n",
      "Batch 1545 finished:\n",
      "agent1 return is:  0.1923794089357022\n",
      "agent2 return is:  12.743724715870746\n",
      "Batch 1546 finished:\n",
      "agent1 return is:  0.18656803227200214\n",
      "agent2 return is:  12.736498993758255\n",
      "Batch 1547 finished:\n",
      "agent1 return is:  0.19666331200898396\n",
      "agent2 return is:  12.68269830237844\n",
      "Batch 1548 finished:\n",
      "agent1 return is:  0.2053445563715287\n",
      "agent2 return is:  12.801976804920479\n",
      "Batch 1549 finished:\n",
      "agent1 return is:  0.22687176019434385\n",
      "agent2 return is:  12.73527838067615\n",
      "Batch 1550 finished:\n",
      "agent1 return is:  0.2240293174662718\n",
      "agent2 return is:  12.617854040781516\n",
      "Batch 1551 finished:\n",
      "agent1 return is:  0.20534208919793207\n",
      "agent2 return is:  12.757302366618157\n",
      "Batch 1552 finished:\n",
      "agent1 return is:  0.12001572425283666\n",
      "agent2 return is:  12.737351899243233\n",
      "Batch 1553 finished:\n",
      "agent1 return is:  0.23706974565518632\n",
      "agent2 return is:  12.687911344020915\n",
      "Batch 1554 finished:\n",
      "agent1 return is:  0.24983834478225864\n",
      "agent2 return is:  12.758433380826553\n",
      "Batch 1555 finished:\n",
      "agent1 return is:  0.26637866650435194\n",
      "agent2 return is:  12.761393946395376\n",
      "Batch 1556 finished:\n",
      "agent1 return is:  0.26472328634794495\n",
      "agent2 return is:  12.674927553039321\n",
      "Batch 1557 finished:\n",
      "agent1 return is:  0.2948751528614856\n",
      "agent2 return is:  12.757288648953534\n",
      "Batch 1558 finished:\n",
      "agent1 return is:  0.1797036219112046\n",
      "agent2 return is:  12.74042786162392\n",
      "Batch 1559 finished:\n",
      "agent1 return is:  0.12097520718128481\n",
      "agent2 return is:  12.69758472404406\n",
      "Batch 1560 finished:\n",
      "agent1 return is:  0.1630319804155892\n",
      "agent2 return is:  12.768578839150372\n",
      "Batch 1561 finished:\n",
      "agent1 return is:  0.3188741197012467\n",
      "agent2 return is:  12.768083129612815\n",
      "Batch 1562 finished:\n",
      "agent1 return is:  0.16243371788770877\n",
      "agent2 return is:  12.845047833468247\n",
      "Batch 1563 finished:\n",
      "agent1 return is:  0.32201330236189063\n",
      "agent2 return is:  12.901940364386796\n",
      "Batch 1564 finished:\n",
      "agent1 return is:  0.30305532880945957\n",
      "agent2 return is:  12.902680016275877\n",
      "Batch 1565 finished:\n",
      "agent1 return is:  0.28557146844722325\n",
      "agent2 return is:  12.87345529606867\n",
      "Batch 1566 finished:\n",
      "agent1 return is:  0.18875130077749522\n",
      "agent2 return is:  12.910635875773758\n",
      "Batch 1567 finished:\n",
      "agent1 return is:  0.05120744176224475\n",
      "agent2 return is:  12.893699828508488\n",
      "Batch 1568 finished:\n",
      "agent1 return is:  0.27571381878519824\n",
      "agent2 return is:  12.889834524015065\n",
      "Batch 1569 finished:\n",
      "agent1 return is:  0.14143818490481247\n",
      "agent2 return is:  12.884459867977817\n",
      "Batch 1570 finished:\n",
      "agent1 return is:  0.2529796075792278\n",
      "agent2 return is:  12.894878265423134\n",
      "Batch 1571 finished:\n",
      "agent1 return is:  0.2696401708491064\n",
      "agent2 return is:  12.790211413448045\n",
      "Batch 1572 finished:\n",
      "agent1 return is:  0.26323355226179956\n",
      "agent2 return is:  12.906824509089532\n",
      "Batch 1573 finished:\n",
      "agent1 return is:  0.2713725792557084\n",
      "agent2 return is:  12.884479316159794\n",
      "Batch 1574 finished:\n",
      "agent1 return is:  0.17941299504701713\n",
      "agent2 return is:  12.845263759220327\n",
      "Batch 1575 finished:\n",
      "agent1 return is:  0.30898921501730203\n",
      "agent2 return is:  12.86407901786059\n",
      "Batch 1576 finished:\n",
      "agent1 return is:  0.31733778554585773\n",
      "agent2 return is:  12.854328660304137\n",
      "Batch 1577 finished:\n",
      "agent1 return is:  0.14079070210033223\n",
      "agent2 return is:  12.830001880937827\n",
      "Batch 1578 finished:\n",
      "agent1 return is:  0.2281809421846594\n",
      "agent2 return is:  12.850879115068501\n",
      "Batch 1579 finished:\n",
      "agent1 return is:  0.2939556284422776\n",
      "agent2 return is:  12.873639859845689\n",
      "Batch 1580 finished:\n",
      "agent1 return is:  0.38122731778780283\n",
      "agent2 return is:  12.845175239249311\n",
      "Batch 1581 finished:\n",
      "agent1 return is:  0.2378230485885047\n",
      "agent2 return is:  12.880431762760606\n",
      "Batch 1582 finished:\n",
      "agent1 return is:  0.30433552077825077\n",
      "agent2 return is:  12.880169549292221\n",
      "Batch 1583 finished:\n",
      "agent1 return is:  0.19097267021796732\n",
      "agent2 return is:  12.941229894813338\n",
      "Batch 1584 finished:\n",
      "agent1 return is:  0.2492522994026234\n",
      "agent2 return is:  12.91309316794138\n",
      "Batch 1585 finished:\n",
      "agent1 return is:  0.21559531278444227\n",
      "agent2 return is:  12.887557932210257\n",
      "Batch 1586 finished:\n",
      "agent1 return is:  0.20139692061594816\n",
      "agent2 return is:  12.951875594023573\n",
      "Batch 1587 finished:\n",
      "agent1 return is:  0.3356520625563074\n",
      "agent2 return is:  12.871377776441573\n",
      "Batch 1588 finished:\n",
      "agent1 return is:  0.3360810252921706\n",
      "agent2 return is:  12.914875277182752\n",
      "Batch 1589 finished:\n",
      "agent1 return is:  0.20567190062940863\n",
      "agent2 return is:  12.88797526443888\n",
      "Batch 1590 finished:\n",
      "agent1 return is:  0.3067365721632812\n",
      "agent2 return is:  12.880859046065183\n",
      "Batch 1591 finished:\n",
      "agent1 return is:  0.317539249693092\n",
      "agent2 return is:  12.84556949014619\n",
      "Batch 1592 finished:\n",
      "agent1 return is:  0.052313774327913044\n",
      "agent2 return is:  12.88774789662531\n",
      "Batch 1593 finished:\n",
      "agent1 return is:  0.14311243680765467\n",
      "agent2 return is:  12.682531043180505\n",
      "Batch 1594 finished:\n",
      "agent1 return is:  0.016386300560770235\n",
      "agent2 return is:  12.806620355493088\n",
      "Batch 1595 finished:\n",
      "agent1 return is:  0.2877837106390144\n",
      "agent2 return is:  12.85880290415873\n",
      "Batch 1596 finished:\n",
      "agent1 return is:  0.3037252895955566\n",
      "agent2 return is:  12.85192007887124\n",
      "Batch 1597 finished:\n",
      "agent1 return is:  0.19749469671704448\n",
      "agent2 return is:  12.880249168344005\n",
      "Batch 1598 finished:\n",
      "agent1 return is:  -0.02232855276598461\n",
      "agent2 return is:  12.876278166784164\n",
      "Batch 1599 finished:\n",
      "agent1 return is:  0.262277104227541\n",
      "agent2 return is:  12.823873990083856\n",
      "Batch 1600 finished:\n",
      "agent1 return is:  0.4057517898710468\n",
      "agent2 return is:  12.793609927453474\n",
      "Batch 1601 finished:\n",
      "agent1 return is:  0.18221158152055644\n",
      "agent2 return is:  12.887565156438612\n",
      "Batch 1602 finished:\n",
      "agent1 return is:  0.20102575737182607\n",
      "agent2 return is:  12.907912288665447\n",
      "Batch 1603 finished:\n",
      "agent1 return is:  0.09024705128886792\n",
      "agent2 return is:  12.786978630446919\n",
      "Batch 1604 finished:\n",
      "agent1 return is:  0.1047706396602843\n",
      "agent2 return is:  12.90409964245314\n",
      "Batch 1605 finished:\n",
      "agent1 return is:  0.2584625982751683\n",
      "agent2 return is:  12.85348650309094\n",
      "Batch 1606 finished:\n",
      "agent1 return is:  0.246966790916888\n",
      "agent2 return is:  12.838242249674241\n",
      "Batch 1607 finished:\n",
      "agent1 return is:  0.3414769824343961\n",
      "agent2 return is:  12.801168495211297\n",
      "Batch 1608 finished:\n",
      "agent1 return is:  0.0626836141158002\n",
      "agent2 return is:  12.693664912133688\n",
      "Batch 1609 finished:\n",
      "agent1 return is:  -0.18654605639314398\n",
      "agent2 return is:  12.703688241110857\n",
      "Batch 1610 finished:\n",
      "agent1 return is:  0.1741836223444725\n",
      "agent2 return is:  12.664682809856286\n",
      "Batch 1611 finished:\n",
      "agent1 return is:  0.14426553818466492\n",
      "agent2 return is:  12.812017863224252\n",
      "Batch 1612 finished:\n",
      "agent1 return is:  0.27656128382586415\n",
      "agent2 return is:  12.83061595219561\n",
      "Batch 1613 finished:\n",
      "agent1 return is:  0.17426644589744622\n",
      "agent2 return is:  12.862447837531345\n",
      "Batch 1614 finished:\n",
      "agent1 return is:  0.22127249634334137\n",
      "agent2 return is:  12.778791188871415\n",
      "Batch 1615 finished:\n",
      "agent1 return is:  0.17551298913922225\n",
      "agent2 return is:  12.853934421448969\n",
      "Batch 1616 finished:\n",
      "agent1 return is:  -0.13890021815497028\n",
      "agent2 return is:  12.863938864748299\n",
      "Batch 1617 finished:\n",
      "agent1 return is:  0.32408295751016747\n",
      "agent2 return is:  12.786220586219729\n",
      "Batch 1618 finished:\n",
      "agent1 return is:  0.05976189132107348\n",
      "agent2 return is:  12.806644587083024\n",
      "Batch 1619 finished:\n",
      "agent1 return is:  -0.030414786001468047\n",
      "agent2 return is:  12.822799944017001\n",
      "Batch 1620 finished:\n",
      "agent1 return is:  0.2955741367357567\n",
      "agent2 return is:  12.804931376899903\n",
      "Batch 1621 finished:\n",
      "agent1 return is:  0.12764353763438005\n",
      "agent2 return is:  12.772114188120167\n",
      "Batch 1622 finished:\n",
      "agent1 return is:  -0.10753540928860181\n",
      "agent2 return is:  12.833949646018219\n",
      "Batch 1623 finished:\n",
      "agent1 return is:  0.17090785438041922\n",
      "agent2 return is:  12.766356247667396\n",
      "Batch 1624 finished:\n",
      "agent1 return is:  0.25742257186674405\n",
      "agent2 return is:  12.794664331026045\n",
      "Batch 1625 finished:\n",
      "agent1 return is:  0.3404215906103699\n",
      "agent2 return is:  12.931155278188054\n",
      "Batch 1626 finished:\n",
      "agent1 return is:  -0.060209419332626746\n",
      "agent2 return is:  12.973171112193555\n",
      "Batch 1627 finished:\n",
      "agent1 return is:  0.17054755607157754\n",
      "agent2 return is:  12.922223688078786\n",
      "Batch 1628 finished:\n",
      "agent1 return is:  0.14779097275618314\n",
      "agent2 return is:  12.9206083959401\n",
      "Batch 1629 finished:\n",
      "agent1 return is:  0.2940603369403805\n",
      "agent2 return is:  12.800869399471331\n",
      "Batch 1630 finished:\n",
      "agent1 return is:  0.17264373583896378\n",
      "agent2 return is:  12.8106656335142\n",
      "Batch 1631 finished:\n",
      "agent1 return is:  0.16587812516605926\n",
      "agent2 return is:  12.9100567839041\n",
      "Batch 1632 finished:\n",
      "agent1 return is:  0.2825455911380095\n",
      "agent2 return is:  12.898931423954506\n",
      "Batch 1633 finished:\n",
      "agent1 return is:  0.15153084617713547\n",
      "agent2 return is:  12.952624621426594\n",
      "Batch 1634 finished:\n",
      "agent1 return is:  0.1602989914022541\n",
      "agent2 return is:  12.956554312160794\n",
      "Batch 1635 finished:\n",
      "agent1 return is:  -0.018906126296113435\n",
      "agent2 return is:  13.010170335058875\n",
      "Batch 1636 finished:\n",
      "agent1 return is:  0.154710250117085\n",
      "agent2 return is:  12.999860147405371\n",
      "Batch 1637 finished:\n",
      "agent1 return is:  0.2786456338822012\n",
      "agent2 return is:  13.030543362865737\n",
      "Batch 1638 finished:\n",
      "agent1 return is:  0.3179960303207836\n",
      "agent2 return is:  13.043432550786559\n",
      "Batch 1639 finished:\n",
      "agent1 return is:  0.1890443749232037\n",
      "agent2 return is:  13.096772105314702\n",
      "Batch 1640 finished:\n",
      "agent1 return is:  0.02664223350487699\n",
      "agent2 return is:  13.099657465444476\n",
      "Batch 1641 finished:\n",
      "agent1 return is:  0.12510034518556237\n",
      "agent2 return is:  13.046436719519797\n",
      "Batch 1642 finished:\n",
      "agent1 return is:  0.1486390103057255\n",
      "agent2 return is:  13.132077799978003\n",
      "Batch 1643 finished:\n",
      "agent1 return is:  0.01935691174707925\n",
      "agent2 return is:  12.944081706017052\n",
      "Batch 1644 finished:\n",
      "agent1 return is:  0.17419114485920073\n",
      "agent2 return is:  13.071793644473436\n",
      "Batch 1645 finished:\n",
      "agent1 return is:  0.2991500489220267\n",
      "agent2 return is:  13.035261096790776\n",
      "Batch 1646 finished:\n",
      "agent1 return is:  0.02427852081094807\n",
      "agent2 return is:  13.035407952544986\n",
      "Batch 1647 finished:\n",
      "agent1 return is:  0.017317712916904815\n",
      "agent2 return is:  13.056218072022066\n",
      "Batch 1648 finished:\n",
      "agent1 return is:  0.30746726041148775\n",
      "agent2 return is:  13.047897070499115\n",
      "Batch 1649 finished:\n",
      "agent1 return is:  0.20184323893073133\n",
      "agent2 return is:  13.053901875145497\n",
      "Batch 1650 finished:\n",
      "agent1 return is:  0.3352474466720947\n",
      "agent2 return is:  13.041742114054216\n",
      "Batch 1651 finished:\n",
      "agent1 return is:  0.198222487564797\n",
      "agent2 return is:  13.025189696349353\n",
      "Batch 1652 finished:\n",
      "agent1 return is:  0.27047238757449643\n",
      "agent2 return is:  13.016719311496571\n",
      "Batch 1653 finished:\n",
      "agent1 return is:  0.02208458901894131\n",
      "agent2 return is:  13.098361463646924\n",
      "Batch 1654 finished:\n",
      "agent1 return is:  0.2539278197329581\n",
      "agent2 return is:  13.036248057975172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \tagent\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msolver\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mglpk\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mnumber_of_batches):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \tbatch_obs,batch_acts, batch_log_probs, batch_rtgs\u001b[39m=\u001b[39mtk\u001b[39m.\u001b[39;49mrollout(env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X10sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39magents:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/NECom.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \t\tV, _\u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mevaluate(batch_obs[agent\u001b[39m.\u001b[39mname],batch_acts[agent\u001b[39m.\u001b[39mname])\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:393\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    391\u001b[0m batch\u001b[39m=\u001b[39m[]\n\u001b[1;32m    392\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mepisodes_per_batch):\n\u001b[0;32m--> 393\u001b[0m     batch\u001b[39m.\u001b[39mappend(run_episode_single(env))\n\u001b[1;32m    394\u001b[0m \u001b[39m#     batch.append(run_episode.remote(env))\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m# batch=ray.get(batch)\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(env\u001b[39m.\u001b[39mepisodes_per_batch):\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:457\u001b[0m, in \u001b[0;36mrun_episode_single\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    455\u001b[0m     agent\u001b[39m.\u001b[39ma\u001b[39m=\u001b[39maction\n\u001b[1;32m    456\u001b[0m     agent\u001b[39m.\u001b[39mlog_prob\u001b[39m=\u001b[39mlog_prob \u001b[39m.\u001b[39mdetach()        \n\u001b[0;32m--> 457\u001b[0m s,r,a,sp\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    458\u001b[0m \u001b[39mfor\u001b[39;00m ind,ag \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(env\u001b[39m.\u001b[39magents):\n\u001b[1;32m    459\u001b[0m     batch_obs[ag\u001b[39m.\u001b[39mname]\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mhstack([s[ag\u001b[39m.\u001b[39mobservables],env\u001b[39m.\u001b[39mt]))\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:155\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m index,flux \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(M\u001b[39m.\u001b[39mactions):\n\u001b[1;32m    153\u001b[0m     \u001b[39mif\u001b[39;00m M\u001b[39m.\u001b[39ma[index]\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m         M\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mreactions[M\u001b[39m.\u001b[39;49mactions[index]]\u001b[39m.\u001b[39;49mlower_bound\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(M\u001b[39m.\u001b[39ma[index],M\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mreactions[M\u001b[39m.\u001b[39mactions[index]]\u001b[39m.\u001b[39mlower_bound)\n\u001b[1;32m    156\u001b[0m         \u001b[39m# M.model.reactions[M.actions[index]].lower_bound=M.a[index]*M.model.reactions[M.actions[index]].lower_bound\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         M\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mreactions[M\u001b[39m.\u001b[39mactions[index]]\u001b[39m.\u001b[39mlower_bound\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(M\u001b[39m.\u001b[39ma[index],\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/util/context.py:111\u001b[0m, in \u001b[0;36mresettable.<locals>.wrapper\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     context(partial(func, \u001b[39mself\u001b[39m, old_value))\n\u001b[0;32m--> 111\u001b[0m func(\u001b[39mself\u001b[39;49m, new_value)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/core/reaction.py:372\u001b[0m, in \u001b[0;36mReaction.lower_bound\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_bounds(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upper_bound)\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lower_bound \u001b[39m=\u001b[39m value\n\u001b[0;32m--> 372\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_variable_bounds()\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/core/reaction.py:326\u001b[0m, in \u001b[0;36mReaction.update_variable_bounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreverse_variable\u001b[39m.\u001b[39mset_bounds(\n\u001b[1;32m    322\u001b[0m         lb\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m isinf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upper_bound) \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upper_bound,\n\u001b[1;32m    323\u001b[0m         ub\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m isinf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lower_bound) \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lower_bound,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_variable\u001b[39m.\u001b[39;49mset_bounds(\n\u001b[1;32m    327\u001b[0m         lb\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, ub\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m isinf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upper_bound) \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upper_bound\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreverse_variable\u001b[39m.\u001b[39mset_bounds(\n\u001b[1;32m    330\u001b[0m         lb\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ub\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m isinf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lower_bound) \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lower_bound\n\u001b[1;32m    331\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/optlang/glpk_interface.py:113\u001b[0m, in \u001b[0;36mVariable.set_bounds\u001b[0;34m(self, lb, ub)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39msuper\u001b[39m(Variable, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mset_bounds(lb, ub)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49m_glpk_set_col_bounds(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/optlang/glpk_interface.py:800\u001b[0m, in \u001b[0;36mModel._glpk_set_col_bounds\u001b[0;34m(self, variable)\u001b[0m\n\u001b[1;32m    797\u001b[0m     glp_set_col_bnds(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem, variable\u001b[39m.\u001b[39m_index,\n\u001b[1;32m    798\u001b[0m                      GLP_FX, \u001b[39mfloat\u001b[39m(variable\u001b[39m.\u001b[39mlb), \u001b[39mfloat\u001b[39m(variable\u001b[39m.\u001b[39mlb))\n\u001b[1;32m    799\u001b[0m \u001b[39melif\u001b[39;00m variable\u001b[39m.\u001b[39mlb \u001b[39m<\u001b[39m variable\u001b[39m.\u001b[39mub:\n\u001b[0;32m--> 800\u001b[0m     glp_set_col_bnds(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem, variable\u001b[39m.\u001b[39;49m_index,\n\u001b[1;32m    801\u001b[0m                      GLP_DB, \u001b[39mfloat\u001b[39m(variable\u001b[39m.\u001b[39mlb), \u001b[39mfloat\u001b[39m(variable\u001b[39m.\u001b[39mub))\n\u001b[1;32m    802\u001b[0m \u001b[39melif\u001b[39;00m variable\u001b[39m.\u001b[39mlb \u001b[39m>\u001b[39m variable\u001b[39m.\u001b[39mub:\n\u001b[1;32m    803\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLower bound \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m is larger than upper bound \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m in variable \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    805\u001b[0m         (variable\u001b[39m.\u001b[39mlb, variable\u001b[39m.\u001b[39mub, variable))\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/optlang/glpk_interface.py:89\u001b[0m, in \u001b[0;36mVariable._index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m         i \u001b[39m=\u001b[39m glp_find_col(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49mproblem, \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname))\n\u001b[1;32m     90\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     91\u001b[0m             \u001b[39mreturn\u001b[39;00m i\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/swiglpk/swiglpk.py:446\u001b[0m, in \u001b[0;36mglp_find_col\u001b[0;34m(P, name)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mglp_find_col\u001b[39m(P, name):\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m _swiglpk\u001b[39m.\u001b[39;49mglp_find_col(P, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent1=tk.Agent(\"agent1\",\n",
    "\t\t\t\tmodel=tm.Toy_Model_NE_Aux_1,\n",
    "\t\t\t\tactor_network=tk.NN,\n",
    "\t\t\t\tcritic_network=tk.NN,\n",
    "\t\t\t\tclip=0.1,\n",
    "\t\t\t\tlr_actor=0.0001,\n",
    "\t\t\t\tlr_critic=0.001,\n",
    "\t\t\t\tgrad_updates=10,\n",
    "\t\t\t\toptimizer_actor=torch.optim.Adam,\n",
    "\t\t\t\toptimizer_critic=torch.optim.Adam,       \n",
    "\t\t\t\tobservables=['agent1','agent2','S',\"A\",\"B\"],\n",
    "\t\t\t\tactions=['A_e','B_e'],\n",
    "\t\t\t\tgamma=1,\n",
    "\t\t\t\t)\n",
    "agent2=tk.Agent(\"agent2\",\n",
    "\t\t\t\tmodel=tm.Toy_Model_NE_Aux_2,\n",
    "\t\t\t\tactor_network=tk.NN,\n",
    "\t\t\t\tcritic_network=tk.NN,\n",
    "\t\t\t\tclip=0.1,\n",
    "\t\t\t\tlr_actor=0.0001,\n",
    "\t\t\t\tlr_critic=0.001,\n",
    "\t\t\t\tgrad_updates=10,\n",
    "\t\t\t\toptimizer_actor=torch.optim.Adam,\n",
    "\t\t\t\toptimizer_critic=torch.optim.Adam,       \n",
    "\t\t\t\tobservables=['agent1','agent2','S',\"A\",\"B\"],\n",
    "\t\t\t\tactions=['A_e','B_e'],\n",
    "\t\t\t\tgamma=1)\n",
    "agents=[agent1,agent2]\n",
    "\n",
    "env=tk.Environment(name=\"Toy-NECOM-Auxotrophs\",\n",
    " \t\t\t\t\tagents=agents,\n",
    " \t\t\t\t\tdilution_rate=0.0001,\n",
    " \t\t\t\t\textracellular_reactions=[],\n",
    " \t\t\t\t\tinitial_condition={\"S\":100,\"agent1\":0.1,\"agent2\":0.1},\n",
    " \t\t\t\t\tinlet_conditions={\"S\":100},\n",
    " \t\t\t\t\tmax_c={'S':100,\n",
    " \t\t\t\t\t\t   'agent1':10,  \n",
    " \t\t\t\t\t\t   'agent2':10,\n",
    " \t\t\t\t\t\t   'A':10,\n",
    " \t\t\t\t\t\t   'B':10,},\n",
    " \t\t\t\t\t\t\tdt=0.1,\n",
    " \t\t\t\t\t\t\tepisode_time=100,\n",
    " \t\t\t\t\t\t\tnumber_of_batches=5000,\n",
    " \t\t\t\t\t\t\tepisodes_per_batch=NUM_CORES,)\n",
    "\n",
    "env.rewards={agent.name:[] for agent in env.agents}\n",
    "if not os.path.exists(f\"Results/{env.name}\"):\n",
    "\tos.makedirs(f\"Results/{env.name}\")\n",
    "for agent in env.agents:\n",
    "\tagent.model.solver=\"glpk\"\n",
    "for batch in range(env.number_of_batches):\n",
    "\tbatch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "\tfor agent in env.agents:\n",
    "\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\tA_k = batch_rtgs[agent.name] - V.detach()   \n",
    "\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "\t\tif batch==0:\n",
    "\t\t\trich.print(\"[bold yellow] Hold on, bringing the creitc network to range...[/bold yellow]\")\n",
    "\t\t\terr=51\n",
    "\t\t\twhile err>50:\n",
    "\t\t\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step() \n",
    "\t\t\t\terr=critic_loss.item()\n",
    "\t\t\trich.print(\"[bold green] Done![/bold green]\")\n",
    "\t\telse: \t\t\t\n",
    "\t\t\tfor _ in range(agent.grad_updates):                                                      \n",
    "\t\t\t\tV, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "\t\t\t\tsurr1 = ratios * A_k.detach()\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_policy_.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\t\t\tagent.optimizer_policy_.step()\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step()                                                            \t\n",
    "\tif batch%500==0:\t\t\n",
    "\t\twith open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(env, f)\n",
    "\t\twith open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(batch_obs,f)\t\t\n",
    "\t\twith open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(batch_acts,f)\t\t\n",
    "    \t\t\n",
    "\tprint(f\"Batch {batch} finished:\")\n",
    "\tfor agent in env.agents:\n",
    "\t\tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy-NECOM-Facultative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Toy-NECOM-Facultative created successfully!.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Hold on, bringing the creitc network to range...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m Hold on, bringing the creitc network to range\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m err\u001b[39m=\u001b[39m\u001b[39m1001\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mwhile\u001b[39;00m err\u001b[39m>\u001b[39m\u001b[39m1000\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \tV, _\u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mevaluate(batch_obs[agent\u001b[39m.\u001b[39;49mname],batch_acts[agent\u001b[39m.\u001b[39;49mname])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \tcritic_loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()(V, batch_rtgs[agent\u001b[39m.\u001b[39mname])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/case_studies.ipynb#X11sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \tagent\u001b[39m.\u001b[39moptimizer_value_\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:284\u001b[0m, in \u001b[0;36mAgent.evaluate\u001b[0;34m(self, batch_obs, batch_acts)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, batch_obs,batch_acts):\n\u001b[0;32m--> 284\u001b[0m     V \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic_network_(batch_obs)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    285\u001b[0m     mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor_network_(batch_obs)\n\u001b[1;32m    286\u001b[0m     \u001b[39m# dist = MultivariateNormal(mean, self.cov_mat)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Toolkit.py:33\u001b[0m, in \u001b[0;36mNN.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, obs):\n\u001b[1;32m     32\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minlayer(obs)\n\u001b[0;32m---> 33\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden(out)\n\u001b[1;32m     34\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(out)\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent1=tk.Agent(\"agent1\",\n",
    "\t\t\t\tmodel=tm.Toy_Model_NE_Mut_1,\n",
    "\t\t\t\tactor_network=tk.NN,\n",
    "\t\t\t\tcritic_network=tk.NN,\n",
    "\t\t\t\tclip=0.1,\n",
    "\t\t\t\tlr_actor=0.0001,\n",
    "\t\t\t\tlr_critic=0.001,\n",
    "\t\t\t\tgrad_updates=10,\n",
    "\t\t\t\toptimizer_actor=torch.optim.Adam,\n",
    "\t\t\t\toptimizer_critic=torch.optim.Adam,       \n",
    "\t\t\t\tobservables=['agent1','agent2','S',\"A\",\"B\"],\n",
    "\t\t\t\tactions=['A_e','B_e'],\n",
    "\t\t\t\tgamma=1,\n",
    "\t\t\t\t)\n",
    "agent2=tk.Agent(\"agent2\",\n",
    "\t\t\t\tmodel=tm.Toy_Model_NE_Mut_2,\n",
    "\t\t\t\tactor_network=tk.NN,\n",
    "\t\t\t\tcritic_network=tk.NN,\n",
    "\t\t\t\tclip=0.1,\n",
    "\t\t\t\tlr_actor=0.0001,\n",
    "\t\t\t\tlr_critic=0.001,\n",
    "\t\t\t\tgrad_updates=10,\n",
    "\t\t\t\toptimizer_actor=torch.optim.Adam,\n",
    "\t\t\t\toptimizer_critic=torch.optim.Adam,       \n",
    "\t\t\t\tobservables=['agent1','agent2','S',\"A\",\"B\"],\n",
    "\t\t\t\tactions=['A_e','B_e'],\n",
    "\t\t\t\tgamma=1)\n",
    "agents=[agent1,agent2]\n",
    "\n",
    "env=tk.Environment(name=\"Toy-NECOM-Facultative\",\n",
    " \t\t\t\t\tagents=agents,\n",
    " \t\t\t\t\tdilution_rate=0.0001,\n",
    " \t\t\t\t\textracellular_reactions=[],\n",
    " \t\t\t\t\tinitial_condition={\"S\":100,\"agent1\":0.1,\"agent2\":0.1,\"A\":0,\"B\":0},\n",
    " \t\t\t\t\tinlet_conditions={\"S\":100},\n",
    " \t\t\t\t\tmax_c={'S':100,\n",
    " \t\t\t\t\t\t   'agent1':10,  \n",
    " \t\t\t\t\t\t   'agent2':10,\n",
    " \t\t\t\t\t\t   'A':10,\n",
    " \t\t\t\t\t\t   'B':10,},\n",
    " \t\t\t\t\t\t\tdt=0.1,\n",
    " \t\t\t\t\t\t\tepisode_time=100,\n",
    " \t\t\t\t\t\t\tnumber_of_batches=5000,\n",
    " \t\t\t\t\t\t\tepisodes_per_batch=4,)\n",
    "\n",
    "env.rewards={agent.name:[] for agent in env.agents}\n",
    "if not os.path.exists(f\"Results/{env.name}\"):\n",
    "\tos.makedirs(f\"Results/{env.name}\")\n",
    "for agent in env.agents:\n",
    "\tagent.model.solver=\"glpk\"\n",
    "for batch in range(env.number_of_batches):\n",
    "\tbatch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "\tfor agent in env.agents:\n",
    "\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\tA_k = batch_rtgs[agent.name] - V.detach()   \n",
    "\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "\t\tif batch==0:\n",
    "\t\t\trich.print(\"[bold yellow] Hold on, bringing the creitc network to range...[/bold yellow]\")\n",
    "\t\t\terr=1001\n",
    "\t\t\twhile err>1000:\n",
    "\t\t\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step() \n",
    "\t\t\t\terr=critic_loss.item()\n",
    "\t\t\trich.print(\"[bold green] Done![/bold green]\")\n",
    "\t\telse: \t\t\t\n",
    "\t\t\tfor _ in range(agent.grad_updates):                                                      \n",
    "\t\t\t\tV, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "\t\t\t\tsurr1 = ratios * A_k.detach()\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_policy_.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\t\t\tagent.optimizer_policy_.step()\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step()                                                            \t\n",
    "\t\tif batch%500==0:\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(env, f)\n",
    "\t\t\twith open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_obs,f)\t\t\n",
    "\t\t\twith open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\t\tpickle.dump(batch_acts,f)\t\t\n",
    "        \t\t\n",
    "\t\tprint(f\"Batch {batch} finished:\")\n",
    "\t\tfor agent in env.agents:\n",
    "\t\t\tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy-Exoenzyme-Five-Agents-with-mass-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from mimetypes import init\n",
    "from turtle import color\n",
    "import Toolkit as tk\n",
    "import Toy_Exoenzyme_mass_transfer as tm\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import ray\n",
    "import os\n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import json\n",
    "import rich\n",
    "import multiprocessing as mp\n",
    "import cobra\n",
    "\n",
    "NUM_CORES = 8\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "toy_model_1=tm.ToyModel_SA_1.copy()\n",
    "toy_model_2=tm.ToyModel_SA_2.copy()\n",
    "toy_model_3=tm.ToyModel_SA_3.copy()\n",
    "toy_model_4=tm.ToyModel_SA_4.copy()\n",
    "toy_model_5=tm.ToyModel_SA_5.copy()\n",
    "\n",
    "\n",
    "agent1=tk.Agent(\"agent1\",\n",
    "                model=toy_model_1,\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5' ,'Glc_1', 'Starch'],\n",
    "                actions=[\"Amylase_1_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "agent2=tk.Agent(\"agent2\",\n",
    "                model=toy_model_2,\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "                observables=['agent1','agent2','agent3','agent4','agent5' ,'Glc_2', 'Starch'],\n",
    "                actions=[\"Amylase_2_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "agent3=tk.Agent(\"agent3\",\n",
    "                model=toy_model_3,\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "\t\t\t\tobservables=['agent1','agent2','agent3','agent4','agent5' ,'Glc_3', 'Starch'],\n",
    "                actions=[\"Amylase_3_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    ")\n",
    "\n",
    "agent4=tk.Agent(\"agent4\",\n",
    "                model=toy_model_4,\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "\t\t\t\tobservables=['agent1','agent2','agent3','agent4','agent5' ,'Glc_4', 'Starch'],\n",
    "                actions=[\"Amylase_4_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    ")\n",
    "\n",
    "agent5=tk.Agent(\"agent5\",\n",
    "                model=toy_model_5,\n",
    "                actor_network=tk.NN,\n",
    "                critic_network=tk.NN,\n",
    "                clip=0.1,\n",
    "                lr_actor=0.0001,\n",
    "                lr_critic=0.001,\n",
    "                grad_updates=4,\n",
    "                optimizer_actor=torch.optim.Adam,\n",
    "                optimizer_critic=torch.optim.Adam,\n",
    "\t\t\t\tobservables=['agent1','agent2','agent3','agent4','agent5' ,'Glc_5', 'Starch'],\n",
    "                actions=[\"Amylase_5_e\"],\n",
    "                gamma=1,\n",
    "                tau=0.1\n",
    ")\n",
    "\n",
    "agents=[agent1,agent2,agent3,agent4,agent5]\n",
    "\n",
    "env=tk.Environment(name=\"Toy-Exoenzyme-Five-agents-mass-transfer-low\",\n",
    "                    agents=agents,\n",
    "                    dilution_rate=0.0001,\n",
    "                    initial_condition={\"Glc\":0,\"Glc_1\":20,\"Glc_2\":20,\"Glc_3\":20,\"Glc_4\":20,\"Glc_5\":20,\"agent1\":0.1,\"agent2\":0.1,'agent3':0.1,'agent4':0.1,'agent5':0.1,\"Starch\":10},\n",
    "                    inlet_conditions={\"Starch\":10},\n",
    "                    extracellular_reactions=[{\"reaction\":{\n",
    "                    \"Glc_1\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc_1\",\"Amylase_1\"))}\n",
    "\t\t            ,\n",
    "\t\t            {\n",
    "                    \"reaction\":{\n",
    "                    \"Glc_2\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc_2\",\"Amylase_2\"))\n",
    "                    ,}\n",
    "\t\t    ,\n",
    "\t\t    {\n",
    "                    \"reaction\":{\n",
    "                    \"Glc_3\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc_3\",\"Amylase_3\"))\n",
    "\t\t    \n",
    "            },\n",
    "            {\n",
    "                    \"reaction\":{\n",
    "                    \"Glc_4\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc_4\",\"Amylase_4\"))\n",
    "                    \n",
    "            },  \n",
    "\t    \n",
    "            {   \"reaction\":{\n",
    "                    \"Glc_5\":10,\n",
    "                    \"Starch\":-0.1,},\n",
    "                    \"kinetics\": (tk.general_kinetic,(\"Glc_5\",\"Amylase_5\"))\n",
    "                    \n",
    "            }  ,\n",
    "            {   \n",
    "                \"reaction\":{\n",
    "                    \"Glc_1\":-1,\n",
    "                    \"Glc\":1},\n",
    "                \"kinetics\": (tk.mass_transfer,(\"Glc_1\",\"Glc\"))\n",
    "            }\n",
    "            ,\n",
    "            {\n",
    "                \"reaction\":{\n",
    "                    \"Glc_2\":-1,\n",
    "                    \"Glc\":1},\n",
    "                \"kinetics\": (tk.mass_transfer,(\"Glc_2\",\"Glc\"))\n",
    "            }\n",
    "            ,\n",
    "            {\n",
    "                \"reaction\":{\n",
    "                    \"Glc_3\":-1,\n",
    "                    \"Glc\":1},\n",
    "                \"kinetics\": (tk.mass_transfer,(\"Glc_3\",\"Glc\"))  \n",
    "            },\n",
    "            {\n",
    "                \"reaction\":{\n",
    "                    \"Glc_4\":-1,\n",
    "                    \"Glc\":1},\n",
    "                \"kinetics\": (tk.mass_transfer,(\"Glc_4\",\"Glc\"))\n",
    "            }\n",
    "            ,\n",
    "            {\n",
    "                \"reaction\":{ \n",
    "                    \"Glc_5\":-1,\n",
    "                    \"Glc\":1},\n",
    "                \"kinetics\": (tk.mass_transfer,(\"Glc_5\",\"Glc\"))\n",
    "            }\n",
    "\t\t\t\t\t],\n",
    "                    max_c={'Glc':100,\n",
    "                           'agent1':10,  \n",
    "                           'Starch':10,\n",
    "                           },\n",
    "                           dt=0.1,\n",
    "                           episode_time=100,\n",
    "                           number_of_batches=5000,\n",
    "                           episodes_per_batch=int(NUM_CORES/2),\n",
    "                           )\n",
    "\n",
    "env.rewards={agent.name:[] for agent in env.agents}\n",
    "\n",
    "if not os.path.exists(f\"Results/{env.name}\"):\n",
    "\tos.makedirs(f\"Results/{env.name}\")\n",
    "\n",
    "for agent in env.agents:\n",
    "\tagent.model.solver=\"glpk\"\n",
    "\n",
    "for batch in range(env.number_of_batches):\n",
    "\n",
    "\tbatch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "\tfor agent in env.agents:\n",
    "\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\tA_k = batch_rtgs[agent.name] - V.detach()   \n",
    "\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "\t\tif batch==0:\n",
    "\t\t\trich.print(\"[bold yellow] Hold on, bringing the creitc network to range...[/bold yellow]\")\n",
    "\t\t\terr=51\n",
    "\t\t\twhile err>50:\n",
    "\t\t\t\tV, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step() \n",
    "\t\t\t\terr=critic_loss.item()\n",
    "\t\t\trich.print(\"[bold green] Done![/bold green]\")\n",
    "\t\telse: \n",
    "\t\t\t\n",
    "\t\t\tfor _ in range(agent.grad_updates):                                                      \n",
    "\t\t\t\tV, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "\t\t\t\tsurr1 = ratios * A_k.detach()\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "\t\t\t\tagent.optimizer_policy_.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=False)\n",
    "\t\t\t\tagent.optimizer_policy_.step()\n",
    "\t\t\t\tagent.optimizer_value_.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "\t\t\t\tagent.optimizer_value_.step()                                                            \n",
    "\t\n",
    "\tif batch%500==0:\n",
    "\t\n",
    "\t\twith open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(env, f)\n",
    "\t\twith open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(batch_obs,f)\t\t\n",
    "\t\twith open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "\t\t\tpickle.dump(batch_acts,f)\t\t\n",
    "      \t\t\n",
    "\tprint(f\"Batch {batch} finished:\")\n",
    "\tfor agent in env.agents:\n",
    "\t\tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IJO1366-Tyr-Phe-Auxotrophs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mimetypes import init\n",
    "from turtle import color\n",
    "import Toolkit as tk\n",
    "import Toy_Exoenzyme_mass_transfer as tm\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import ray\n",
    "import os\n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import json\n",
    "import rich\n",
    "import multiprocessing as mp\n",
    "import cobra\n",
    "from itertools import combinations\n",
    "\n",
    "NUM_CORES = 8\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "model_base = cobra.io.read_sbml_model(\"iJO1366.xml\")\n",
    "medium = model_base.medium.copy()\n",
    "test_model = model_base.copy()\n",
    "\n",
    "knockouts_gene_names = [\n",
    "    \"tyrA\",\n",
    "    \"pheA\",\n",
    "]\n",
    "\n",
    "exchange_reactions = {\n",
    "    \"tyrA\": \"EX_tyr__L_e\",\n",
    "    \"pheA\": \"EX_phe__L_e\",\n",
    "    # \"argA\": \"EX_arg__L_e\",\n",
    "    # \"hisB\": \"EX_his__L_e\",\n",
    "    # \"leuB\": \"EX_leu__L_e\",\n",
    "    # \"cysE\": \"EX_cys__L_e\",\n",
    "    # \"glyA\": \"EX_gly_e\",\n",
    "    # \"serA\": \"EX_ser__L_e\",\n",
    "    # \"thrC\": \"EX_thr__L_e\",\n",
    "    # \"trpC\": \"EX_trp__L_e\",\n",
    "    # \"ilvA\": \"EX_ile__L_e\",\n",
    "    # \"lysA\": \"EX_lys__L_e\",\n",
    "    # \"metA\": \"EX_met__L_e\",\n",
    "    # \"proA\": \"EX_pro__L_e\",\n",
    "}\n",
    "\n",
    "exchange_species = {}\n",
    "exchange_mets = {}\n",
    "for i in exchange_reactions.items():\n",
    "    exchange_mets[i[0]] = list(test_model.reactions.get_by_id(i[1]).metabolites.keys())[\n",
    "        0\n",
    "    ].id\n",
    "\n",
    "gene_ids = {}\n",
    "for ko_gene in knockouts_gene_names:\n",
    "    for gene in test_model.genes:\n",
    "        if gene.name == ko_gene:\n",
    "            gene_ids[ko_gene] = gene.id\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "knockouts = set()\n",
    "for i in combinations(knockouts_gene_names, 2):\n",
    "    if set(i) not in knockouts:\n",
    "        knockouts.add(frozenset(i))\n",
    "\n",
    "unique_knockouts = [tuple(i) for i in knockouts]\n",
    "\n",
    "ic={\n",
    "    key.lstrip(\"EX_\"):3 for key,val in model_base.medium.items() \n",
    "}\n",
    "\n",
    "ic['glc__D_e']=500\n",
    "ic['agent1']=0.1\n",
    "ic['agent2']=0.1\n",
    "for ko in [(\"tyrA\",\"pheA\")]:\n",
    "    model1 = model_base.copy()\n",
    "    model2 = model_base.copy()\n",
    "    model1.remove_reactions([model1.reactions.get_by_id('PPND')]) ## Tyrosine Mutant\n",
    "    model2.remove_reactions([model2.reactions.get_by_id('PPNDH')]) ## Phenylalanine Mutant\n",
    "    model1.exchange_reactions = tuple([model1.reactions.index(i) for i in model1.exchanges])\n",
    "    model2.exchange_reactions = tuple([model2.reactions.index(i) for i in model2.exchanges])\n",
    "    model1.biomass_ind=model1.reactions.index(\"BIOMASS_Ec_iJO1366_core_53p95M\")\n",
    "    model2.biomass_ind=model2.reactions.index(\"BIOMASS_Ec_iJO1366_core_53p95M\")\n",
    "    model1.solver = \"gurobi\"\n",
    "    model2.solver = \"gurobi\"\n",
    "    if model1.optimize().objective_value != 0 or model2.optimize().objective_value != 0:\n",
    "        rich.print(f\"[yellow]Skipping {ko} because at least one organism can grow without auxotrophy\")\n",
    "        continue\n",
    "    else:\n",
    "        rich.print(f\"[green]Non of the KOs can grow without auxotrophy: Running {ko}\")\n",
    "    ko_name = ko[0] + \"_\" + ko[1]\n",
    "    agent1 = tk.Agent(\n",
    "        \"agent1\",\n",
    "        model=model1,\n",
    "        actor_network=tk.NN,\n",
    "        critic_network=tk.NN,\n",
    "        clip=0.1,\n",
    "        lr_actor=0.0001,\n",
    "        lr_critic=0.001,\n",
    "        actor_var=0.05,\n",
    "        grad_updates=1,\n",
    "        optimizer_actor=torch.optim.Adam,\n",
    "        optimizer_critic=torch.optim.Adam,\n",
    "        observables=[\n",
    "            \"agent1\",\n",
    "            \"agent2\",\n",
    "            \"glc__D_e\",\n",
    "            *[i.replace(\"EX_\", \"\") for i in exchange_reactions.values()]\n",
    "        ],\n",
    "        actions=[i for i in exchange_reactions.values()],\n",
    "        gamma=1,\n",
    "    )\n",
    "    agent2 = tk.Agent(\n",
    "        \"agent2\",\n",
    "        model=model2,\n",
    "        actor_network=tk.NN,\n",
    "        critic_network=tk.NN,\n",
    "        clip=0.1,\n",
    "        lr_actor=0.0001,\n",
    "        lr_critic=0.001,\n",
    "        grad_updates=1,\n",
    "        actor_var=0.05,\n",
    "        optimizer_actor=torch.optim.Adam,\n",
    "        optimizer_critic=torch.optim.Adam,\n",
    "        observables=[\n",
    "            \"agent1\",\n",
    "            \"agent2\",\n",
    "            \"glc__D_e\",\n",
    "            *[i.replace(\"EX_\", \"\") for i in exchange_reactions.values()]\n",
    "        ],\n",
    "        actions=[i for i in exchange_reactions.values()],\n",
    "        gamma=1,\n",
    "    )\n",
    "    constants=list(ic.keys())\n",
    "    constants.remove(\"agent1\")\n",
    "    constants.remove(\"agent2\")\n",
    "    constants.remove(\"glc__D_e\")\n",
    "\n",
    "    env = tk.Environment(\n",
    "        \"IJO1366-Tyr-Phe-Auxotrophs\" ,\n",
    "        agents=[agent1, agent2],\n",
    "        dilution_rate=0,\n",
    "        extracellular_reactions=[],\n",
    "        initial_condition=ic,\n",
    "        inlet_conditions={},\n",
    "        max_c={},\n",
    "        dt=0.2,\n",
    "        episode_time=20,  ##TOBECHANGED\n",
    "        number_of_batches=10000,  ##TOBECHANGED\n",
    "        episodes_per_batch=4,\n",
    "        constant=constants,\n",
    "    )\n",
    "\n",
    "    env.rewards = {agent.name: [] for agent in env.agents}\n",
    "\n",
    "    if not os.path.exists(f\"Results/{env.name}\"):\n",
    "        os.makedirs(f\"Results/{env.name}\")\n",
    "### The next block will train the actor network to output -1 for all actions, so that \n",
    "### the agents start like FBA\n",
    "\n",
    "    for batch in range(env.number_of_batches):\n",
    "        batch_obs,batch_acts, batch_log_probs, batch_rtgs=tk.rollout(env)\n",
    "        for agent in env.agents:\n",
    "            V, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "            A_k = batch_rtgs[agent.name] - V.detach()   \n",
    "            A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5) \n",
    "            if batch==0:\n",
    "                rich.print(\"[bold yellow] Hold on, bringing the networks to range...[/bold yellow]\")\n",
    "                err=101\n",
    "                while err>100:\n",
    "                    V, _= agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "                    critic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "                    agent.optimizer_value_.zero_grad()\n",
    "                    critic_loss.backward()\n",
    "                    agent.optimizer_value_.step() \n",
    "                    err=critic_loss.item()\n",
    "                rich.print(\"[bold green] Done![/bold green]\")\n",
    "            else: \t\t\t\n",
    "                for _ in range(agent.grad_updates):                                                      \n",
    "                    V, curr_log_probs = agent.evaluate(batch_obs[agent.name],batch_acts[agent.name])\n",
    "                    ratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "                    surr1 = ratios * A_k.detach()\n",
    "                    surr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "                    actor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "                    critic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "                    agent.optimizer_policy_.zero_grad()\n",
    "                    actor_loss.backward(retain_graph=False)\n",
    "                    agent.optimizer_policy_.step()\n",
    "                    agent.optimizer_value_.zero_grad()\n",
    "                    critic_loss.backward()\n",
    "                    agent.optimizer_value_.step()   \n",
    "\n",
    "        if batch%500==0:\n",
    "            with open(f\"Results/{env.name}/{env.name}_{batch}.pkl\", 'wb') as f:\n",
    "                pickle.dump(env, f)\n",
    "            with open(f\"Results/{env.name}/observations_{batch}.pkl\", 'wb') as f:\n",
    "                pickle.dump(batch_obs,f)\t\t\n",
    "            with open(f\"Results/{env.name}/actions_{batch}.pkl\", 'wb') as f:\n",
    "                pickle.dump(batch_acts,f)\t\t\n",
    "        print(f\"Batch {batch} finished:\")\n",
    "        for agent in env.agents:\n",
    "        \tprint(f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\")\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd4282f6964f11bb4427604f51fdde6c3d4aaf7297d931ff306d1c282a07f33e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
